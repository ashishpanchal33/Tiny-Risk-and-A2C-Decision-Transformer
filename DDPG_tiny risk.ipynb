{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "358fdba8-2d74-46d3-8d0c-650038d08878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs and experiment results can be found at https://docs.cleanrl.dev/rl-algorithms/ddpg/#ddpg_continuous_actionpy\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#import tyro\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a1da81-2341-40e2-b749-915e79723108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] =\"expandable_segments:True\"\n",
    "import gymnasium as gym\n",
    "\n",
    "#import gym\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tyro\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import functools\n",
    "import random\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "from gymnasium.spaces import Discrete, MultiDiscrete, Box, Dict\n",
    "\n",
    "from pettingzoo import AECEnv\n",
    "\n",
    "\n",
    "\n",
    "import gymnasium\n",
    "\n",
    "\n",
    "from pettingzoo.utils import agent_selector, wrappers\n",
    "\n",
    "from gymnasium.utils import EzPickle\n",
    "\n",
    "\n",
    "\n",
    "from statistics import NormalDist\n",
    "\n",
    "import pygame\n",
    "\n",
    "from typing import Any , Generic, Iterable, Iterator, TypeVar\n",
    "ActionType = TypeVar(\"ActionType\")\n",
    "\n",
    "import collections\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf526ce-0ee4-4087-91bf-994df54a3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  Utilities.new_models import *\n",
    "from  Utilities.Transformer_risk_act_2 import *\n",
    "import utils_gym\n",
    "import env_model_class_2\n",
    "\n",
    "\n",
    "from board_env import *\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2a79e0-f1da-41f8-aa8e-2c1f388c2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209de013-e362-45d3-88e4-f4a98e8375c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model arch def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171f9c25-a240-49fa-be75-47dd78de3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    exp_name: str = 'Tiny_Risk'#os.path.basename(__file__)[: -len(\".py\")]\n",
    "    \"\"\"the name of this experiment\"\"\"\n",
    "    seed: int = 1\n",
    "    \"\"\"seed of the experiment\"\"\"\n",
    "    torch_deterministic: bool = True\n",
    "    \"\"\"if toggled, `torch.backends.cudnn.deterministic=False`\"\"\"\n",
    "    cuda: bool = True\n",
    "    \"\"\"if toggled, cuda will be enabled by default\"\"\"\n",
    "    track: bool = False\n",
    "    \"\"\"if toggled, this experiment will be tracked with Weights and Biases\"\"\"\n",
    "    wandb_project_name: str = \"cleanRL\"\n",
    "    \"\"\"the wandb's project name\"\"\"\n",
    "    wandb_entity: str = None\n",
    "    \"\"\"the entity (team) of wandb's project\"\"\"\n",
    "    capture_video: bool = False\n",
    "    \"\"\"whether to capture videos of the agent performances (check out `videos` folder)\"\"\"\n",
    "    save_model: bool = False\n",
    "    \"\"\"whether to save model into the `runs/{run_name}` folder\"\"\"\n",
    "    upload_model: bool = False\n",
    "    \"\"\"whether to upload the saved model to huggingface\"\"\"\n",
    "    hf_entity: str = \"\"\n",
    "    \"\"\"the user or org name of the model repository from the Hugging Face Hub\"\"\"\n",
    "\n",
    "    # Algorithm specific arguments\n",
    "    env_id: str = \"Tiny_Risk\" #\"Hopper-v4\"\n",
    "    \"\"\"the environment id of the Atari game\"\"\"\n",
    "    total_timesteps: int = 1000000\n",
    "    \"\"\"total timesteps of the experiments\"\"\"\n",
    "    learning_rate: float = 3e-4\n",
    "    \"\"\"the learning rate of the optimizer\"\"\"\n",
    "    buffer_size: int = int(1e6)\n",
    "    \"\"\"the replay memory buffer size\"\"\"\n",
    "    gamma: float = 0.99\n",
    "    \"\"\"the discount factor gamma\"\"\"\n",
    "    tau: float = 0.005\n",
    "    \"\"\"target smoothing coefficient (default: 0.005)\"\"\"\n",
    "    batch_size: int = 256\n",
    "    \"\"\"the batch size of sample from the reply memory\"\"\"\n",
    "    exploration_noise: float = 0.1\n",
    "    \"\"\"the scale of exploration noise\"\"\"\n",
    "    learning_starts: int = 25e3\n",
    "    \"\"\"timestep to start learning\"\"\"\n",
    "    policy_frequency: int = 2\n",
    "    \"\"\"the frequency of training policy (delayed)\"\"\"\n",
    "    noise_clip: float = 0.5\n",
    "    \"\"\"noise clip parameter of the Target Policy Smoothing Regularization\"\"\"\n",
    "\n",
    "\n",
    "def make_env(env_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        if capture_video and idx == 0:\n",
    "            env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "            env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        env.action_space.seed(seed)\n",
    "        return env\n",
    "\n",
    "    return thunk\n",
    "\n",
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "\n",
    "# ALGO LOGIC: initialize agent here:\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs,action,h_dim=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(obs + h_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "\n",
    "        self.embed_action = layer_init(torch.nn.Linear(2, h_dim), std=0.01)\n",
    "\n",
    "    def forward(self, x, a1,a2):\n",
    "        #x = torch.cat([x, a], 1)\n",
    "        a = torch.concat((a1,a2),axis = -1)\n",
    "        a = self.embed_action(a)\n",
    "\n",
    "        x = torch.concat((x,a),axis = 1)\n",
    "\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def differentiable_randomized_argmax(softmax_output, temperature=1.0):\n",
    "\n",
    "    if temperature < 0:\n",
    "        raise ValueError(\"Temperature must be non-negative.\")\n",
    "    max_prob = torch.max(softmax_output, dim=-1, keepdim=True)[0]\n",
    "    top_k_mask = (softmax_output == max_prob).float()\n",
    "    # Generate Gumbel noise\n",
    "    gumbel_noise = -torch.log(-torch.log(torch.rand_like(softmax_output) + 1e-9) + 1e-9)  # Adding small epsilon for numerical stability\n",
    "\n",
    "    # Add Gumbel noise to logits (implicitly working with logits since softmax_output is probabilities)\n",
    "    # To make it more numerically stable if starting from probabilities, you might want to work with logits directly if possible.\n",
    "    # However, we can approximate logits from probabilities (though it might lose some precision)\n",
    "    # logits = torch.log(softmax_output + 1e-9) # Avoid log(0)\n",
    "    # noisy_logits = logits + gumbel_noise\n",
    "\n",
    "    # More directly with probabilities (and numerically safer)\n",
    "    noisy_logits = torch.log(softmax_output + 1e-9) + gumbel_noise * top_k_mask # Approximate logits then add noise\n",
    "    noisy_output = nn.functional.softmax(noisy_logits / temperature, dim=-1) # Apply softmax with temperature\n",
    "\n",
    "    a=torch.argmax(noisy_output,-1)\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "class ActorDiscrete(nn.Module):\n",
    "    def __init__(self, obs, action_space): # Pass action_space instead of env\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(obs, 256) # Use obs.shape directly\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_pi = nn.Linear(256, action_space) # Output size is the number of discrete actions\n",
    "\n",
    "    def forward(self, x,action_mask=[],use_action_mask=True,give_prob=False):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = self.fc_pi(x) # Output logits for each discrete action\n",
    "        \n",
    "        if use_action_mask:\n",
    "            probs = (F.softmax(logits*action_mask + 1e-9, dim=-1)) # Apply softmax to get probabilities\n",
    "        else:\n",
    "            probs = (F.softmax(logits+ 1e-9, dim=-1))\n",
    "        if give_prob:\n",
    "            return probs # Return the probability distribution over actions\n",
    "        else:\n",
    "            dis = Categorical(probs)\n",
    "            acts = dis.sample()\n",
    "            return  acts#differentiable_randomized_argmax(probs)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, obs,action_space,h_dim = 6):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(obs+h_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_mu = nn.Linear(256, 1)\n",
    "        # action rescaling\n",
    "        self.register_buffer(\n",
    "            \"action_scale\", torch.tensor((1 - 0) / 2.0, dtype=torch.float32)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"action_bias\", torch.tensor((1 - 0) / 2.0, dtype=torch.float32)\n",
    "        )\n",
    "        self.embed_action_1 = torch.nn.Embedding(action_space+1, h_dim)\n",
    "\n",
    "    def forward(self, x,a):\n",
    "        \n",
    "    \n",
    "        a = self.embed_action_1(a.long())\n",
    "\n",
    "        x = torch.concat((x,a),axis = -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc_mu(x))\n",
    "        return x * self.action_scale + self.action_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466fc388-73b5-4ab6-a84a-b22188fd81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PG_ValueNetwork(nn.Module): # Renamed from QNetwork to ValueNetwork\n",
    "    def __init__(self, obs): # Removed action input from __init__\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(obs, 256) # Input is now just observation\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 1) # Output is a single value (V-value)\n",
    "\n",
    "    def forward(self, x): # Removed action inputs a1, a2 from forward\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class PG_ActorDiscrete(nn.Module):\n",
    "    def __init__(self, obs, action_space): # Pass action_space\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(obs, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_pi = nn.Linear(256, action_space) # Output logits for each discrete action\n",
    "\n",
    "    def forward(self, x, action_mask=[], use_action_mask=True, give_prob=False,give_action=True): # Always give probabilities in forward\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = self.fc_pi(x) # Output logits\n",
    "\n",
    "        if use_action_mask:\n",
    "            probs = (F.softmax(logits * action_mask + 1e-9, dim=-1)) # Softmax with mask\n",
    "        else:\n",
    "            probs = (F.softmax(logits + 1e-9, dim=-1)) # Softmax without mask\n",
    "\n",
    "        if give_prob and not give_action:\n",
    "            return probs # Return the probability distribution over actions\n",
    "        elif (not give_prob) and give_action:\n",
    "            dis = Categorical(probs)\n",
    "            acts = dis.sample()\n",
    "            return  acts#differentiable_randomized_argmax(probs)\n",
    "        else:\n",
    "            dis = Categorical(probs)\n",
    "            acts = dis.sample()\n",
    "            return  probs, acts#differentiable_randomized_argmax(probs)            \n",
    "\n",
    "    def get_logprob(self, observations, actions, action_mask=[], use_action_mask=True): # New method to get log probabilities\n",
    "        probs = self.forward(observations, action_mask=action_mask, use_action_mask=use_action_mask,give_prob=True,give_action=False) # Get probabilities\n",
    "        log_probs = torch.log(probs.gather(1, actions.long().unsqueeze(1)) + 1e-9) # Log prob of taken actions\n",
    "        return log_probs.squeeze(1)\n",
    "\n",
    "\n",
    "class PG_Actor(nn.Module):\n",
    "    def __init__(self, obs, action_space, h_dim=6): # action_space is not directly used here, but kept for consistency if needed elsewhere\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(obs + h_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_mu = nn.Linear(256, 1) # Output mean (mu)\n",
    "        self.log_std = nn.Parameter(torch.zeros(1, 1)) # Learnable log std (or could be fixed std)\n",
    "        self.embed_action_1 = torch.nn.Embedding(action_space + 1, h_dim) # Keep embedding layer\n",
    "\n",
    "    def forward(self, x, a, give_dis= False, give_entropy=False):\n",
    "        a = self.embed_action_1(a.long()) # Embed discrete action a1\n",
    "        x = torch.concat((x, a), axis=-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mu = torch.tanh(self.fc_mu(x)) # Mean action (bounded by tanh)\n",
    "        std = torch.exp(self.log_std) # Standard deviation (always positive)\n",
    "        \n",
    "        if give_entropy:\n",
    "            entropy = torch.distributions.Normal(mu, std).entropy().squeeze(-1)\n",
    "            \n",
    "        \n",
    "        if give_dis and not(give_entropy):\n",
    "            return mu, std # Return both mean and std\n",
    "        elif give_dis and give_entropy:\n",
    "            return mu, std, entropy\n",
    "        elif (not give_dis) and give_entropy:\n",
    "            return mu, entropy\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def get_logprob(self, observations, actions, a1): # New method to get log probabilities\n",
    "        mu, std = self.forward(observations, a1,give_dis=True) # Get mean and std\n",
    "        dist = torch.distributions.Normal(mu, std) # Create normal distribution\n",
    "        log_prob = dist.log_prob(actions) # Log prob of given actions under this distribution\n",
    "        return log_prob.squeeze(1) # Return log probs, squeezed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2864bb62-5660-4a08-b782-02d0732e4a2d",
   "metadata": {},
   "source": [
    "## env config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba604305-ee44-42b7-b916-91ddd5d05354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.buffers import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc82383d-97ec-40f0-b9b3-4b8f08eb42a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = dict(render_mode = None,#'rgb_array', \n",
    "                    default_attack_all  = True,\n",
    "                    agent_count  = 3#4\n",
    "                    ,use_placement_perc=True,\n",
    "                    render_=False,\n",
    "                    bad_mov_penalization = 0.01\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9580c235-e152-4d5a-bd79-703710908934",
   "metadata": {},
   "source": [
    "# Hero agent def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06932cd2-3a1f-4ff2-a2d4-c73d508606a2",
   "metadata": {},
   "source": [
    "## base hero agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ae1e0a-62a8-4bb5-8e95-c10ff2c47c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "        #self.model = \n",
    "\n",
    "\n",
    "\n",
    "class Hero_agent(int):\n",
    "    def init_properties(self,agent_count,phases,cp=[],df=[],direct_action=True):\n",
    "        #self.draw_count = 0\n",
    "        self.init_win_count_iter(agent_count)\n",
    "        self.init_move_count_epi(phases)\n",
    "        self.cp = cp\n",
    "        self.df = df\n",
    "        self.direct_action = direct_action\n",
    "        self.init_reward_concern(agent_count,cp=cp,df=df)\n",
    "        \n",
    "    def init_reward_concern(self,agent_count,cp=[],df=[]):\n",
    "        if len(cp)==0:\n",
    "            cp = [int(self)]\n",
    "        self.concern=torch.tensor([(1 if i in cp \n",
    "                             else \n",
    "                             (-1 if i in df \n",
    "                                  else 0)) for i in range(1,agent_count+1) ])\n",
    "        #self.concern_2 = self.concern\n",
    "        #self.concern_2[self-1] =0\n",
    "        \n",
    "        self.multi_dependency = (sum(self.concern !=0)>1)\n",
    "        \n",
    "        \n",
    "    def init_model(self,model_name=\"DDQN_module\",\n",
    "                   kwarg = dict({})):\n",
    "        self.model = model_selector(model_name=model_name, \n",
    "                                    kwarg = kwarg)\n",
    "\n",
    "        \n",
    "    def init_win_count_iter(self,agent_count):\n",
    "        self.count_dict = {i:0 for i in range(1,agent_count+1)}\n",
    "        self.count_draw_dict = {i:0 for i in range(1,agent_count+1)}\n",
    "        self.draw_territory_count = 0\n",
    "    def init_move_count_epi(self,phases):\n",
    "        self.bad_move_count = 0\n",
    "        self.bad_move_phase_count = {i:0 for i in phases}\n",
    "        self.move_count =  {i:0 for i in phases}        \n",
    "    \n",
    "    def model_def(self, model):\n",
    "        self.model =model\n",
    "\n",
    "    def action_predict(self,save_R=True,return_R = False,action_masks = [],return_log_prob_a2 = False):\n",
    "        return self.model.action_predict(save_R=save_R,return_R = return_R, action_masks = action_masks,return_log_prob_a2 = return_log_prob_a2)\n",
    "\n",
    "    def action_predict_direct(self,data,return_R = False,return_log_prob_a2 = False):\n",
    "        return self.model.action_predict_direct(data,return_R = return_R,return_log_prob_a2 = return_log_prob_a2)\n",
    "    def save_models(self):\n",
    "        self.model.save_models()\n",
    "\n",
    "    def process_reward(self,rewards,step,hero_steps):\n",
    "        if self.multi_dependency and self.direct_action:\n",
    "            return (rewards*self.concern.to(rewards.device)).sum(-1)[:step][hero_steps][:,None]\n",
    "        elif self.multi_dependency and not self.direct_action:\n",
    "            base_rew = torch.zeros( rewards[:step,self-1][hero_steps].shape,require_grad=False)\n",
    "            #print(base_rew)\n",
    "\n",
    "            \n",
    "            hero_step_list  = np.arange(0,step)[hero_steps]\n",
    "            for i,j in zip(hero_step_list[:-1],hero_step_list[1:]):\n",
    "                if j-i>1:\n",
    "                    #print(j,i,rewards[i:j],(rewards[i:j]*self.concern),(rewards[i:j]*self.concern).sum())\n",
    "                    base_rew[i]+= (rewards[i:j]*self.concern).sum()\n",
    "            #print(base_rew,rewards[hero_step_list[-1]:],(rewards[hero_step_list[-1]:]*self.concern))\n",
    "            base_rew[-1]+= (rewards[hero_step_list[-1]:]*self.concern).sum()\n",
    "            \n",
    "            return base_rew[:,None]\n",
    "            \n",
    "        else:\n",
    "            return rewards[:step][hero_steps][:,None]\n",
    "\n",
    "\n",
    "    def init_model_config(self,args):\n",
    "        self.args = args\n",
    "\n",
    "    def init_memory_config(self,args):\n",
    "        self.args = args\n",
    "        \n",
    "    def init_loss_config(self,args):\n",
    "        self.args = args\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #def model_forward_call(self,name,kwarg):\n",
    "    #    return self.model_dict[name](**kwarg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1dfa91-b15b-4980-88de-9ed8268141d4",
   "metadata": {},
   "source": [
    "## Memory agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735c5c81-ee35-4841-b5c0-90d9bda99995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from stable_baselines3.common.type_aliases import (\n",
    "    ReplayBufferSamples,\n",
    "    RolloutBufferSamples,\n",
    ")\n",
    "from stable_baselines3.common.preprocessing import get_action_dim, get_obs_shape\n",
    "\n",
    "\n",
    "from typing import Dict, Generator, NamedTuple, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e704166-6d0a-4889-aea1-9d064ffc5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBufferSamples(NamedTuple):\n",
    "    observations: th.Tensor\n",
    "    actions: th.Tensor\n",
    "    next_observations: th.Tensor\n",
    "    dones: th.Tensor\n",
    "    rewards: th.Tensor\n",
    "    mask: th.Tensor\n",
    "    t_pow: th.Tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aca30ce-f9ad-4773-830d-516d42edf659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces as spaces_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "061ddd3d-5216-47e3-ba43-2bbaa9c0e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomReplayBuffer(ReplayBuffer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.mask = np.zeros((self.buffer_size, 32), dtype=np.float32)  # Add a new array for custom feature\n",
    "        self.t_pow = np.zeros((self.buffer_size, 1), dtype=np.float32)\n",
    "\n",
    "\n",
    "    def add(self, obs, action, reward, next_obs, done, mask,t_pow):  # Add custom value when adding data\n",
    "\n",
    "        super().add(obs, action, reward, next_obs, done,{'t':t_pow})\n",
    "\n",
    "        self.mask[self.pos] = mask\n",
    "        self.t_pow[self.pos] = t_pow\n",
    "\n",
    "    def _get_samples(self,  batch_inds: np.ndarray, env: Optional[VecNormalize] = None) -> ReplayBufferSamples:\n",
    "        # ... (rest of the _get_samples code from SB3's ReplayBuffer) ...\n",
    "        #custom_value = self.custom_feature[batch_inds] # Retrieve infos\n",
    "\n",
    "\n",
    "\n",
    "        if self.optimize_memory_usage:\n",
    "            next_obs = self._normalize_obs(self.observations[(batch_inds + 1) % self.buffer_size, 0, :], env)\n",
    "        else:\n",
    "            next_obs = self._normalize_obs(self.next_observations[batch_inds, 0, :], env)\n",
    "\n",
    "        data = (\n",
    "            self._normalize_obs(self.observations[batch_inds, 0, :], env),\n",
    "            self.actions[batch_inds, 0, :],\n",
    "            next_obs,\n",
    "            self.dones[batch_inds],\n",
    "            self._normalize_reward(self.rewards[batch_inds], env),\n",
    "            self.mask[batch_inds],\n",
    "            self.t_pow[batch_inds]\n",
    "            \n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "        #data = (observations, actions, next_observations, dones, rewards, custom_value) # Include infos\n",
    "        return ReplayBufferSamples(*tuple(map(self.to_torch, data))) # Or InfoReplayBufferSamples if you define it\n",
    "\n",
    "    def sample(self, batch_size: int, env: Optional[VecNormalize] = None) -> ReplayBufferSamples: # Optionally adjust return type hint\n",
    "        # ... (rest of the sample code from SB3) ...\n",
    "        \n",
    "        if not self.optimize_memory_usage:\n",
    "            return super().sample(batch_size=batch_size, env=env)\n",
    "        # Do not sample the element with index `self.pos` as the transitions is invalid\n",
    "        # (we use only one array to store `obs` and `next_obs`)\n",
    "        if self.full:\n",
    "            batch_inds = (np.random.randint(1, self.buffer_size, size=batch_size) + self.pos) % self.buffer_size\n",
    "        else:\n",
    "            batch_inds = np.random.randint(0, self.pos, size=batch_size)      \n",
    "        \n",
    "        \n",
    "        return self._get_samples(batch_inds, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac0a35aa-314c-425b-a650-534420f7638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class memory_agent(Hero_agent):\n",
    "    def init_path(self):\n",
    "        self.paths = []\n",
    "    def path_que(self, dtl):\n",
    "        \n",
    "        if (len(self.paths)==self.rb_len):\n",
    "            if (self.rb_len >1):\n",
    "                self.paths.pop(random.randrange(len(self.paths)-self.args.num_episodes +1 )) # dont pop the most recent experiences and ensure rb_len > num.episodes\n",
    "            else: \n",
    "                self.paths.pop()\n",
    "        self.paths.append(dtl)\n",
    "        \n",
    "    def create_training_dataset(self):\n",
    "        self.traj_dataset =  TrajectoryDataset_2_through_episodes(self.paths)  # a dataset of dataloaders\n",
    "\n",
    "        self.traj_data_loader = DataLoader(  # only spit 1 episode a time\n",
    "            self.traj_dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=self.args.shuffle,\n",
    "            pin_memory=self.args.pin_memory,\n",
    "            drop_last=self.args.drop_last,\n",
    "            pin_memory_device=self.args.pin_memory_device,\n",
    "            )\n",
    "\n",
    "\n",
    "    def init_CL_sample_store(self,num_steps,total_agents,total_phases):\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.total_agents = total_agents\n",
    "        self.total_phases = total_phases\n",
    "        self.DT_input = {  # self.actor_config_dict['ob_space']\n",
    "                'timestep': torch.zeros((1,\n",
    "                                        ),requires_grad =False).to(self.device,\n",
    "                        dtype=torch.int),\n",
    "                'state': torch.zeros((1,\n",
    "                                     self.state_dim),requires_grad =False).to(self.device,dtype=torch.float32),\n",
    "                'action_1': torch.zeros((1,\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                'action_2': torch.zeros((1,\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                \n",
    "                'return_to_go': torch.ones((1,\n",
    "                                    ),requires_grad =False).to(self.device,dtype=torch.float32) * 110,\n",
    "                }            \n",
    "    \n",
    "        self.returntogo = torch.zeros((self.num_steps,\n",
    "                1),requires_grad =False).to(self.device,dtype=torch.float32)  # self.total_agents\n",
    "        self.returntogo_pred = torch.zeros((self.num_steps,\n",
    "                1)).to(self.device,dtype=torch.float32)  # self.total_agents\n",
    "\n",
    "    def update_CL_sample_store(\n",
    "        self,\n",
    "        curr_agent_,\n",
    "        inp={'step': None, 'act_2_1': [],'act_2_2': [], 'curr_reward_list': []},\n",
    "        before_action=True,\n",
    "        ):\n",
    "        self.DT_input['return_to_go'] = self.DT_input['return_to_go'] -    inp['curr_reward_list']  # [self.hero]\n",
    "        self.returntogo[inp['step']] = self.DT_input['return_to_go']\n",
    "\n",
    "\n",
    "    #rb = ReplayBuffer(\n",
    "    #    args.buffer_size,\n",
    "    #    envs.single_observation_space,\n",
    "    #    envs.single_action_space,\n",
    "    #    device,\n",
    "    #    handle_timeout_termination=False,\n",
    "    #)\n",
    "\n",
    "#real_next_obs = next_obs.copy()\n",
    "#rb.add(obs, real_next_obs, actions, rewards, terminations, infos)\n",
    "\n",
    "\n",
    "\n",
    "    def init_buffer(self,action_space,\n",
    "                    state_space=spaces_.Box(low=0,high=np.inf,shape=(#self.states.shape[1]\n",
    "                                                                     77,),dtype = np.float32)\n",
    "                    ,buffer_size = 30000):\n",
    "        action_space.dtype = np.float32\n",
    "        \n",
    "        self.rb = CustomReplayBuffer(\n",
    "                                    buffer_size,\n",
    "                                    state_space,\n",
    "                                    action_space,\n",
    "                                    self.device,\n",
    "                                    handle_timeout_termination=False,\n",
    "                                )\n",
    "    \n",
    "    def update_train_data(\n",
    "            self,\n",
    "            step_count,\n",
    "            obs,\n",
    "            ob_space_shape,\n",
    "            rewards_2,\n",
    "            dones_2,\n",
    "            actions_1,\n",
    "            actions_2,\n",
    "            log_probs_actions_2,\n",
    "            action_masks,\n",
    "            current_agent,\n",
    "            current_agent_acting,\n",
    "            current_phase,\n",
    "            current_troops_count,\n",
    "            map_agent_phase_vector\n",
    "            ):\n",
    "        \n",
    "\n",
    "        data_ = collections.defaultdict(torch.tensor)\n",
    "        #print(obs)\n",
    "        #print(obs[:step_count].reshape(-1,\n",
    "        #                            np.prod(ob_space_shape)))\n",
    "        \n",
    "        data_['observations'] =   obs[:step_count].reshape(-1,\n",
    "                                    np.prod(ob_space_shape))\n",
    "\n",
    "        data_['returntogo'] =      self.returntogo[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['returntogo_pred'] = self.returntogo_pred[:step_count]  # torch.tensor([1,2,3,4])\n",
    "\n",
    "        data_['rewards']   =       rewards_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['terminals'] =       dones_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['actions_1'] =       actions_1[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['actions_2'] =       actions_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['log_probs_actions_2'] =log_probs_actions_2[:step_count]\n",
    "        data_['action_masks'] =       action_masks[:step_count]\n",
    "        data_['current_agent_acting']=current_agent_acting[:step_count]\n",
    "        data_['current_agent_simple']=current_agent[:step_count]\n",
    "        data_['current_agent'] =      map_agent_phase_vector(current_agent[:step_count],\n",
    "                                   num_classes=self.total_agents + 1)[:, 1:]\n",
    "        data_['current_phase'] =      map_agent_phase_vector(current_phase[:step_count],\n",
    "                                   num_classes=self.total_phases)\n",
    "        data_['current_troops_count']=current_troops_count[:step_count]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        self.data_ = data_\n",
    "        hero_steps = data_['current_agent_simple'] == int(self)\n",
    "        self.data_['hero_steps'] = hero_steps\n",
    "        states = torch.cat((data_['observations'], data_['action_masks'] * hero_steps,\n",
    "                              data_['current_phase'], data_['current_agent'],\n",
    "                              data_['current_troops_count'][:, #:,\n",
    "                                                        None]), axis=1)#2)  # ,torch.ones(len(action_masks))[:,None]*self.hero\n",
    "\n",
    "        self.recalculate_rewards()\n",
    "        self.states = states.to(dtype=torch.float32)\n",
    "        data_['returns_to_go_cal'] = discount_cumsum(data_['rewards'], 0.99) / 1\n",
    "        data_['current_troops_count']=(data_['current_troops_count'] - 5.2496)/1.4733\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        data_['actions'] = torch.cat( (self.data_['actions_1'][:,None], \n",
    "                          self.data_['actions_2'][:,None]),axis =-1).to(dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        \n",
    "        for i in range(len(self.states)-1):\n",
    "            if hero_steps[i]:\n",
    "                self.rb.add(self.states[i], \n",
    "                       self.states[\n",
    "                       i+self.data_['t_pow'][i]], \n",
    "                       self.data_['actions'][i], \n",
    "                       self.data_['rewards_2'][i], \n",
    "                       self.data_['terminals_2'][i], \n",
    "                       self.data_['action_masks'][i],\n",
    "                       self.data_['t_pow'][i,None])\n",
    "        \n",
    "\n",
    "\n",
    "    def recalculate_rewards(self,gamma=0.99):\n",
    "\n",
    "\n",
    "        lis1 = []\n",
    "        lis2 = []\n",
    "        \n",
    "        self.data_['rewards_2'] = self.data_['rewards']*(self.data_['hero_steps'][:,0])\n",
    "        self.data_['t_pow'] = torch.ones_like(self.data_['rewards_2'],dtype =torch.int32)\n",
    "        for i,j in enumerate(self.data_['current_agent_simple'][:-1,0]):\n",
    "            if j != self.data_['current_agent_simple'][i+1]:\n",
    "                if j == 1:\n",
    "                    lis1.append(i+1)\n",
    "                if self.data_['current_agent_simple'][i+1]==1:\n",
    "                    lis2.append(i+1)\n",
    "                    \n",
    "        for i,j in zip(lis2,lis1):\n",
    "\n",
    "            ar = self.data_['rewards'][j:i]\n",
    "            self.data_['rewards_2'][j-1\n",
    "                        ] += ( ar*np.power([0.99],np.arange(len(ar)))).sum()\n",
    "            self.data_['t_pow'][j-1] = i-j+1+1\n",
    "\n",
    "        ar = self.data_['rewards'][lis1[-1]:] \n",
    "        self.data_['rewards_2'][lis1[-1]-1] = (ar*np.power([0.99],np.arange(len(ar)))).sum()\n",
    "\n",
    "        last = (len(self.data_['hero_steps'][:,0])-1 if self.data_['hero_steps'][-1,0]\n",
    "                else lis1[-1])\n",
    "        self.data_['terminals_2'] = np.arange(len(self.data_['hero_steps'][:,0]))==last\n",
    "        self.data_['t_pow'][lis1[-1]-1] = len(ar)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c99599d-2d5c-4007-bd00-fbcd066864b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#env.action_space(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a245bf-c571-4e36-8389-1aaeab8d0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_cumsum(x, gamma,Torch = True):\n",
    "    if Torch:\n",
    "        disc_cumsum = torch.zeros_like(x,dtype = torch.float32)\n",
    "    else:\n",
    "        disc_cumsum = np.zeros_like(x,dtype = np.float32)\n",
    "    \n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    #print(disc_cumsum[-1])\n",
    "    for t in reversed(range(x.shape[0]-1)):\n",
    "        disc_cumsum[t] = x[t] + gamma * disc_cumsum[t+1]\n",
    "        #print(x[t],disc_cumsum[t])\n",
    "    return disc_cumsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e76f6-d16d-4df8-9b10-4bb7b589e9f8",
   "metadata": {},
   "source": [
    "## DDPG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5fe8e3c-01ea-488f-9f7e-14b42ec68848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hero_agent_DDPG(memory_agent):\n",
    "    #def __init__(self):\n",
    "    #    super().__init__()\n",
    "\n",
    "    def set_device(self,device='cpu'):\n",
    "        self.device = device\n",
    "\n",
    "    def current_model_in(\n",
    "        self,\n",
    "        observation,\n",
    "        curr_agent,\n",
    "        phase_mapping,\n",
    "        curr_agent_mapping,\n",
    "        env_board_agents=[],\n",
    "        ):\n",
    "\n",
    "\n",
    "\n",
    "        #single obs\n",
    "        self.model_in =  torch.hstack((observation['observation'\n",
    "                         ].reshape(-1).to(self.device),\n",
    "                         torch.tensor(observation['action_mask'\n",
    "                         ].reshape(-1)).to(self.device) * (curr_agent\n",
    "                         == self), phase_mapping.to(self.device),\n",
    "                         curr_agent_mapping.to(self.device),\n",
    "                         ( (torch.tensor([env_board_agents[self].bucket]).to(self.device) - 5.2496)/1.4733\n",
    "                                      )))[None,\n",
    "                         :].float().requires_grad_(False).to(self.device)  \n",
    "    def init_model(self,actor_config_dict,args,device, writer,run_name,agent):\n",
    "\n",
    "        self.args = args\n",
    "        self.set_device(device)\n",
    "\n",
    "        self.state_dim = actor_config_dict['ob_space'] \n",
    "        self.act_dim = actor_config_dict['action_space']\n",
    "        \n",
    "        self.actor1 = ActorDiscrete(self.state_dim,self.act_dim).to(device)\n",
    "        self.actor2 = Actor(self.state_dim,self.act_dim).to(device)\n",
    "        \n",
    "        self.target_actor1 = ActorDiscrete(self.state_dim,self.act_dim).to(device)\n",
    "        self.target_actor1.load_state_dict(self.actor1.state_dict())\n",
    "        \n",
    "        self.target_actor2 = Actor(self.state_dim,self.act_dim).to(device)\n",
    "        self.target_actor2.load_state_dict(self.actor2.state_dict())\n",
    "        \n",
    "        self.qf1 = QNetwork(self.state_dim,2).to(device)\n",
    "        self.qf1_target = QNetwork(self.state_dim,2).to(device)\n",
    "        self.qf1_target.load_state_dict(self.qf1.state_dict())\n",
    "\n",
    "\n",
    "\n",
    "        self.init_model_config(writer=writer\n",
    "                            ,agent=agent\n",
    "                            ,run_name=run_name\n",
    "                            ,args=self.args)\n",
    "        self.init_optim()\n",
    "\n",
    "    def action_predict(self,data,mask=[],use_action_mask=False,no_grad = 1):\n",
    "        if no_grad==1:\n",
    "            with torch.no_grad():\n",
    "                a1 = self.actor1(data,action_mask=mask,use_action_mask=use_action_mask)\n",
    "                a2 = self.actor2(data,a1)\n",
    "                v = self.qf1(data,a1[:,None],a2)\n",
    "        elif no_grad ==2:\n",
    "            a1 = self.actor1(data,action_mask=mask,use_action_mask=use_action_mask)\n",
    "            a2 = self.actor2(data,a1.clone().detach())\n",
    "            v = self.qf1(data,a1[:,None],a2)\n",
    "            \n",
    "        else:\n",
    "            a1 = self.actor1(data)\n",
    "            a2 = self.actor2(data,a1)\n",
    "            v = self.qf1(data,a1[:,None],a2)\n",
    "\n",
    "        return a1,a2,v\n",
    "\n",
    "    def init_model_config(self,writer\n",
    "                            ,agent\n",
    "                            ,run_name\n",
    "                            ,args):\n",
    "        self.writer = writer\n",
    "        self.hero = agent\n",
    "        self.args = args\n",
    "        self.run_name = run_name\n",
    "        self.set_device(args['device']) # config['device']\n",
    "        self.n_blocks = args['model_config']['n_blocks']\n",
    "        self.embed_dim = args['model_config']['embed_dim']\n",
    "        self.context_len = args['model_config']['context_len']\n",
    "        self.n_heads = args['model_config']['n_heads']\n",
    "        self.dropout_p = args['model_config']['dropout_p']\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        self.num_steps = args['num_steps']\n",
    "        self.total_agents = args['total_agents']\n",
    "        self.total_phases = args['total_phases']\n",
    "\n",
    "        #init other dep\n",
    "        self.init_memory_config(args)\n",
    "        self.init_loss_config(args)\n",
    "        self.init_optim()\n",
    "\n",
    "\n",
    "    def init_memory_config(self,args):\n",
    "        self.rb_len = args['model_config']['rb_len']\n",
    "        self.chunk_size = args['model_config']['chunk_size']\n",
    "        self.chunk_overlap = args['model_config']['chunk_overlap']\n",
    "        \n",
    "    def init_loss_config(self,args):\n",
    "        self.lr = args['learning_rate']\n",
    "        self.warmup_epoch = args['model_config']['warmup_epoch']\n",
    "        self.total_epoch = args['model_config']['total_epoch']\n",
    "        self.initial_lr =  args['model_config']['initial_lr'] #5e-4\n",
    "        self.final_lr =  args['model_config']['final_lr'] #1e-6\n",
    "        \n",
    "        self.tau = args['model_config']['tau']        \n",
    "        self.beta = args['model_config']['beta']         #0.2 #Q_mse\n",
    "        self.alpha =args['model_config']['alpha']          #0.1  #actionloss\n",
    "        self.entropy_coeff = args['model_config']['entropy_coeff']         #0.1#0.5   #entropy loss in action\n",
    "        self.val_loss_coeff = args['model_config']['val_loss_coeff']        #0.5      #Q loss\n",
    "\n",
    "        self.gamma = args['gamma'] #0.99\n",
    "        self.policy_frequency = args['model_config']['policy_frequency'] #10\n",
    "        self.tau= args['model_config']['tau']#0.15\n",
    "\n",
    "                    \n",
    "    def init_optim(self):\n",
    "        \n",
    "        self.q_optimizer = optim.Adam(list(self.qf1.parameters()), lr=self.lr)\n",
    "        \n",
    "        self.actor1_optimizer = optim.Adam(list(self.actor1.parameters()), lr=self.lr)\n",
    "        self.actor2_optimizer = optim.Adam(list(self.actor2.parameters()), lr=self.lr)\n",
    "\n",
    "\n",
    "\n",
    "    def init_win_count_iter(self,agent_count):\n",
    "        self.count_dict = {i:0 for i in range(1,agent_count+1)}\n",
    "        self.count_draw_dict = {i:0 for i in range(1,agent_count+1)}\n",
    "        self.draw_territory_count = 0\n",
    "    \n",
    "    def init_move_count_epi(self,phases):\n",
    "        self.bad_move_count = 0\n",
    "        self.bad_move_phase_count = {i:0 for i in phases}\n",
    "        self.move_count =  {i:0 for i in phases}  \n",
    "    \n",
    "    def train_outer():\n",
    "        pass\n",
    "    \n",
    "    def train(self,epoch,iteration, batch_size = 100):\n",
    "\n",
    "        losses_ret =dict({})\n",
    "        data= self.rb.sample(batch_size)\n",
    "        with torch.no_grad():\n",
    "            next_state_actions1 = self.target_actor1(data.next_observations,action_mask=[],use_action_mask=False,give_prob=False)\n",
    "            next_state_actions2 = self.target_actor2(data.next_observations,\n",
    "                                                     next_state_actions1)\n",
    "            qf1_next_target = self.qf1_target(data.next_observations, next_state_actions1[:,None], next_state_actions2)\n",
    "            next_q_value = data.rewards.flatten() + (1 - data.dones.flatten()) * np.power(self.gamma,data.t_pow.flatten()) * (qf1_next_target).view(-1)\n",
    "\n",
    "        qf1_a_values = self.qf1(data.observations, data.actions[:,0,None], data.actions[:,1,None] ).view(-1)\n",
    "        qf1_loss = F.mse_loss(qf1_a_values, next_q_value)\n",
    "\n",
    "        # optimize the model\n",
    "        self.q_optimizer.zero_grad()\n",
    "        qf1_loss.backward()\n",
    "        self.q_optimizer.step()\n",
    "        print('epoch',epoch,'qf1_loss',qf1_loss)\n",
    "        \n",
    "        losses_ret['Q_loss'] = qf1_loss.item()\n",
    "        losses_ret['action_loss_cal'] = False\n",
    "        losses_ret['qf1_values'] = qf1_a_values.mean().item()\n",
    "\n",
    "        if epoch % self.policy_frequency == 0:\n",
    "            \n",
    "            acts_1 = self.actor1(data.observations,action_mask=data.mask,use_action_mask=True,give_prob=False).to(dtype=torch.float32)\n",
    "            acts_2 = self.actor2(data.observations,acts_1)\n",
    "            print(data.observations.dtype,acts_1.dtype,acts_2.dtype)\n",
    "            actor_loss = -self.qf1(data.observations, acts_1[:,None], acts_2#.to(dtype=float)\n",
    "                                  ).mean()\n",
    "            self.actor1_optimizer.zero_grad()\n",
    "            \n",
    "            actor_loss.backward(retain_graph=True)\n",
    "            self.actor1_optimizer.step()\n",
    "\n",
    "            self.actor2_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            \n",
    "            self.actor2_optimizer.step()\n",
    "\n",
    "            print('actor_loss',actor_loss)\n",
    "            losses_ret['action_loss_cal'] = True\n",
    "            losses_ret['policy_loss'] = actor_loss.item()\n",
    "            \n",
    "            # update the target network\n",
    "            for param, target_param in zip(self.actor1.parameters(), self.target_actor1.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "            for param, target_param in zip(self.actor2.parameters(), self.target_actor2.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "            \n",
    "            for param, target_param in zip(self.qf1.parameters(), self.qf1_target.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "\n",
    "        return losses_ret\n",
    "\n",
    "    def write_learning(self,episode,losses):\n",
    "        \n",
    "        for i in losses:\n",
    "            self.writer.add_scalar(\"charts/Q_learning_rate\", self.q_optimizer.param_groups[0][\"lr\"], episode)   \n",
    "            self.writer.add_scalar(\"charts/A1_learning_rate_value\", self.actor1_optimizer.param_groups[0][\"lr\"], episode)   \n",
    "            self.writer.add_scalar(\"charts/A2_learning_rate_value\", self.actor2_optimizer.param_groups[0][\"lr\"], episode) \n",
    "\n",
    "            #self.writer.add_scalar(\"total_loss\", np.mean(total_loss_list), episode)\n",
    "            #self.writer.add_scalar(\"Q_TD\", np.mean(Q_TD_list), episode)\n",
    "            self.writer.add_scalar(\"losses/qf1_values\", losses['qf1_values'], episode)\n",
    "            self.writer.add_scalar(\"losses/Q_loss\", losses['Q_loss'], episode)\n",
    "            if losses['action_loss_cal']:\n",
    "                self.writer.add_scalar(\"losses/policy_loss\", losses['policy_loss'], episode)\n",
    "\n",
    "\n",
    "\n",
    "#a = Hero_agent_DDQN(1)\n",
    "#a.init_properties(3,[1,2,3],cp=[1],df=[2])\n",
    "#a.set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bacd4-9274-4421-a6b6-0d687940cba7",
   "metadata": {},
   "source": [
    "## A2C agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b507cbff-7442-4e06-a2f3-e9260ba715ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hero_agent_A2C(Hero_agent_DDPG):\n",
    "    def init_model(self,actor_config_dict,args,device, writer,run_name,agent):\n",
    "\n",
    "        self.args = args\n",
    "        self.set_device(device)\n",
    "        self.entropy_coefficient = args['entropy_coefficient']\n",
    "        self.max_grad_norm = args['max_grad_norm'] #0.5 # Example max_norm value\n",
    "\n",
    "        self.state_dim = actor_config_dict['ob_space'] \n",
    "        self.act_dim = actor_config_dict['action_space']\n",
    "\n",
    "        self.actor1 = PG_ActorDiscrete(self.state_dim,self.act_dim).to(device)\n",
    "        self.actor2 = PG_Actor(self.state_dim,self.act_dim).to(device)\n",
    "        \n",
    "        self.qf1 = PG_ValueNetwork(self.state_dim).to(device) # Value network 1\n",
    "        self.qf2 = PG_ValueNetwork(self.state_dim).to(device) # Value network 2 (optional, you might use only one in A2C)\n",
    "\n",
    "\n",
    "\n",
    "        #self.gamma = gamma\n",
    "        #self.policy_frequency = policy_frequency\n",
    "        #self.tau = tau # Tau is not really used in typical A2C, can be removed or ignored\n",
    "        #self.rb = rb # Replay buffer is NOT used in standard A2C, but you might use it for batching on-policy data\n",
    "        \n",
    "\n",
    "        self.init_model_config(writer=writer\n",
    "                            ,agent=agent\n",
    "                            ,run_name=run_name\n",
    "                            ,args=self.args)\n",
    "        self.init_optim()\n",
    "\n",
    "    def init_optim(self):\n",
    "\n",
    "        self.actor1_optimizer = optim.Adam(list(self.actor1.parameters()), lr=self.lr)\n",
    "        self.actor2_optimizer = optim.Adam(list(self.actor2.parameters()), lr=self.lr)\n",
    "        self.q1_optimizer = optim.Adam(list(self.qf1.parameters()), lr=self.lr) # Value network optimizer\n",
    "        self.q2_optimizer = optim.Adam(list(self.qf2.parameters()), lr=self.lr) # Value network 2 optimizer (optional)\n",
    "\n",
    "\n",
    "    def action_predict(self,data,mask=[],use_action_mask=False,no_grad = 1):\n",
    "        if no_grad==1:\n",
    "            with torch.no_grad():\n",
    "                a1 = self.actor1(data,action_mask=mask,use_action_mask=use_action_mask)\n",
    "                a2 = self.actor2(data,a1)\n",
    "                v = self.qf1(data)\n",
    "        elif no_grad ==2:\n",
    "            a1 = self.actor1(data,action_mask=mask,use_action_mask=use_action_mask)\n",
    "            a2 = self.actor2(data,a1.clone().detach())\n",
    "            v = self.qf1(data)\n",
    "            \n",
    "        else:\n",
    "            a1 = self.actor1(data)\n",
    "            a2 = self.actor2(data,a1)\n",
    "            v = self.qf1(data)\n",
    "\n",
    "        return a1,a2,v\n",
    "\n",
    "    def train(self,epoch,iteration, batch_size = 100):\n",
    "\n",
    "        losses_ret =dict({})\n",
    "        data= self.rb.sample(batch_size)\n",
    "\n",
    "        # 1. Calculate Value (Critic) Loss\n",
    "        value_1_predicted = self.qf1(data.observations).view(-1) # Value prediction from critic 1\n",
    "        #value_2_predicted = self.q2(data.observations).view(-1) # If you have a second critic\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_state_value_1 = self.qf1(data.next_observations).view(-1) # Value of next state from critic 1\n",
    "            #next_state_value_2 = self.critic2(data.next_observations).view(-1) # Value of next state from critic 2\n",
    "\n",
    "            # TD Target: reward + gamma * V(next_state)\n",
    "            value_target = data.rewards.flatten() + (1 - data.dones.flatten()) * np.power(self.gamma,data.t_pow.flatten()) * next_state_value_1 # Using critic 1 for target\n",
    "            # You could average targets from critic 1 and 2 if you have two critics, or just use one.\n",
    "\n",
    "        #qf1_a_values = self.qf1(data.observations).view(-1)\n",
    "        qf1_loss = F.mse_loss(value_1_predicted, value_target) # Value loss for critic 1\n",
    "        # qf2_loss = F.mse_loss(value_2_predicted, value_target) # Value loss for critic 2 (if you have critic 2)\n",
    "\n",
    "        # optimize the model\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        \n",
    "        qf1_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.qf1.parameters(), self.max_grad_norm)\n",
    "        self.q1_optimizer.step()\n",
    "        print('epoch',epoch,'qf1_loss',qf1_loss)\n",
    "        \n",
    "        losses_ret['Q_loss'] = qf1_loss.item()\n",
    "        losses_ret['action_loss_cal'] = False\n",
    "        losses_ret['qf1_values'] = value_1_predicted.mean().item()\n",
    "\n",
    "        if epoch % self.policy_frequency == 0:\n",
    "            \n",
    "            probs_actor1, acts_1 = self.actor1(data.observations,action_mask=data.mask,use_action_mask=True,give_prob=True)\n",
    "            acts_1=acts_1.to(dtype=torch.float32)\n",
    "            acts_2,entropy_actor_2 = self.actor2(data.observations,acts_1,give_dis= False, give_entropy=True)\n",
    "            \n",
    "            #entropy_loss\n",
    "            entropy_actor_1 = -torch.sum(probs_actor1 * torch.log(probs_actor1 + 1e-9), dim=-1)\n",
    "            \n",
    "            #print(data.observations.dtype,acts_1.dtype,acts_2.dtype)\n",
    "            #actor_loss = -self.qf1(data.observations, acts_1[:,None], acts_2#.to(dtype=float)\n",
    "            #                      ).mean()\n",
    "            \n",
    "            # Calculate Advantage (TD Error) - using critic 1 value function\n",
    "            advantage = value_target - value_1_predicted.detach() # Detach V-values to prevent gradient flow through critic in actor loss\n",
    "\n",
    "            \n",
    "            # Calculate Policy Loss (Policy Gradient with Advantage)\n",
    "            # Assuming your actor outputs *log probabilities* or probabilities directly.\n",
    "            # You will need to adapt this based on how your actor networks are set up\n",
    "            log_probs_action1 = self.actor1.get_logprob(data.observations, acts_1, action_mask=data.mask, use_action_mask=True) # Get log prob of taken actions under current policy\n",
    "            log_probs_action2 = self.actor2.get_logprob(data.observations, acts_2, acts_1) # Get log prob of taken actions under current policy\n",
    "\n",
    "            \n",
    "            \n",
    "            # Policy Loss (maximize expected return = maximize log_prob * advantage)\n",
    "            actor_loss_1 = (-log_probs_action1 * advantage - self.entropy_coefficient * entropy_actor_1).mean() # Policy loss for actor 1\n",
    "            actor_loss_2 = (-log_probs_action2 * advantage - self.entropy_coefficient * entropy_actor_2).mean() # Policy loss for actor 2\n",
    "\n",
    "            # Optimize Actors (Policy Networks)\n",
    "            self.actor1_optimizer.zero_grad()\n",
    "            actor_loss_1.backward(retain_graph=True) # Retain graph if actor2 loss depends on actor1 computation\n",
    "            torch.nn.utils.clip_grad_norm_(self.actor1.parameters(), self.max_grad_norm)\n",
    "            self.actor1_optimizer.step()\n",
    "\n",
    "            self.actor2_optimizer.zero_grad()\n",
    "            actor_loss_2.backward() # No retain_graph needed now\n",
    "            torch.nn.utils.clip_grad_norm_(self.actor2.parameters(), self.max_grad_norm)\n",
    "            self.actor2_optimizer.step()\n",
    "\n",
    "            \n",
    "            \n",
    "            print('actor_loss_1',actor_loss_1.item(), 'actor_loss_2', actor_loss_2.item()) # Renamed loss print\n",
    "            losses_ret['Policy_loss_1'] = actor_loss_1.item() # Renamed loss keys\n",
    "            losses_ret['Policy_loss_2'] = actor_loss_2.item()\n",
    "            losses_ret['action_loss_cal'] = True\n",
    "            \n",
    "        return losses_ret\n",
    "        \n",
    "    def write_learning(self,episode,losses):\n",
    "        \n",
    "\n",
    "        self.writer.add_scalar(\"charts/Q_learning_rate\", self.q1_optimizer.param_groups[0][\"lr\"], episode)   \n",
    "        self.writer.add_scalar(\"charts/A1_learning_rate_value\", self.actor1_optimizer.param_groups[0][\"lr\"], episode)   \n",
    "        self.writer.add_scalar(\"charts/A2_learning_rate_value\", self.actor2_optimizer.param_groups[0][\"lr\"], episode) \n",
    "\n",
    "        #self.writer.add_scalar(\"total_loss\", np.mean(total_loss_list), episode)\n",
    "        #self.writer.add_scalar(\"Q_TD\", np.mean(Q_TD_list), episode)\n",
    "        self.writer.add_scalar(\"losses/qf1_values\", losses['qf1_values'], episode)\n",
    "        self.writer.add_scalar(\"losses/Q_loss\", losses['Q_loss'], episode)\n",
    "        if losses['action_loss_cal']:\n",
    "            self.writer.add_scalar(\"losses/policy_loss1\", losses['Policy_loss_1'], episode)\n",
    "            self.writer.add_scalar(\"losses/policy_loss2\", losses['Policy_loss_2'], episode)\n",
    "        #self.writer.add_scalar(\"policy_loss\", np.mean(policy_loss_list), episode)    \n",
    "                \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a35b0d-2f4e-43a6-821e-4b4ac288ad0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c30e5b2-ff86-4396-8c6f-0fe76b613ffe",
   "metadata": {},
   "source": [
    "## PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "befe8cda-df14-491e-923b-aba4fc3a4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hero_agent_PPO(Hero_agent_A2C):\n",
    "    def init_model(self,actor_config_dict,args,device, writer,run_name,agent):\n",
    "\n",
    "        self.args = args\n",
    "        self.set_device(device)\n",
    "        self.entropy_coefficient = args['entropy_coefficient']\n",
    "        self.max_grad_norm = args['max_grad_norm']\n",
    "\n",
    "        self.clip_param = args['clip_param'] # 0.1\n",
    "        self.state_dim = actor_config_dict['ob_space'] \n",
    "        self.act_dim = actor_config_dict['action_space']\n",
    "\n",
    "        self.actor1 = PG_ActorDiscrete(self.state_dim,self.act_dim).to(device)\n",
    "        self.actor2 = PG_Actor(self.state_dim,self.act_dim).to(device)\n",
    "        \n",
    "        self.qf1 = PG_ValueNetwork(self.state_dim).to(device) # Value network 1\n",
    "        self.qf2 = PG_ValueNetwork(self.state_dim).to(device) # Value network 2 (optional, you might use only one in A2C)\n",
    "\n",
    "\n",
    "        self.policy_old_actor1 = PG_ActorDiscrete(self.state_dim,self.act_dim).to(device) # Create old policy networks (actor1, actor2) - initialize with current policy\n",
    "        self.policy_old_actor2 = PG_Actor(self.state_dim,self.act_dim).to(device)\n",
    "        self.policy_old_actor1.load_state_dict(self.actor1.state_dict()) # Load initial weights from current policy\n",
    "        self.policy_old_actor2.load_state_dict(self.actor2.state_dict())\n",
    "\n",
    "        \n",
    "\n",
    "        #self.gamma = gamma\n",
    "        #self.policy_frequency = policy_frequency\n",
    "        #self.tau = tau # Tau is not really used in typical A2C, can be removed or ignored\n",
    "        #self.rb = rb # Replay buffer is NOT used in standard A2C, but you might use it for batching on-policy data\n",
    "        \n",
    "\n",
    "        self.init_model_config(writer=writer\n",
    "                            ,agent=agent\n",
    "                            ,run_name=run_name\n",
    "                            ,args=self.args)\n",
    "        self.init_optim()\n",
    "\n",
    "    def init_optim(self):\n",
    "\n",
    "        self.actor1_optimizer = optim.Adam(list(self.actor1.parameters()), lr=self.lr)\n",
    "        self.actor2_optimizer = optim.Adam(list(self.actor2.parameters()), lr=self.lr)\n",
    "        self.q1_optimizer = optim.Adam(list(self.qf1.parameters()), lr=self.lr) # Value network optimizer\n",
    "        self.q2_optimizer = optim.Adam(list(self.qf2.parameters()), lr=self.lr) # Value network 2 optimizer (optional)\n",
    "\n",
    "\n",
    "    def action_predict(self,data,mask=[],use_action_mask=False,no_grad = 1):\n",
    "        if no_grad==1:\n",
    "            with torch.no_grad():\n",
    "                a1 = self.actor1(data,action_mask=mask,use_action_mask=use_action_mask)\n",
    "                a2 = self.actor2(data,a1)\n",
    "                v = self.qf1(data)\n",
    "        elif no_grad ==2:\n",
    "            a1 = self.actor1(data,action_mask=mask,use_action_mask=use_action_mask)\n",
    "            a2 = self.actor2(data,a1.clone().detach())\n",
    "            v = self.qf1(data)\n",
    "            \n",
    "        else:\n",
    "            a1 = self.actor1(data)\n",
    "            a2 = self.actor2(data,a1)\n",
    "            v = self.qf1(data)\n",
    "\n",
    "        return a1,a2,v\n",
    "\n",
    "    def train(self,epoch,iteration, batch_size = 100):\n",
    "\n",
    "        losses_ret =dict({})\n",
    "        data= self.rb.sample(batch_size)\n",
    "\n",
    "        # 1. Calculate Value (Critic) Loss\n",
    "        value_1_predicted = self.qf1(data.observations).view(-1) # Value prediction from critic 1\n",
    "        #value_2_predicted = self.q2(data.observations).view(-1) # If you have a second critic\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_state_value_1 = self.qf1(data.next_observations).view(-1) # Value of next state from critic 1\n",
    "            #next_state_value_2 = self.critic2(data.next_observations).view(-1) # Value of next state from critic 2\n",
    "\n",
    "            # TD Target: reward + gamma * V(next_state)\n",
    "            value_target = data.rewards.flatten() + (1 - data.dones.flatten()) * np.power(self.gamma,data.t_pow.flatten()) * next_state_value_1 # Using critic 1 for target\n",
    "            # You could average targets from critic 1 and 2 if you have two critics, or just use one.\n",
    "\n",
    "        #qf1_a_values = self.qf1(data.observations).view(-1)\n",
    "        qf1_loss = F.mse_loss(value_1_predicted, value_target) # Value loss for critic 1\n",
    "        # qf2_loss = F.mse_loss(value_2_predicted, value_target) # Value loss for critic 2 (if you have critic 2)\n",
    "\n",
    "        # optimize the model\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        qf1_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.qf1.parameters(), self.max_grad_norm)\n",
    "        self.q1_optimizer.step()\n",
    "        print('epoch',epoch,'qf1_loss',qf1_loss)\n",
    "        \n",
    "        losses_ret['Q_loss'] = qf1_loss.item()\n",
    "        losses_ret['action_loss_cal'] = False\n",
    "        losses_ret['qf1_values'] = value_1_predicted.mean().item()\n",
    "\n",
    "        if epoch % self.policy_frequency == 0:\n",
    "\n",
    "            acts_1 = data.actions[:,0]\n",
    "            acts_2 = data.actions[:,1]\n",
    "            # IAM HEREEEeeeeeeee \n",
    "            #-------------------\n",
    "            \n",
    "            \n",
    "            # Calculate Advantage (TD Error) - using critic 1 value function\n",
    "            advantage = value_target - value_1_predicted.detach() # Detach V-values to prevent gradient flow through critic in actor loss\n",
    "            \n",
    "            #not using it not sure how it effects in highly non-stationary events.\n",
    "            #advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8) # Optional: Advantage normalization (can help stability)\n",
    "            \n",
    "            # Get log probs of *old* actions under *old* policy\n",
    "            log_probs_old_action1 = self.policy_old_actor1.get_logprob(data.observations, acts_1, action_mask=data.mask, use_action_mask=True).detach() # Detach old log probs - these are constants for optimization\n",
    "            log_probs_old_action2 = self.policy_old_actor2.get_logprob(data.observations, acts_2, acts_1).detach() # Detach old log probs\n",
    "\n",
    "            # Calculate Policy Loss (Policy Gradient with Advantage)\n",
    "            # Assuming your actor outputs *log probabilities* or probabilities directly.\n",
    "            # You will need to adapt this based on how your actor networks are set up\n",
    "            log_probs_current_action1 = self.actor1.get_logprob(data.observations, acts_1, action_mask=data.mask, use_action_mask=True) # Get log prob of taken actions under current policy\n",
    "            log_probs_current_action2 = self.actor2.get_logprob(data.observations, acts_2, acts_1) # Get log prob of taken actions under current policy\n",
    "\n",
    "            # Calculate probability ratio (current policy prob / old policy prob) - in log space, this is exp(log_prob_current - log_prob_old)\n",
    "            ratio1 = torch.exp(log_probs_current_action1 - log_probs_old_action1)\n",
    "            ratio2 = torch.exp(log_probs_current_action2 - log_probs_old_action2)\n",
    "\n",
    "\n",
    "            # Calculate Surrogate Objective (unclipped)\n",
    "            surr1 = ratio1 * advantage\n",
    "            surr2 = ratio2 * advantage\n",
    "\n",
    "            # Calculate Clipped Surrogate Objective\n",
    "            clip_param = self.clip_param\n",
    "            ratio1_clipped = torch.clamp(ratio1, 1 - clip_param, 1 + clip_param)\n",
    "            ratio2_clipped = torch.clamp(ratio2, 1 - clip_param, 1 + clip_param)\n",
    "\n",
    "            surr1_clipped = ratio1_clipped * advantage\n",
    "            surr2_clipped = ratio2_clipped * advantage\n",
    "\n",
    "\n",
    "            #calculating act\n",
    "            probs_actor1, acts_1 = self.actor1(data.observations,action_mask=data.mask,use_action_mask=False,give_prob=True)\n",
    "            acts_1=acts_1.to(dtype=torch.float32)\n",
    "            acts_2,entropy_actor_2 = self.actor2(data.observations,acts_1,give_dis= False, give_entropy=True)\n",
    "\n",
    "            #entropy_loss\n",
    "            entropy_actor_1 = -torch.sum(probs_actor1 * torch.log(probs_actor1 + 1e-9), dim=-1)\n",
    "            \n",
    "            # PPO Policy Loss - minimize the *negative* of the clipped surrogate objective (we want to *maximize* the objective)\n",
    "            actor_loss_1 = (-torch.min(surr1, surr1_clipped) - self.entropy_coefficient * entropy_actor_1).mean()\n",
    "            actor_loss_2 = (-torch.min(surr2, surr2_clipped) - self.entropy_coefficient * entropy_actor_2).mean()\n",
    "\n",
    "\n",
    "            # Optimize Actors (Policy Networks)\n",
    "            self.actor1_optimizer.zero_grad()\n",
    "            actor_loss_1.backward(retain_graph=True) # Retain graph if actor2 loss depends on actor1 computation\n",
    "            torch.nn.utils.clip_grad_norm_(self.actor1.parameters(), self.max_grad_norm)\n",
    "            self.actor1_optimizer.step()\n",
    "\n",
    "            self.actor2_optimizer.zero_grad()\n",
    "            actor_loss_2.backward() # No retain_graph needed now\n",
    "            torch.nn.utils.clip_grad_norm_(self.actor2.parameters(), self.max_grad_norm)\n",
    "            self.actor2_optimizer.step()\n",
    "            \n",
    "\n",
    "            # update the target network\n",
    "            for param, target_param in zip(self.actor1.parameters(), self.policy_old_actor1.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "            for param, target_param in zip(self.actor2.parameters(), self.policy_old_actor2.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "            \n",
    "            \n",
    "            print('actor_loss_1',actor_loss_1.item(), 'actor_loss_2', actor_loss_2.item()) # Renamed loss print\n",
    "            losses_ret['Policy_loss_1'] = actor_loss_1.item() # Renamed loss keys\n",
    "            losses_ret['Policy_loss_2'] = actor_loss_2.item()\n",
    "            losses_ret['action_loss_cal'] = True\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        return losses_ret\n",
    "        \n",
    "    def write_learning(self,episode,losses):\n",
    "        \n",
    "\n",
    "        self.writer.add_scalar(\"charts/Q_learning_rate\", self.q1_optimizer.param_groups[0][\"lr\"], episode)   \n",
    "        self.writer.add_scalar(\"charts/A1_learning_rate_value\", self.actor1_optimizer.param_groups[0][\"lr\"], episode)   \n",
    "        self.writer.add_scalar(\"charts/A2_learning_rate_value\", self.actor2_optimizer.param_groups[0][\"lr\"], episode) \n",
    "\n",
    "        #self.writer.add_scalar(\"total_loss\", np.mean(total_loss_list), episode)\n",
    "        #self.writer.add_scalar(\"Q_TD\", np.mean(Q_TD_list), episode)\n",
    "        self.writer.add_scalar(\"losses/qf1_values\", losses['qf1_values'], episode)\n",
    "        self.writer.add_scalar(\"losses/Q_loss\", losses['Q_loss'], episode)\n",
    "        if losses['action_loss_cal']:\n",
    "            self.writer.add_scalar(\"losses/policy_loss1\", losses['Policy_loss_1'], episode)\n",
    "            self.writer.add_scalar(\"losses/policy_loss2\", losses['Policy_loss_2'], episode)\n",
    "        #self.writer.add_scalar(\"policy_loss\", np.mean(policy_loss_list), episode)    \n",
    "                \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4bb7c-9c02-4831-9c3c-6ce261896d31",
   "metadata": {},
   "source": [
    "## Model_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0013a7c8-bd0b-4fa0-b3a8-3c152c42b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mapper(i,k,lookup={'DDPG':Hero_agent_DDPG,'A2C':Hero_agent_A2C,'PPO':Hero_agent_PPO}):\n",
    "    return lookup[k[i]](i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcf599-470d-4218-8f0c-56e1deb2f429",
   "metadata": {},
   "source": [
    "# Sample and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9a953acb-43d2-46e3-a99a-3152a2ae1a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 7],\n",
       "       [2, 1],\n",
       "       [2, 1],\n",
       "       [2, 5],\n",
       "       [0, 0],\n",
       "       [2, 1],\n",
       "       [2, 2],\n",
       "       [2, 2],\n",
       "       [2, 5],\n",
       "       [2, 2]], dtype=int32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_.last()[0]['observation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d236725f-19f5-4718-9ab9-f18ea85f8d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 2],\n",
       "       [1, 8],\n",
       "       [2, 1],\n",
       "       [2, 5],\n",
       "       [2, 3],\n",
       "       [3, 2],\n",
       "       [4, 5],\n",
       "       [5, 6],\n",
       "       [5, 2],\n",
       "       [5, 4],\n",
       "       [6, 7],\n",
       "       [6, 5],\n",
       "       [7, 8],\n",
       "       [7, 6],\n",
       "       [8, 9],\n",
       "       [8, 1],\n",
       "       [8, 7],\n",
       "       [9, 8]], dtype=int8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_.board.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9190540-c832-4091-bd75-398cd7df075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha =0.2\n",
    "list_ = [1]\n",
    "for i in range(100):\n",
    "    list_.append(list_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "16227f70-a921-4442-be29-329dc19f724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_.possible_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "33b4d933-0440-48a9-bfb7-a326362bc6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([0.1,0.2,0.3])).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "71738b41-5d1a-46f7-8fe2-52aeb9551466",
   "metadata": {},
   "outputs": [],
   "source": [
    "kj = 1\n",
    "alp = 0.01\n",
    "\n",
    "kj_ = [kj]\n",
    "\n",
    "adder = [0.1,0.2,0.3]\n",
    "\n",
    "for i in range(1000):\n",
    "    kj = (1-alp)*kj + alp*np.random.choice(adder)\n",
    "    kj_.append(kj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "535b5e48-c419-4eda-b31c-7354b45b0143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation': array([[2, 7],\n",
       "        [2, 1],\n",
       "        [2, 1],\n",
       "        [2, 5],\n",
       "        [0, 0],\n",
       "        [2, 1],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 5],\n",
       "        [2, 2]], dtype=int32),\n",
       " 'action_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int8)}"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_.last()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "a92c2281-db56-4b63-97a7-cfd143da1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Personality_bot(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.personalty_alpha = {1:0.2, 2:0.2, 3:0.2} # this defined the horizon of rememberance\n",
    "        self.base_prob = {1:0.1, 2:0.1, 3:0.2}\n",
    "        self.a= 1\n",
    "        self.agent_history = { i:{ j:{ 'attacked_me':0,\n",
    "                                      #'i_attacked_you':0,\n",
    "                                      'neighbour_cooperate':0} for j in env_.possible_agents if j !=i } for i in env_.possible_agents}\n",
    "        self.attack_count = {j:0 for j in env_.possible_agents }\n",
    "\n",
    "        self.relation = { i:{ j:0.5 for j in env_.possible_agents if j !=i } for i in env_.possible_agents}\n",
    "\n",
    "\n",
    "        self.relation_tracker = dict({})\n",
    "        self.relation_tracker_list = []\n",
    "\n",
    "    def relation_recorder(self,list_ = False):\n",
    "\n",
    "        if list_:\n",
    "            self.relation_tracker_list.append(self.relation)\n",
    "        else:\n",
    "            for i in self.relation:\n",
    "                for j in self.relation[i]:\n",
    "                    if (i,j) not in self.relation_tracker:\n",
    "                        self.relation_tracker[(i,j)] = [self.relation[i][j]]\n",
    "                    else:\n",
    "                        self.relation_tracker[(i,j)].append(self.relation[i][j])\n",
    "\n",
    "        \n",
    "\n",
    "    def update_relation(self,agent2,agent1,attack=0):\n",
    "        self.relation[agent1][agent2] = (1- self.personalty_alpha[agent1])*self.relation[agent1][agent2] + self.personalty_alpha[agent1]*attack\n",
    "    \n",
    "    def update_history(self,observation,env,agent,action):\n",
    "        self.attack_count[agent] +=1\n",
    "\n",
    "        if observation['action_mask'][action] and action<30:\n",
    "\n",
    "            agent_b = self.update_history_attacker(env,observation,agent,action)\n",
    "    \n",
    "    \n",
    "            pos_ag = set(env.possible_agents) - {agent_b,agent }\n",
    "            \n",
    "            for j,k in env.board.edges:\n",
    "                if env.board.agents[env.board.territories[j][0]] == agent:\n",
    "                    other_ag =env.board.agents[env.board.territories[k][0]]\n",
    "                    for i in list(pos_ag):\n",
    "                        if i == other_ag:\n",
    "                            self.agent_history[other_ag][agent]['neighbour_cooperate']+=1\n",
    "                            self.update_relation(agent,other_ag,attack=0)\n",
    "                            pos_ag -= {other_ag}\n",
    "                if len(pos_ag) == 0:\n",
    "                    break\n",
    "        \n",
    "        self.relation_recorder() # the history has to be updated for every attacker.\n",
    "\n",
    "    def print_relation(self):\n",
    "\n",
    "        print('relation',self.relation)\n",
    "        \n",
    "        for i in env_.possible_agents:\n",
    "            for j in env_.possible_agents:\n",
    "                if j !=i:\n",
    "                    sum_ = sum(self.agent_history[j][i].values())\n",
    "                    if sum_>0:\n",
    "                        print(j,i,self.agent_history[j][i]['attacked_me']/sum_ )\n",
    "                    else:\n",
    "                        print(j,i,0)\n",
    "\n",
    "\n",
    "    def update_history_attacker(self,env,observation,agent,action):\n",
    "        #print(action,action, (len(env.board.edges) - env.board.territory_count))\n",
    "        if (action - env.board.territory_count)< (len(env.board.edges) ):\n",
    "            #print('action',action,action-env.board.territory_count,)\n",
    "            edge = env.board.edges[action-env.board.territory_count]\n",
    "            \n",
    "            \n",
    "            #territory_a = env.board.territories[edge[0]]\n",
    "            #territory_b = env.board.territories[edge[1]]\n",
    "\n",
    "\n",
    "            territory_a = (observation['observation'][edge[0]])\n",
    "            territory_b = (observation['observation'][edge[1]])\n",
    "            \n",
    "            #agent_a = env.board.agents[territory_a[0]] \n",
    "            \n",
    "            agent_b = env.board.agents[territory_b[0]]\n",
    "\n",
    "            #print('territory',territory_b[0],observation['observation'][env.board.edges[action-env.board.territory_count+1][1]] )\n",
    "            #print('edge',agent_b)\n",
    "            \n",
    "            #if agent_b !=0:\n",
    "                \n",
    "                #print('obs',observation)\n",
    "                #print('territory',territory_a,territory_b)\n",
    "                #print('agb',agent_b)\n",
    "            if agent_b in env.possible_agents:\n",
    "                #print(agent_b,agent)\n",
    "                self.agent_history[agent_b][agent]['attacked_me']+=1\n",
    "                self.update_relation(agent,agent_b,attack=1)\n",
    "            return agent_b\n",
    "        else:\n",
    "            #print('prob',agent,action)\n",
    "            return -1\n",
    "\n",
    "    def define_mask_prob(self,env,agent,observation):\n",
    "        action_mask = observation['action_mask'][env.board.territory_count:-2]\n",
    "\n",
    "\n",
    "        \n",
    "        #setting_base\n",
    "        if sum(action_mask)>0:\n",
    "            players = observation['observation'][:,0][env.board.edges[:,1]]\n",
    "    \n",
    "            action_mask_prob = ((~np.isin(players, env.possible_agents))*action_mask)*self.base_prob[agent]\n",
    "\n",
    "            #print(type(action_mask_prob),type(observation['observation'][:,0][env.board.edges[:,1]] ),type(action_mask),type(self.relation[agent]))\n",
    "            for i in (set(env.possible_agents) - {agent }):\n",
    "                action_mask_prob+=(observation['observation'][:,0][env.board.edges[:,1]]== i )*action_mask*self.relation[agent][i]\n",
    "    \n",
    "            action_mask_prob = np.append(action_mask_prob,[self.base_prob[agent],self.base_prob[agent]])\n",
    "            action_mask_prob = np.append(observation['action_mask'][:env.board.territory_count],action_mask_prob)\n",
    "            #print(len(action_mask_prob),len(observation['action_mask']))\n",
    "    \n",
    "            #print('before',action_mask_prob)\n",
    "            action_mask_prob = np.where((action_mask_prob<self.base_prob[agent]) & (action_mask_prob>0)\n",
    "                                        \n",
    "                                        , \n",
    "                                        \n",
    "                                        self.base_prob[agent], \n",
    "                                        \n",
    "                                        action_mask_prob)\n",
    "    \n",
    "            #print('after',action_mask_prob)\n",
    "        else:\n",
    "            action_mask_prob=observation['action_mask']*self.base_prob[agent]*0.9\n",
    "            players = [0]\n",
    "        return action_mask_prob/sum(action_mask_prob), players        \n",
    "        \n",
    "    def agent_action(self, observation, reward, termination, truncation, info, phase, troops,env,agent,device='cpu'):\n",
    "        \n",
    "        action = env.action_space(agent).sample()                        \n",
    "        #part_0 =np.random.choice(np.where(env.board.calculated_action_mask(agent))[0])\n",
    "\n",
    "        id_ = np.where(observation['action_mask'])[0]\n",
    "        if phase == 1:\n",
    "            \n",
    "            probs,players = self.define_mask_prob(env,agent,observation)\n",
    "            probs = probs[id_]\n",
    "            #print(id_)\n",
    "            #print(probs)\n",
    "            \n",
    "            part_0 =np.random.choice(id_,p=probs)\n",
    "            #print('action',part_0)\n",
    "            if part_0<30:\n",
    "                print(agent,'attacking',players[part_0 - env.board.territory_count] )\n",
    "        else:\n",
    "            part_0 =np.random.choice(id_)\n",
    "        action = torch.tensor([\n",
    "                                [\n",
    "                                 [part_0],\n",
    "                                 [np.around(action[1],2)]\n",
    "                                ]\n",
    "                                ],requires_grad =False).to(device)\n",
    "        \n",
    "        action = action[:,:,0]\n",
    "        action_1 = action[:,0]\n",
    "        action_2 = action[:,1]\n",
    "        act_2_1 = action_1[0]\n",
    "        act_2_2 = action_2[0]\n",
    "\n",
    "        \n",
    "            \n",
    "            #rint(self.agent_history )\n",
    "            #print(self.attack_count)\n",
    "    \n",
    "        return [act_2_1.clone().detach().cpu().item(), max(act_2_2.clone().detach().cpu().item(),0.001) ]\n",
    "\n",
    "\n",
    "class sim_simple(object):\n",
    "    def __init__(self,env_config ):\n",
    "        self.env_config = env_config\n",
    "        #self.env = env_risk(**(self.env_config  #| {\"render_mode\" : None,\"bad_mov_penalization\" : 0.01,\"render_\":False#False\n",
    "                                                    # }\n",
    "        #                         ))\n",
    "        self.Personality_bot = Personality_bot()\n",
    "        #self.env.observation_space(1)['observation'].dtype =np.float32\n",
    "        self.seed = 1\n",
    "        #self.env.reset(seed=self.seed)\n",
    "    def run_sim(self):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.env = env_risk(**(self.env_config  #| {\"render_mode\" : None,\"bad_mov_penalization\" : 0.01,\"render_\":False#False\n",
    "                                                    # }\n",
    "                                 ))\n",
    "            self.env.observation_space(1)['observation'].dtype =np.float32\n",
    "\n",
    "            self.env.reset(seed=self.seed)\n",
    "            \n",
    "            \n",
    "            for agent in self.env.agent_iter():\n",
    "                e_t = self.env.terminations\n",
    "                if sum(e_t.values()) <(self.env.max_num_agents-1):\n",
    "                    observation, reward, termination, truncation, info = self.env.last()\n",
    "                    obs = observation['observation']\n",
    "                    mask = observation['action_mask']\n",
    "                    phase = self.env.phase_selection\n",
    "                    curr_agent = agent\n",
    "                    troops = self.env.board.agents[agent-1].bucket\n",
    "\n",
    "                    action_ = self.Personality_bot.agent_action(observation, reward, termination, truncation, info, phase, troops,self.env,agent)\n",
    "\n",
    "                    #self.Personality_bot.update_history(observation,self.env,agent,action_)\n",
    "                    \n",
    "                    if phase == 1:\n",
    "                        #print(act_2_1,part_0)\n",
    "                        self.Personality_bot.update_history(observation,self.env,agent,int(action_[0]))\n",
    "                        self.Personality_bot.print_relation()\n",
    "\n",
    "                    \n",
    "                    self.env.step(action_)\n",
    "                else:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937a581-f7f8-471c-afcf-26a5acfc140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(action_mask_prob<self.base_prob[agent], \n",
    "                                    \n",
    "                                    self.base_prob[agent], \n",
    "                                    \n",
    "                                    action_mask_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "b916851b-3413-461a-9aea-16831af2ea0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 0])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.where(( np.array([1,2,0])<2)&( np.array([1,2,0])>0) , 7, np.array([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d71f294f-e954-47d1-be9f-142f1240167d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(masking)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0cd8cf18-5940-436a-b1fe-63ab67927fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config2 = {'render_mode': 'rgb_array',\n",
    " 'default_attack_all': True,\n",
    " 'agent_count': 3,\n",
    " 'use_placement_perc': True,\n",
    " 'render_': True,\n",
    " 'bad_mov_penalization': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "5298a678-d90a-4fb0-8d06-4419963430e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = sim_simple(env_config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "0cce4305-98f4-4e8c-9577-e6fe091a4cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {2: {'attacked_me': 0, 'neighbour_cooperate': 0},\n",
       "  3: {'attacked_me': 0, 'neighbour_cooperate': 0}},\n",
       " 2: {1: {'attacked_me': 0, 'neighbour_cooperate': 0},\n",
       "  3: {'attacked_me': 0, 'neighbour_cooperate': 0}},\n",
       " 3: {1: {'attacked_me': 0, 'neighbour_cooperate': 0},\n",
       "  2: {'attacked_me': 0, 'neighbour_cooperate': 0}}}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss1.Personality_bot.agent_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "f16a3835-ea8d-4ae5-9cc5-215b618d0018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.5}, 3: {1: 0.5, 2: 0.5}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0\n",
      "1 3 0\n",
      "2 3 0\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.5}, 3: {1: 0.5, 2: 0.5}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0\n",
      "1 3 0\n",
      "2 3 0\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.1 0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.1 0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "2 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.5}, 3: {1: 0.5, 2: 0.5}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0\n",
      "1 3 0\n",
      "2 3 0\n",
      "prob 2 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.5}, 3: {1: 0.5, 2: 0.5}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0\n",
      "1 3 0\n",
      "2 3 0\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.5}, 3: {1: 0.5, 2: 0.5}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0\n",
      "1 3 0\n",
      "2 3 0\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.4}, 3: {1: 0.5, 2: 0.5}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0\n",
      "1 3 0\n",
      "2 3 0.0\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.4}, 3: {1: 0.5, 2: 0.5}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0\n",
      "1 3 0\n",
      "2 3 0.0\n",
      "prob 2 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.4}, 3: {1: 0.5, 2: 0.4}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.0\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.32000000000000006}, 3: {1: 0.5, 2: 0.4}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.0\n",
      "prob 2 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.32000000000000006}, 3: {1: 0.5, 2: 0.32000000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.0\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.25600000000000006}, 3: {1: 0.5, 2: 0.32000000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.0\n",
      "prob 2 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.25600000000000006}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.0\n",
      "before [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.2   0.256 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.2   0.2  ]\n",
      "after [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.2   0.256 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.2   0.2  ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.20480000000000007}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.0\n",
      "before [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.2   0.256 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.2   0.2  ]\n",
      "after [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.2   0.256 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.2   0.2  ]\n",
      "3 attacking 2\n",
      "2\n",
      "2 3\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.36384000000000005}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.2\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.29107200000000005}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.16666666666666666\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.29107200000000005}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.16666666666666666\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.29107200000000005}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.16666666666666666\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.29107200000000005}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.16666666666666666\n",
      "before [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.2   0.256 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.2   0.2  ]\n",
      "after [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.2   0.256 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.2   0.2  ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.23285760000000005}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.14285714285714285\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.23285760000000005}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.14285714285714285\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.18628608000000005}, 3: {1: 0.5, 2: 0.25600000000000006}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.0\n",
      "1 3 0\n",
      "2 3 0.125\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.1        0.18628608 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.1        0.18628608 0.         0.\n",
      " 0.1        0.1       ]\n",
      "2 attacking 3\n",
      "3\n",
      "3 2\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.18628608000000005}, 3: {1: 0.5, 2: 0.40480000000000005}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.25\n",
      "1 3 0\n",
      "2 3 0.125\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "prob 2 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.18628608000000005}, 3: {1: 0.5, 2: 0.40480000000000005}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.25\n",
      "1 3 0\n",
      "2 3 0.125\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.18628608000000005}, 3: {1: 0.5, 2: 0.40480000000000005}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.25\n",
      "1 3 0\n",
      "2 3 0.125\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1 0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1 0.  0.  0.1 0.1]\n",
      "2 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.18628608000000005}, 3: {1: 0.5, 2: 0.40480000000000005}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.25\n",
      "1 3 0\n",
      "2 3 0.125\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.18628608\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.18628608\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 2 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.18628608000000005}, 3: {1: 0.5, 2: 0.3238400000000001}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.2\n",
      "1 3 0\n",
      "2 3 0.125\n",
      "before [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.32384 0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.2     0.2    ]\n",
      "after [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.32384 0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.2     0.2    ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.14902886400000004}, 3: {1: 0.5, 2: 0.3238400000000001}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.2\n",
      "1 3 0\n",
      "2 3 0.1111111111111111\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.14902886\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.1        0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.14902886\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.1        0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 2 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.14902886400000004}, 3: {1: 0.5, 2: 0.2590720000000001}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.16666666666666666\n",
      "1 3 0\n",
      "2 3 0.1111111111111111\n",
      "before [0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.259072 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.2      0.2     ]\n",
      "after [0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.259072 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.2      0.2     ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.11922309120000003}, 3: {1: 0.5, 2: 0.2590720000000001}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.16666666666666666\n",
      "1 3 0\n",
      "2 3 0.1\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.11922309120000003}, 3: {1: 0.5, 2: 0.2590720000000001}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.16666666666666666\n",
      "1 3 0\n",
      "2 3 0.1\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11922309\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.1        0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11922309\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.1        0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 2 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.11922309120000003}, 3: {1: 0.5, 2: 0.20725760000000007}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.14285714285714285\n",
      "1 3 0\n",
      "2 3 0.1\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11922309\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.1        0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11922309\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1        0.1        0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 2 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.11922309120000003}, 3: {1: 0.5, 2: 0.16580608000000008}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.1\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16580608 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.09537847296000003}, 3: {1: 0.5, 2: 0.16580608000000008}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.5, 3: 0.09537847296000003}, 3: {1: 0.5, 2: 0.16580608000000008}}\n",
      "2 1 0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.1 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.1 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 2\n",
      "2\n",
      "2 1\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.6000000000000001, 3: 0.09537847296000003}, 3: {1: 0.5, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.5 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.5 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 2\n",
      "2\n",
      "2 1\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.6800000000000002, 3: 0.09537847296000003}, 3: {1: 0.4, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.0\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.5 0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.5 0.  0.1 0.1]\n",
      "1 attacking 2\n",
      "2\n",
      "2 1\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.32000000000000006, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.0\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.25600000000000006, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.0\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40480000000000005, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.25\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3238400000000001, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.2\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2590720000000001, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.16666666666666666\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.1 0.  0.  0.1 0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.1 0.  0.  0.1 0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20725760000000007, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.14285714285714285\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.1 0.  0.  0.  0.  0.1 0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16580608000000008, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.125\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16580608 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6000000000000001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16580608000000008, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.125\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 1.0\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.16580608 0.16580608 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6800000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16580608000000008, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.125\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 1.0\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.16580608 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16580608000000008, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.125\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "before [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.1   0.    0.\n",
      " 0.544 0.    0.    0.    0.    0.    0.1   0.1  ]\n",
      "after [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.1   0.    0.\n",
      " 0.544 0.    0.    0.    0.    0.    0.1   0.1  ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33264486400000004, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.2222222222222222\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.26611589120000007, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.2\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.21289271296000006, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.18181818181818182\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.17031417036800006, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.16666666666666666\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.13625133629440006, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.15384615384615385\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.10900106903552005, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.14285714285714285\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "before [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.544 0.    0.    0.    0.    0.    0.1   0.1  ]\n",
      "after [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.544 0.    0.    0.    0.    0.    0.1   0.1  ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28720085522841604, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.2\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.22976068418273285, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.1875\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.1838085473461863, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.17647058823529413\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.14704683787694903, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.16666666666666666\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5440000000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.11763747030155923, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.15789473684210525\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.11763747 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.11763747 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.43520000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.11763747030155923, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.15789473684210525\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.4352 0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.1    0.1   ]\n",
      "after [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.4352 0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.1    0.1   ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.43520000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2941099762412474, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.2\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.43520000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23528798099299794, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.19047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.43520000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.18823038479439835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.18181818181818182\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.18823038 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.18823038 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.34816000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.18823038479439835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.18181818181818182\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.34816 0.      0.\n",
      " 0.      0.      0.      0.1     0.1    ]\n",
      "after [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.34816 0.      0.\n",
      " 0.      0.      0.      0.1     0.1    ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.34816000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.15058430783551868, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.17391304347826086\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.34816 0.      0.\n",
      " 0.      0.      0.      0.1     0.1    ]\n",
      "after [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.34816 0.      0.\n",
      " 0.      0.      0.      0.1     0.1    ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.34816000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.12046744626841495, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.16666666666666666\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.34816 0.      0.\n",
      " 0.      0.      0.      0.1     0.1    ]\n",
      "after [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.34816 0.      0.\n",
      " 0.      0.      0.      0.1     0.1    ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.34816000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.29637395701473196, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.2\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.34816000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23709916561178557, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.19230769230769232\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.34816 0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.1     0.1    ]\n",
      "after [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.34816 0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.1     0.1    ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.34816000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3896793324894285, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.2222222222222222\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.34816000000000014}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3117434659915428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.21428571428571427\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31174347 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.31174347 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31174347 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.31174347 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4785280000000001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3117434659915428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.21428571428571427\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31174347 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31174347 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31174347 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31174347 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5828224000000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3117434659915428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.21428571428571427\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5714285714285714\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31174347 0.31174347 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31174347 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31174347 0.31174347 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31174347 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6662579200000002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3117434659915428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.21428571428571427\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.625\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31174347 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31174347 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.7330063360000001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3117434659915428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.21428571428571427\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6666666666666666\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.31174347\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.31174347\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.5864050688000001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3117434659915428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.21428571428571427\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.31174347\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.31174347\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6691240550400002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3117434659915428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.21428571428571427\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.6363636363636364\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5352992440320001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3117434659915428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.21428571428571427\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5833333333333334\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.53529924 0.53529924 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.53529924 0.53529924 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.5352992440320001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44939477279323425, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.2413793103448276\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5833333333333334\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53529924 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53529924 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.5352992440320001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5595158182345874, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.26666666666666666\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5833333333333334\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.53529924 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.53529924 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5352992440320001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44761265458766997, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.25806451612903225\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5833333333333334\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.4282393952256001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44761265458766997, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.25806451612903225\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5384615384615384\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.4282394\n",
      " 0.        0.        0.        0.4282394 0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.4282394\n",
      " 0.        0.        0.        0.4282394 0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4282393952256001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.558090123670136, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.28125\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5384615384615384\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.4282394\n",
      " 0.        0.        0.        0.        0.        0.1       0.4282394\n",
      " 0.        0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.4282394\n",
      " 0.        0.        0.        0.        0.        0.1       0.4282394\n",
      " 0.        0.        0.1       0.1      ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4282393952256001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6464720989361088, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.30303030303030304\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5384615384615384\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.1       0.4282394\n",
      " 0.        0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.1       0.4282394\n",
      " 0.        0.        0.1       0.1      ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.4282393952256001}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.517177679148887, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.29411764705882354\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5384615384615384\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3425915161804801}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.517177679148887, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.29411764705882354\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.2740732129443841}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.517177679148887, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.29411764705882354\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4666666666666667\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.51717768 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.51717768 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4192585703555073}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.517177679148887, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.29411764705882354\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.51717768 0.         0.51717768 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.51717768 0.         0.51717768 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.33540685628440586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.517177679148887, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.29411764705882354\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33540686 0.         0.         0.         0.         0.33540686\n",
      " 0.         0.         0.1        0.33540686 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33540686 0.         0.         0.         0.         0.33540686\n",
      " 0.         0.         0.1        0.33540686 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.33540685628440586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6137421433191097, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3142857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.33540686\n",
      " 0.33540686 0.         0.         0.         0.         0.\n",
      " 0.33540686 0.         0.         0.         0.         0.33540686\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.33540686\n",
      " 0.33540686 0.         0.         0.         0.         0.\n",
      " 0.33540686 0.         0.         0.         0.         0.33540686\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.33540685628440586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6909937146552878, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3333333333333333\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.33540686\n",
      " 0.33540686 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.33540686 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.33540686\n",
      " 0.33540686 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.33540686 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.33540685628440586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7527949717242304, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35135135135135137\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.33540686 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.33540686 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.33540685628440586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.8022359773793843, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3684210526315789\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.33540685628440586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6417887819035075, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.358974358974359\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.33540685628440586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5134310255228061, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.51343103 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.51343103 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4683254850275247}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5134310255228061, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.51343103 0.51343103 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.51343103 0.51343103 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5746603880220198}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5134310255228061, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5263157894736842\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.51343103 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.51343103 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.45972831041761586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5134310255228061, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.45972831041761586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4107448204182449, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.34146341463414637\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.41074482 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.41074482 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.41074482 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.41074482 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3677826483340927}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4107448204182449, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.34146341463414637\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47619047619047616\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.41074482 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.41074482 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.29422611866727416}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4107448204182449, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.34146341463414637\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.45454545454545453\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.41074482 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.41074482 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.41074482 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.41074482 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.23538089493381933}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4107448204182449, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.34146341463414637\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43478260869565216\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23538089 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.23538089 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23538089 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.23538089 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.23538089493381933}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5285958563345959, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35714285714285715\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43478260869565216\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23538089 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23538089 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.23538089493381933}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6228766850676768, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.37209302325581395\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43478260869565216\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.23538089493381933}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.49830134805414145, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.36363636363636365\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43478260869565216\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.49830135 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49830135 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.49830135 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49830135 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3883047159470555}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.49830134805414145, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.36363636363636365\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4583333333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.49830135 0.49830135 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49830135 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.49830135 0.49830135 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49830135 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5106437727576445}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.49830134805414145, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.36363636363636365\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.48\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49830135 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49830135 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6085150182061156}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.49830134805414145, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.36363636363636365\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.49830135 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.49830135 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6868120145648926}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.49830134805414145, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.36363636363636365\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5185185185185185\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.5494496116519141}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.49830134805414145, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.36363636363636365\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54944961\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54944961\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5494496116519141}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3986410784433132, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35555555555555557\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.4395596893215313}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3986410784433132, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35555555555555557\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4827586206896552\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.39864108 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.39864108 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5516477514572251}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3986410784433132, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35555555555555557\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.5\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.44131820116578013}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3986410784433132, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35555555555555557\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4838709677419355\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.39864108 0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.39864108 0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3530545609326241}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3986410784433132, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35555555555555557\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.46875\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.39864108 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.39864108 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4824436487460993}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3986410784433132, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35555555555555557\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.48484848484848486\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.38595491899687945}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3986410784433132, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.35555555555555557\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.38595492\n",
      " 0.38595492 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.38595492\n",
      " 0.38595492 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.38595491899687945}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3189128627546506, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.34782608695652173\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.47058823529411764\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.31891286 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.31891286 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5087639351975035}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3189128627546506, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.34782608695652173\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4857142857142857\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.4070111481580028}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3189128627546506, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.34782608695652173\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4722222222222222\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.40701115\n",
      " 0.40701115 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.40701115\n",
      " 0.40701115 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4070111481580028}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4551302902037205, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3617021276595745\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4722222222222222\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.40701115 0.40701115 0.         0.\n",
      " 0.40701115 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.40701115 0.40701115 0.         0.\n",
      " 0.40701115 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4070111481580028}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5641042321629763, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.375\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4722222222222222\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.40701115 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.40701115 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4070111481580028}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.45128338573038107, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3673469387755102\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4722222222222222\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3256089185264023}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.45128338573038107, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3673469387755102\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4594594594594595\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32560892 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32560892 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3256089185264023}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5610267085843048, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.38\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4594594594594595\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.32560892 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.32560892 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3256089185264023}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4488213668674439, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.37254901960784315\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4594594594594595\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.44882137 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.44882137 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.26048713482112185}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4488213668674439, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.37254901960784315\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4473684210526316\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.44882137 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.44882137 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.20838970785689748}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4488213668674439, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.37254901960784315\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4358974358974359\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.20838971 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.20838971 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.20838970785689748}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5590570934939552, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.38461538461538464\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4358974358974359\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.20838971 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.20838971 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.20838970785689748}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44724567479516414, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.37735849056603776\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4358974358974359\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.44724567 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.44724567 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.366711766285518}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44724567479516414, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.37735849056603776\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.45\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.44724567 0.44724567 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.44724567 0.44724567 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.2933694130284144}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44724567479516414, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.37735849056603776\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43902439024390244\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29336941\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.29336941 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29336941\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.29336941 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.2933694130284144}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5577965398361313, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3888888888888889\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43902439024390244\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.29336941 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.29336941 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.2933694130284144}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6462372318689051, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43902439024390244\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29336941 0.29336941 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29336941 0.29336941 0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.2933694130284144}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5169897854951241, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39285714285714285\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43902439024390244\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.51698979 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.51698979\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.51698979 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.51698979\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.23469553042273153}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5169897854951241, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39285714285714285\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23469553 0.23469553 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23469553 0.23469553 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.23469553042273153}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6135918283960993, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23469553 0.23469553 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.23469553 0.23469553 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.23469553042273153}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6908734627168794, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41379310344827586\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.23469553042273153}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5526987701735036, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4067796610169492\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.55269877\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.55269877\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.38775642433818525}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5526987701735036, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4067796610169492\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4418604651162791\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.55269877 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.55269877 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5102051394705482}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5526987701735036, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4067796610169492\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.45454545454545453\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.4081641115764386}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5526987701735036, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4067796610169492\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4444444444444444\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.4081641115764386}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4421590161388029, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4444444444444444\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.32653128926115094}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4421590161388029, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43478260869565216\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.2612250314089208}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4421590161388029, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.425531914893617\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.26122503 0.         0.1        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.26122503 0.         0.1        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.2612250314089208}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3537272129110423, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39344262295081966\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.425531914893617\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.26122503 0.         0.         0.\n",
      " 0.26122503 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.26122503 0.         0.         0.\n",
      " 0.26122503 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.2612250314089208}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28298177032883387, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3870967741935484\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.425531914893617\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.28298177 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.28298177 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.40898002512713666}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28298177032883387, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3870967741935484\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4375\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3271840201017093}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28298177032883387, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3870967741935484\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32718402\n",
      " 0.         0.         0.32718402 0.         0.         0.\n",
      " 0.32718402 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32718402\n",
      " 0.         0.         0.32718402 0.         0.         0.\n",
      " 0.32718402 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3271840201017093}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42638541626306714, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3968253968253968\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32718402\n",
      " 0.         0.         0.32718402 0.         0.         0.\n",
      " 0.32718402 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32718402\n",
      " 0.         0.         0.32718402 0.         0.         0.\n",
      " 0.32718402 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3271840201017093}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5411083330104538, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40625\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32718402\n",
      " 0.         0.         0.32718402 0.         0.         0.\n",
      " 0.         0.         0.32718402 0.32718402 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32718402\n",
      " 0.         0.         0.32718402 0.         0.         0.\n",
      " 0.         0.         0.32718402 0.32718402 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3271840201017093}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.632886666408363, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4153846153846154\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1        0.         0.         0.\n",
      " 0.         0.         0.32718402 0.32718402 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1        0.         0.         0.\n",
      " 0.         0.         0.32718402 0.32718402 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3271840201017093}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7063093331266905, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42424242424242425\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3271840201017093}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5650474665013524, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.417910447761194\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3271840201017093}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.45203797320108197, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4117647058823529\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.2617472160813675}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.45203797320108197, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4117647058823529\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.20939777286509398}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.45203797320108197, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4117647058823529\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4117647058823529\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.20939777 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.20939777 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.20939777286509398}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5616303785608656, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42028985507246375\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4117647058823529\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.20939777286509398}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4493043028486925, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4142857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4117647058823529\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.4493043 0.4493043\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.4493043 0.4493043\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3675182182920752}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4493043028486925, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4142857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4230769230769231\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.29401457463366015}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4493043028486925, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4142857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41509433962264153\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.29401457463366015}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.35944344227895403, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4084507042253521\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41509433962264153\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29401457 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29401457 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.29401457463366015}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41509433962264153\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.28755475 0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.28755475 0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.28755475382316326, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4027777777777778\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23004380305853062, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3972602739726027\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.43521166 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.43521166 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3840350424468245, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40540540540540543\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3072280339574596, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.43521165970692816}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2457824271659677, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42592592592592593\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.24578243 0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.24578243 0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.34816932776554255}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2457824271659677, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41818181818181815\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.24578243 0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.24578243 0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.278535462212434}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2457824271659677, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4107142857142857\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24578243 0.         0.24578243 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24578243 0.         0.24578243 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.22282836976994724}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2457824271659677, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40350877192982454\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22282837\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22282837\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.22282836976994724}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3966259417327742, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4025974025974026\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40350877192982454\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.22282836976994724}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3173007533862194, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3974358974358974\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40350877192982454\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.22282836976994724}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2538406027089755, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3924050632911392\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40350877192982454\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.2538406 0.\n",
      " 0.2538406 0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.2538406 0.\n",
      " 0.2538406 0.        0.2       0.2      ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.1782626958159578}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2538406027089755, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3924050632911392\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39655172413793105\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.1782627 0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.1782627 0.1       0.1      ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.1782626958159578}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20307248216718043, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3875\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39655172413793105\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.20307248 0.         0.20307248 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.20307248 0.         0.20307248 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3426101566527663}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20307248216718043, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3875\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4067796610169492\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.27408812532221305}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20307248216718043, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3875\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.20307248 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.20307248 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.21927050025777045}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20307248216718043, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3875\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39344262295081966\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.20307248 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.20307248 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.20307248 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.20307248 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.17541640020621638}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20307248216718043, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3875\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.17541640020621638}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16245798573374437, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.38271604938271603\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.16245799 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16245799 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.2]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3403331201649731}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16245798573374437, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.38271604938271603\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3968253968253968\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.16245799 0.16245799 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16245799 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.2]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.47226649613197846}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16245798573374437, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.38271604938271603\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40625\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16245799 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.2]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5778131969055829}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16245798573374437, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.38271604938271603\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4153846153846154\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.4622505575244663}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16245798573374437, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.38271604938271603\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4090909090909091\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.46225056 0.         0.1        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.46225056 0.         0.1        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4622505575244663}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3299663885869955, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3902439024390244\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4090909090909091\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.46225056 0.         0.46225056 0.\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.46225056 0.         0.46225056 0.\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.4622505575244663}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2639731108695964, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3855421686746988\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4090909090909091\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.46225056 0.         0.46225056 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.46225056 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.46225056 0.         0.46225056 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.46225056 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4622505575244663}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.41117848869567714, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39285714285714285\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4090909090909091\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.46225056 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.46225056 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4622505575244663}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5289427909565417, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4090909090909091\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.46225056 0.46225056 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.46225056 0.46225056 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4622505575244663}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6231542327652334, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4069767441860465\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4090909090909091\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.46225056\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.46225056\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4622505575244663}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4090909090909091\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49852339 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49852339\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49852339 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49852339\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5698004460195731}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.417910447761194\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.49852339 0.49852339 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49852339\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.49852339 0.49852339 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49852339\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6558403568156586}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4264705882352941\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49852339 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.49852339 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.7246722854525269}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43478260869565216\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.49852339 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.49852339 0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.7797378283620215}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.44285714285714284\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49852339\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49852339\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.8237902626896172}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4507042253521127\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.49852339 0.49852339 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.49852339 0.49852339 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.8590322101516938}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4583333333333333\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.6872257681213552}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4520547945205479\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5497806144970842}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4985233862121867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40229885057471265\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.44594594594594594\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54978061 0.54978061 0.         0.\n",
      " 0.54978061 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54978061 0.54978061 0.         0.\n",
      " 0.54978061 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.5497806144970842}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988187089697494, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4090909090909091\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.44594594594594594\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.54978061 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.54978061 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5497806144970842}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.47905496717579954, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4044943820224719\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.44594594594594594\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.43982449159766734}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.47905496717579954, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4044943820224719\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.44\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.43982449 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.43982449 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.43982449159766734}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5832439737406396, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4111111111111111\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.44\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.43982449 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.43982449 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.43982449159766734}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6665951789925117, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4175824175824176\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.44\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.43982449159766734}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5332761431940094, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41304347826086957\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.44\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53327614\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53327614\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3518595932781339}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5332761431940094, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41304347826086957\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4342105263157895\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35185959 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35185959 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3518595932781339}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6266209145552075, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41935483870967744\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4342105263157895\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35185959\n",
      " 0.         0.35185959 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35185959\n",
      " 0.         0.35185959 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3518595932781339}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.501296731644166, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4148936170212766\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4342105263157895\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.50129673 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.50129673\n",
      " 0.         0.         0.         0.50129673 0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.50129673 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.50129673\n",
      " 0.         0.         0.         0.50129673 0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.2814876746225071}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.501296731644166, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4148936170212766\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.28148767\n",
      " 0.         0.28148767 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.28148767\n",
      " 0.         0.28148767 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.2814876746225071}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6010373853153328, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42105263157894735\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.2814876746225071}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48082990825226624, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4166666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.48082991 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.48082991\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.48082991 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.48082991\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.42519013969800573}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48082990825226624, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4166666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4358974358974359\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.48082991\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.48082991\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3401521117584046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48082990825226624, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4166666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43037974683544306\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3401521117584046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.38466392660181303, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41237113402061853\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43037974683544306\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3401521117584046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30773114128145046, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40816326530612246\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43037974683544306\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.34015211\n",
      " 0.         0.34015211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.34015211\n",
      " 0.         0.34015211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3401521117584046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.24618491302516038, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40404040404040403\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43037974683544306\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.34015211\n",
      " 0.         0.34015211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.34015211\n",
      " 0.         0.34015211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3401521117584046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3969479304201283, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43037974683544306\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3401521117584046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3175583443361027, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40594059405940597\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43037974683544306\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.3401521117584046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.25404667546888215, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4019607843137255\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43037974683544306\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25404668\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25404668\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.2721216894067237}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.25404667546888215, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4019607843137255\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.425\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.27212169 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.27212169 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.2721216894067237}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20323734037510574, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39805825242718446\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.425\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.20323734\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.20323734\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.417697351525379}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20323734037510574, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39805825242718446\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43209876543209874\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.20323734 0.20323734 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.20323734 0.20323734 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5341578812203032}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20323734037510574, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39805825242718446\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43902439024390244\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.4273263049762426}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20323734037510574, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39805825242718446\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43373493975903615\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.4273263\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.4273263\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.4273263049762426}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.1625898723000846, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3942307692307692\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43373493975903615\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.4273263 0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.4273263 0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4273263049762426}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3300718978400677, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43373493975903615\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.4273263 0.\n",
      " 0.4273263 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.4273263 0.\n",
      " 0.4273263 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4273263049762426}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.26405751827205415, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39622641509433965\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43373493975903615\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.26405752 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.26405752 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3418610439809941}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.26405751827205415, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39622641509433965\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.34186104 0.         0.         0.         0.\n",
      " 0.         0.34186104 0.         0.34186104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.34186104 0.         0.         0.         0.\n",
      " 0.         0.34186104 0.         0.34186104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3418610439809941}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4112460146176433, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40186915887850466\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.34186104 0.         0.34186104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.34186104 0.         0.34186104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3418610439809941}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5289968116941146, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4074074074074074\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3418610439809941}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231974493552917, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4036697247706422\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.34186104 0.         0.34186104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.34186104 0.         0.34186104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.3418610439809941}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3385579594842334, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33855796 0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33855796 0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.2734888351847953}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3385579594842334, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4235294117647059\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.27348884 0.         0.27348884 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.27348884 0.         0.27348884 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.2734888351847953}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.47084636758738674, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40540540540540543\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4235294117647059\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.2734888351847953}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3766770940699094, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4017857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4235294117647059\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.2734888351847953}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30134167525592753, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39823008849557523\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4235294117647059\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.30134168 0.         0.         0.         0.         0.30134168\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.30134168 0.         0.         0.         0.         0.30134168\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.21879106814783622}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30134167525592753, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39823008849557523\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4186046511627907\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.30134168 0.         0.         0.         0.         0.30134168\n",
      " 0.         0.         0.         0.30134168 0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.30134168 0.         0.         0.         0.         0.30134168\n",
      " 0.         0.         0.         0.30134168 0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.375032854518269}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30134167525592753, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39823008849557523\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42528735632183906\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.30134168 0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.30134168 0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5000262836146152}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30134167525592753, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39823008849557523\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4318181818181818\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.30134168\n",
      " 0.30134168 0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.30134168\n",
      " 0.30134168 0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6000210268916921}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30134167525592753, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39823008849557523\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43820224719101125\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.48001682151335373}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30134167525592753, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.39823008849557523\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43333333333333335\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.48001682 0.1        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.48001682 0.1        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.48001682151335373}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43333333333333335\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.48001682151335373}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43333333333333335\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.2 0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.2 0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.48001682151335373}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43333333333333335\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.38401345721068303}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42857142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.30721076576854645}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42391304347826086\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.44107334 0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.44107334 0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4457686126148372}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43010752688172044\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.35661489009186975}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.425531914893617\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.44107334\n",
      " 0.44107334 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.44107334\n",
      " 0.44107334 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4852919120734958}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.43157894736842106\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.38823352965879665}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44107334020474204, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40350877192982454\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4270833333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38823353 0.\n",
      " 0.         0.         0.38823353 0.38823353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38823353 0.\n",
      " 0.         0.         0.38823353 0.38823353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.38823352965879665}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.35285867216379363, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4270833333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38823353 0.\n",
      " 0.         0.         0.38823353 0.38823353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38823353 0.\n",
      " 0.         0.         0.38823353 0.38823353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.38823352965879665}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4822869377310349, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4051724137931034\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4270833333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.38823352965879665}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.38582955018482795, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4017094017094017\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4270833333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.38823352965879665}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3086636401478624, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3983050847457627\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4270833333333333\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.31058682372703733}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3086636401478624, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3983050847457627\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.422680412371134\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.24846945898162986}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3086636401478624, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.3983050847457627\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41836734693877553\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.         0.1        0.24846946 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.         0.1        0.24846946 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.24846945898162986}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44693091211828995, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40336134453781514\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41836734693877553\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.24846945898162986}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.44693091211828995, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40336134453781514\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41836734693877553\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.24846946 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.24846946 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.24846945898162986}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.557544729694632, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4083333333333333\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41836734693877553\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24846946 0.         0.24846946 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24846946 0.         0.24846946 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.24846945898162986}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6460357837557056, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4132231404958678\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41836734693877553\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24846946 0.         0.24846946 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24846946 0.         0.24846946 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.24846945898162986}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7168286270045645, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4180327868852459\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41836734693877553\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.24846945898162986}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5734629016036517, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4146341463414634\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41836734693877553\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.2       0.        0.\n",
      " 0.        0.        0.2       0.5734629 0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.2       0.        0.\n",
      " 0.        0.        0.2       0.5734629 0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.1987755671853039}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5734629016036517, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4146341463414634\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41414141414141414\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.1987755671853039}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.45877032128292133, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4112903225806452\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41414141414141414\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.1987755671853039}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3670162570263371, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.408\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41414141414141414\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.36701626 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.36701626 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.35902045374824315}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3670162570263371, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.408\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.42\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.2        0.36701626 0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.2        0.36701626 0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.28721636299859454}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3670162570263371, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.408\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4158415841584158\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.28721636299859454}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2936130056210697, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40476190476190477\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4158415841584158\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.2        0.29361301 0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.2        0.29361301 0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.22977309039887564}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2936130056210697, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40476190476190477\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4117647058823529\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29361301 0.         0.         0.\n",
      " 0.         0.         0.2        0.29361301 0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29361301 0.         0.         0.\n",
      " 0.         0.         0.2        0.29361301 0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.38381847231910055}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2936130056210697, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40476190476190477\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4174757281553398\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29361301\n",
      " 0.29361301 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29361301 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29361301\n",
      " 0.29361301 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29361301 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.30705477785528046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2936130056210697, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40476190476190477\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41346153846153844\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.30705478 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.30705478 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.30705477785528046}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23489040449685575, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4015748031496063\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41346153846153844\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.2348904\n",
      " 0.        0.        0.        0.        0.        0.2       0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.2348904\n",
      " 0.        0.        0.        0.        0.        0.2       0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.24564382228422438}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23489040449685575, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4015748031496063\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4095238095238095\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.2348904\n",
      " 0.        0.        0.        0.        0.        0.2       0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.2348904\n",
      " 0.        0.        0.        0.        0.        0.2       0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3965150578273795}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23489040449685575, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4015748031496063\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41509433962264153\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.31721204626190364}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23489040449685575, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4015748031496063\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.411214953271028\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.25376963700952293}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23489040449685575, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4015748031496063\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4074074074074074\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.2348904\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.2348904\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.20301570960761836}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23489040449685575, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4015748031496063\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4036697247706422\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.2348904\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.2348904\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.1624125676860947}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23489040449685575, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4015748031496063\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16241257 0.\n",
      " 0.         0.         0.16241257 0.16241257 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16241257 0.\n",
      " 0.         0.         0.16241257 0.16241257 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.1624125676860947}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3879123235974846, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40625\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.16241257 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.16241257 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.1624125676860947}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3103298588779877, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40310077519379844\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31032986 0.         0.         0.\n",
      " 0.         0.         0.         0.31032986 0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31032986 0.         0.         0.\n",
      " 0.         0.         0.         0.31032986 0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.12993005414887576}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3103298588779877, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40310077519379844\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3963963963963964\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.12993005 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.12993005 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.12993005414887576}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4482638871023902, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4076923076923077\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3963963963963964\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.12993005 0.         0.12993005 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.12993005 0.         0.12993005 0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.12993005414887576}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3586111096819122, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40458015267175573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3963963963963964\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35861111 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35861111\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35861111 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35861111\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.30394404331910063}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3586111096819122, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40458015267175573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4017857142857143\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35861111 0.         0.35861111 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35861111\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35861111 0.         0.35861111 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35861111\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.24315523465528052}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3586111096819122, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40458015267175573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39823008849557523\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35861111 0.         0.35861111 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35861111\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35861111 0.         0.35861111 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35861111\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.39452418772422443}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3586111096819122, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40458015267175573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40350877192982454\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35861111\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35861111\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3156193501793796}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3586111096819122, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.40458015267175573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31561935 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31561935 0.         0.31561935 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31561935 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31561935 0.         0.31561935 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3156193501793796}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48688888774552974, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4090909090909091\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31561935 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31561935 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31561935 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31561935 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3156193501793796}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5895111101964239, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41353383458646614\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31561935 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31561935 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3156193501793796}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6716088881571392, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.417910447761194\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.3156193501793796}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5372871105257113, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4148148148148148\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.53728711 0.\n",
      " 0.         0.         0.         0.         0.         0.53728711\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.53728711 0.\n",
      " 0.         0.         0.         0.         0.         0.53728711\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4524954801435037}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5372871105257113, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4148148148148148\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4051724137931034\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.53728711 0.\n",
      " 0.         0.         0.         0.53728711 0.53728711 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.53728711 0.\n",
      " 0.         0.         0.         0.53728711 0.53728711 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.561996384114803}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5372871105257113, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4148148148148148\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41025641025641024\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53728711\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.53728711 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53728711\n",
      " 0.2        0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.53728711 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.44959710729184243}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5372871105257113, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4148148148148148\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4067796610169492\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53728711\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53728711 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53728711\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53728711 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.559677685833474}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5372871105257113, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4148148148148148\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4117647058823529\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53728711\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53728711\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.4477421486667792}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5372871105257113, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4148148148148148\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4083333333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.44774215 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.44774215 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4477421486667792}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6298296884205691, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41911764705882354\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4083333333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.44774215 0.44774215 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.44774215 0.44774215 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4477421486667792}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7038637507364554, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4233576642335766\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4083333333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.44774215 0.         0.1        0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.44774215 0.         0.1        0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4477421486667792}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5630910005891643, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42028985507246375\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4083333333333333\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3581937189334234}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5630910005891643, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42028985507246375\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4049586776859504\n",
      "2 3 0.09090909090909091\n",
      "before [0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.563091 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.2      0.2     ]\n",
      "after [0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.563091 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.2      0.2     ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.2865549751467387}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5630910005891643, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42028985507246375\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4016393442622951\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.28655498 0.         0.1        0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.28655498 0.         0.1        0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.2865549751467387}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6504728004713314, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4244604316546763\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4016393442622951\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.2865549751467387}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5203782403770651, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42142857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4016393442622951\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52037824 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52037824 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.429243980117391}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5203782403770651, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42142857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4065040650406504\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.52037824\n",
      " 0.         0.52037824 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.52037824\n",
      " 0.         0.52037824 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5433951840939129}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5203782403770651, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42142857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4112903225806452\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.4347161472751303}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5203782403770651, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42142857142857143\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.408\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4347161472751303}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4163025923016521, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41843971631205673\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.408\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3477729178201043}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4163025923016521, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41843971631205673\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40476190476190477\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3477729178201043}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33304207384132173, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4154929577464789\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40476190476190477\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33304207384132173, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4154929577464789\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2664336590730574, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4125874125874126\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.27821833 0.1        0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.27821833 0.1        0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.41314692725844593, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4166666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.27821833 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.27821833 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5305175418067567, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4206896551724138\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.27821833 0.27821833 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.27821833 0.27821833 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6244140334454054, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4246575342465753\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.27821833 0.         0.27821833 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.27821833 0.         0.27821833 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6995312267563243, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42857142857142855\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5596249814050595, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42567567567567566\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.27821833 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.27821833 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6476999851240476, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42953020134228187\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.27821833425608344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5181599880992381, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4266666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015748031496063\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.51815999\n",
      " 0.51815999 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.51815999\n",
      " 0.51815999 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.42257466740486677}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5181599880992381, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4266666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40625\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.51815999 0.51815999 0.         0.\n",
      " 0.51815999 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.51815999 0.51815999 0.         0.\n",
      " 0.51815999 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5380597339238935}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5181599880992381, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4266666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4108527131782946\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.4304477871391148}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5181599880992381, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4266666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4076923076923077\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3443582297112919}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5181599880992381, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4266666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40458015267175573\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.2754865837690335}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5181599880992381, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4266666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4015151515151515\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.51815999 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.51815999 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.22038926701522682}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5181599880992381, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4266666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39849624060150374\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.22038927 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.22038927 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.22038926701522682}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.41452799047939054, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.423841059602649\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39849624060150374\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.41452799 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.41452799 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.37631141361218146}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.41452799047939054, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.423841059602649\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40298507462686567\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.37631141361218146}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.41452799047939054, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.423841059602649\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40298507462686567\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.37631141361218146}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.41452799047939054, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.423841059602649\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40298507462686567\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.37631141361218146}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.41452799047939054, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.423841059602649\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40298507462686567\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.37631141 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.37631141 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.37631141361218146}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33162239238351243, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42105263157894735\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40298507462686567\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.30104913088974516}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33162239238351243, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42105263157894735\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33162239 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33162239 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.24083930471179615}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33162239238351243, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42105263157894735\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39705882352941174\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.2408393 0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.2408393 0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.24083930471179615}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.26529791390680996, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41830065359477125\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39705882352941174\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.2408393 0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.2408393 0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.2408393 0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.2408393 0.        0.1       0.1      ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.24083930471179615}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.412238331125448, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42207792207792205\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39705882352941174\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.2408393 0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.2408393 0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.1       0.1      ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.24083930471179615}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3297906649003584, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41935483870967744\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39705882352941174\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32979066 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32979066 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.19267144376943693}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3297906649003584, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41935483870967744\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39416058394160586\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32979066 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32979066 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.15413715501554956}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3297906649003584, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.41935483870967744\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.15413716 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.15413716 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.15413715501554956}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2638325319202867, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4166666666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.15413716 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15413716 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.15413716 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15413716 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.15413715501554956}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4110660255362294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42038216560509556\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.15413716 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.15413716 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.15413715501554956}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.15413715501554956}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.2 0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.2 0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.15413715501554956}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.12330972401243966}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38848920863309355\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52885282 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52885282 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.09864777920995173}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38571428571428573\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52885282 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52885282 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.2789182233679614}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3900709219858156\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.22313457869436915}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3873239436619718\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.17850766295549533}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38461538461538464\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.14280613036439627}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5288528204289835, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4240506329113924\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3819444444444444\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.14280613036439627}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42308225634318686, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42138364779874216\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3819444444444444\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.11424490429151701}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42308225634318686, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42138364779874216\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3793103448275862\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.42308226 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.42308226 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.29139592343321363}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42308225634318686, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42138364779874216\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3835616438356164\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.29139592343321363}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42308225634318686, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42138364779874216\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3835616438356164\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.29139592343321363}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42308225634318686, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42138364779874216\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3835616438356164\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.42308226\n",
      " 0.         0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.42308226\n",
      " 0.         0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4331167387465709}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42308225634318686, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42138364779874216\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3877551020408163\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.34649339099725673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42308225634318686, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42138364779874216\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38513513513513514\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.34649339 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.34649339 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.34649339099725673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5384658050745494, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.425\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38513513513513514\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.34649339 0.1        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.34649339 0.1        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.34649339099725673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6307726440596395, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.42857142857142855\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38513513513513514\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34649339 0.34649339 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34649339 0.34649339 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.34649339099725673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7046181152477116, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43209876543209874\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38513513513513514\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.34649339099725673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5636944921981693, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4294478527607362\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38513513513513514\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56369449\n",
      " 0.         0.         0.56369449 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56369449\n",
      " 0.         0.         0.56369449 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4771947127978054}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5636944921981693, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4294478527607362\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38926174496644295\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.56369449 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.56369449 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5817557702382443}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5636944921981693, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4294478527607362\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3933333333333333\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56369449\n",
      " 0.         0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56369449\n",
      " 0.         0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.4654046161905955}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5636944921981693, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4294478527607362\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39072847682119205\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.56369449 0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.56369449 0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5723236929524764}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5636944921981693, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4294478527607362\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39473684210526316\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.45785895436198115}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5636944921981693, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4294478527607362\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39215686274509803\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56369449\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56369449\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.36628716348958495}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5636944921981693, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4294478527607362\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38961038961038963\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.36628716 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.36628716\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.36628716 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.36628716\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.36628716348958495}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6509555937585354, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4329268292682927\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38961038961038963\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.36628716 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.36628716 0.36628716 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.36628716 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.36628716 0.36628716 0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.36628716348958495}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5207644750068283, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4303030303030303\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38961038961038963\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.52076448\n",
      " 0.         0.52076448 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.52076448\n",
      " 0.         0.52076448 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.293029730791668}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5207644750068283, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4303030303030303\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29302973 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.29302973 0.29302973 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29302973 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.29302973 0.29302973 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.293029730791668}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6166115800054627, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43373493975903615\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.29302973 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.29302973 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.293029730791668}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6932892640043702, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.437125748502994\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.29302973 0.29302973 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.29302973 0.29302973 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.293029730791668}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7546314112034962, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.293029730791668}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.603705128962797, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4378698224852071\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.293029730791668}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48296410317023764, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43529411764705883\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.4829641 0.        0.        0.4829641\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.4829641 0.        0.        0.4829641\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.2344237846333344}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48296410317023764, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43529411764705883\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38461538461538464\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.4829641 0.        0.        0.4829641\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.4829641 0.        0.        0.4829641\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.38753902770666754}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48296410317023764, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43529411764705883\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3885350318471338\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.4829641 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.4829641 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.510031222165334}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48296410317023764, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43529411764705883\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3924050632911392\n",
      "2 3 0.09090909090909091\n",
      "before [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.4829641 0.        0.4829641\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "after [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.4829641 0.        0.4829641\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.2       0.2      ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6080249777322673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48296410317023764, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43529411764705883\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39622641509433965\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.48641998218581384}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48296410317023764, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43529411764705883\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39375\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.48296410317023764, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43529411764705883\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38913599 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.38913599 0.38913599 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38913599 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.38913599 0.38913599 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5863712825361902, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43859649122807015\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38913599 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38913599 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6690970260289522, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4418604651162791\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38913599 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38913599 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7352776208231617, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44508670520231214\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38913599 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38913599 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7882220966585294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4482758620689655\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7882220966585294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4482758620689655\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7882220966585294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4482758620689655\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7882220966585294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4482758620689655\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7882220966585294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4482758620689655\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7882220966585294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4482758620689655\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.2 0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 0.  0.  0.2 0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7882220966585294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4482758620689655\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7882220966585294, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4482758620689655\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.38913599 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.38913599 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3891359857486511}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6305776773268236, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44571428571428573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391304347826087\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.2        0.         0.63057768 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.2        0.         0.63057768 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3113087885989209}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6305776773268236, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44571428571428573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3888888888888889\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63057768 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.63057768 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63057768 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.63057768 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4490470308791368}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6305776773268236, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44571428571428573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39263803680981596\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63057768 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.63057768 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63057768 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.63057768 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5592376247033095}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6305776773268236, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44571428571428573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39634146341463417\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63057768 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63057768 0.63057768 0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63057768 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63057768 0.63057768 0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6473900997626476}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6305776773268236, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44571428571428573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.63057768\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.63057768\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5179120798101181}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6305776773268236, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44571428571428573\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39759036144578314\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.51791208 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.51791208\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.51791208 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.51791208\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.5179120798101181}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.704462141861459, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44886363636363635\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39759036144578314\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.51791208\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.51791208\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.5179120798101181}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5635697134891672, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4463276836158192\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39759036144578314\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56356971\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56356971\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.4143296638480945}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5635697134891672, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4463276836158192\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39520958083832336\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56356971\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56356971\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5314637310784756}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5635697134891672, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4463276836158192\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39880952380952384\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.4251709848627805}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5635697134891672, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4463276836158192\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39644970414201186\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.42517098\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.42517098\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4251709848627805}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6508557707913338, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.449438202247191\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39644970414201186\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.42517098 0.42517098 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.42517098 0.42517098 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4251709848627805}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7206846166330672, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.45251396648044695\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39644970414201186\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.42517098 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.42517098 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4251709848627805}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5765476933064537, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.45\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39644970414201186\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.57654769 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.57654769 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3401367878902244}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5765476933064537, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.45\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3941176470588235\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.34013679 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.34013679 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3401367878902244}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.661238154645163, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4530386740331492\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3941176470588235\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3401367878902244}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5289905237161304, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.45054945054945056\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3941176470588235\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.27210943031217955}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5289905237161304, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.45054945054945056\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391812865497076\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.27210943031217955}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231924189729044, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44808743169398907\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.391812865497076\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.         0.\n",
      " 0.42319242 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.         0.\n",
      " 0.42319242 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.41768754424974364}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231924189729044, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44808743169398907\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3953488372093023\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.41768754424974364}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231924189729044, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44808743169398907\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3953488372093023\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.41768754424974364}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231924189729044, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44808743169398907\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3953488372093023\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.41768754424974364}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231924189729044, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44808743169398907\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3953488372093023\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.42319242 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.42319242 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.534150035399795}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231924189729044, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44808743169398907\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3988439306358382\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.534150035399795}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231924189729044, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44808743169398907\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3988439306358382\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.534150035399795}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4231924189729044, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44808743169398907\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3988439306358382\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.53415004 0.53415004 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.53415004 0.53415004 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.534150035399795}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5385539351783235, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.45108695652173914\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3988439306358382\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.534150035399795}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.43084314814265884, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4486486486486487\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3988439306358382\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.427320028319836}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.43084314814265884, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4486486486486487\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39655172413793105\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.427320028319836}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3446745185141271, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44623655913978494\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39655172413793105\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.34467452 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.34467452 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5418560226558689}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3446745185141271, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44623655913978494\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.34467452 0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.34467452 0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.4334848181246951}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3446745185141271, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44623655913978494\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3977272727272727\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.43348482\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.43348482\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4334848181246951}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4757396148113017, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44919786096256686\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3977272727272727\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.43348482 0.43348482 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.43348482 0.43348482 0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.4334848181246951}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3805916918490414, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44680851063829785\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3977272727272727\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3467878544997561}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3805916918490414, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44680851063829785\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3954802259887006\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.27743028359980487}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3805916918490414, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44680851063829785\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39325842696629215\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.27743028 0.27743028 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.27743028 0.27743028 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.27743028359980487}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5044733534792332, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4497354497354497\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39325842696629215\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.27743028 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.27743028 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.27743028359980487}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40357868278338654, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39325842696629215\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.40357868 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.40357868 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.40357868 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.40357868 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4219442268798439}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40357868278338654, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39664804469273746\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.40357868 0.\n",
      " 0.         0.         0.40357868 0.         0.40357868 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.40357868 0.\n",
      " 0.         0.         0.40357868 0.         0.40357868 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5375553815038752}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40357868278338654, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.40357868 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.40357868 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6300443052031002}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40357868278338654, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40331491712707185\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.5040354441624801}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40357868278338654, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4473684210526316\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010989010989011\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.50403544\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.50403544\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.5040354441624801}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5228629462267093, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.450261780104712\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010989010989011\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.50403544\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.50403544\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.5040354441624801}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4182903569813674, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4479166666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010989010989011\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.40322835532998413}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4182903569813674, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4479166666666667\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3989071038251366\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.40322836\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.40322836\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.40322835532998413}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.534632285585094, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.45077720207253885\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3989071038251366\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.40322836 0.40322836 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.40322836 0.40322836 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.40322835532998413}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6277058284680752, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4536082474226804\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3989071038251366\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.40322835532998413}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5021646627744601, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4512820512820513\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3989071038251366\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.40322835532998413}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40173173021956815, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4489795918367347\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3989071038251366\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.40173173 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.40173173 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.32258268426398734}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40173173021956815, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4489795918367347\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3967391304347826\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.32258268426398734}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.32138538417565454, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4467005076142132\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3967391304347826\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.32138538 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32138538 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.32138538 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32138538 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4580661474111899}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.32138538417565454, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4467005076142132\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.32138538 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32138538 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.32138538 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32138538 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.36645291792895196}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.32138538417565454, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4467005076142132\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3978494623655914\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32138538 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32138538 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4931623343431616}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.32138538417565454, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4467005076142132\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40106951871657753\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.4931623343431616}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.32138538417565454, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4467005076142132\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40106951871657753\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.4931623343431616}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.32138538417565454, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4467005076142132\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40106951871657753\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.49316233 0.49316233 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.49316233 0.49316233 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.4931623343431616}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.45710830734052366, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4494949494949495\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40106951871657753\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.49316233 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.49316233 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4931623343431616}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.36568664587241895, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4472361809045226\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40106951871657753\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.36568665 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.36568665 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5945298674745293}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.36568664587241895, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4472361809045226\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40425531914893614\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.47562389397962346}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.36568664587241895, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4472361809045226\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4021164021164021\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.47562389 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.47562389 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.47562389397962346}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.29254931669793516, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.445\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4021164021164021\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.29254932 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29254932 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.29254932 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29254932 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5804991151836988}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.29254931669793516, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.445\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4052631578947368\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29254932 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29254932 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.4643992921469591}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.29254931669793516, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.445\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4031413612565445\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.46439929 0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.46439929 0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4643992921469591}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23403945335834814, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4427860696517413\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4031413612565445\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.23403945 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.23403945 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3715194337175673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.23403945335834814, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4427860696517413\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010416666666667\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.37151943 0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.37151943 0.         0.         0.         0.1\n",
      " 0.1        0.1       ]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3715194337175673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.1872315626866785, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4405940594059406\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010416666666667\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.37151943 0.         0.37151943 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.37151943 0.         0.37151943 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3715194337175673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3497852501493428, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4433497536945813\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010416666666667\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37151943 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37151943 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3715194337175673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.47982820011947425, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44607843137254904\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010416666666667\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37151943 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37151943 0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3715194337175673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3838625600955794, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44390243902439025\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010416666666667\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38386256 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.38386256 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.49721554697405385}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3838625600955794, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44390243902439025\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40414507772020725\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38386256 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38386256 0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3977724375792431}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3838625600955794, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44390243902439025\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4020618556701031\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.39777244 0.39777244 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.39777244 0.39777244 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3977724375792431}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5070900480764635, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44660194174757284\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4020618556701031\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3977724375792431}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40567203846117084, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4020618556701031\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.1        0.39777244 0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.1        0.39777244 0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3977724375792431}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5245376307689367, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44711538461538464\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4020618556701031\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.39777244 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.39777244 0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3977724375792431}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6196301046151493, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44976076555023925\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4020618556701031\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.39777244\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.39777244\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3977724375792431}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6957040836921196, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4523809523809524\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4020618556701031\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.39777244 0.39777244 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.39777244 0.39777244 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3977724375792431}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7565632669536957, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4549763033175355\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4020618556701031\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3977724375792431}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4020618556701031\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2        0.\n",
      " 0.         0.         0.2        0.60525061 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2        0.\n",
      " 0.         0.         0.2        0.60525061 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3182179500633945}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2        0.\n",
      " 0.         0.         0.2        0.60525061 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2        0.\n",
      " 0.         0.         0.2        0.60525061 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4545743600507156}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4030612244897959\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.60525061 0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.60525061 0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3636594880405725}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4010152284263959\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.60525061 0.         0.         0.         0.\n",
      " 0.         0.60525061 0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.60525061 0.         0.         0.         0.\n",
      " 0.         0.60525061 0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.49092759043245804}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40404040404040403\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.60525061 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.60525061 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5927420723459664}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40703517587939697\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.60525061 0.         0.60525061 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.60525061 0.         0.60525061 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6741936578767731}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.5393549263014185}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4079601990049751\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.4314839410411348}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6052506135629566, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4528301886792453\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40594059405940597\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.43148394 0.1        0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.43148394 0.1        0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.4314839410411348}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4842004908503653, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4507042253521127\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40594059405940597\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.48420049 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.48420049 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5451871528329079}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4842004908503653, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4507042253521127\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4088669950738916\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.4361497222663263}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4842004908503653, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4507042253521127\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4068627450980392\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.48420049 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.48420049 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.548919777813061}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4842004908503653, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4507042253521127\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4097560975609756\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.43913582225044884}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4842004908503653, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4507042253521127\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4077669902912621\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3513086578003591}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4842004908503653, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4507042253521127\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4057971014492754\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.35130866 0.1        0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.35130866 0.1        0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3513086578003591}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.38736039268029226, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4485981308411215\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4057971014492754\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35130866\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.35130866\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3513086578003591}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30988831414423385, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44651162790697674\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4057971014492754\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.30988831 0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.30988831 0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.28104692624028726}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30988831414423385, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44651162790697674\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40384615384615385\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.30988831 0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.30988831 0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.22483754099222983}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.30988831414423385, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44651162790697674\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4019138755980861\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22483754\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22483754\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.22483754099222983}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4479106513153871, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44907407407407407\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4019138755980861\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22483754 0.1        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22483754 0.1        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.22483754099222983}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3583285210523097, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4470046082949309\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4019138755980861\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.35832852 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.35832852 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3798700327937839}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3583285210523097, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4470046082949309\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40476190476190477\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.30389602623502715}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3583285210523097, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4470046082949309\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4028436018957346\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.30389602623502715}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4028436018957346\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.28666282 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.28666282 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.1 0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.1 0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.1 0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.1 0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.1 0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.1 0.1 0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2866628168418478, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44495412844036697\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.44311682 0.1        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.44311682 0.1        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42933025347347825, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4474885844748858\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.44311682 0.         0.44311682 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.44311682 0.         0.44311682 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5434642027787826, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.45\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4347713622230261, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4479638009049774\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.44311682098802174}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3478170897784209, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44594594594594594\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4056603773584906\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.34781709 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.2        0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.34781709 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.2        0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.35449345679041744}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3478170897784209, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44594594594594594\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40375586854460094\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35449346 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35449346 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.35449345679041744}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.27825367182273675, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4439461883408072\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40375586854460094\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35449346 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35449346 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.35449345679041744}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.42260293745818944, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44642857142857145\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40375586854460094\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.35449345679041744}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40375586854460094\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33808235 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.2        0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33808235 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.2        0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.483594765432334}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40654205607476634\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.33808235 0.33808235 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.2        0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.33808235 0.33808235 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.2        0.         0.2        0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.5868758123458673}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40930232558139534\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.33808235 0.         0.2        0.         0.\n",
      " 0.         0.         0.2        0.         0.2        0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.33808235 0.         0.2        0.         0.\n",
      " 0.         0.         0.2        0.         0.2        0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.6695006498766938}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41203703703703703\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.2 0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.535600519901355}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.41013824884792627\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.42848041592108405}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40825688073394495\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.2 0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.2 0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.34278433273686726}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4063926940639269\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.2 0.  0.2 0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.2 0.  0.2 0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.27422746618949384}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40454545454545454\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.2193819729515951}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33808234996655157, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4444444444444444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40271493212669685\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.21938197\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.21938197\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.2193819729515951}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2704658799732413, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4424778761061947\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.40271493212669685\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.1755055783612761}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2704658799732413, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4424778761061947\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4009009009009009\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.17550558\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.17550558\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.1755055783612761}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.21637270397859304, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44052863436123346\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.4009009009009009\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.14040446268902088}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.21637270397859304, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44052863436123346\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3991031390134529\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.1123235701512167}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.21637270397859304, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44052863436123346\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39732142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11232357\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11232357\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.1123235701512167}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.17309816318287444, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43859649122807015\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39732142857142855\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.08985885612097337}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.17309816318287444, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43859649122807015\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39555555555555555\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.0718870848967787}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.17309816318287444, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43859649122807015\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3938053097345133\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.05750966791742296}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.17309816318287444, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43859649122807015\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3920704845814978\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.04600773433393837}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.17309816318287444, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43859649122807015\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39035087719298245\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04600773\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.04600773433393837}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.13847853054629955, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4366812227074236\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39035087719298245\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.0368061874671507}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.13847853054629955, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4366812227074236\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.388646288209607\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.02944494997372056}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.13847853054629955, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4366812227074236\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3869565217391304\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.02944495\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.02944494997372056}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.11078282443703964, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43478260869565216\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3869565217391304\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.02944495\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.02944494997372056}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2886262595496317, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43722943722943725\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3869565217391304\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.02944495 0.02944495 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.02944494997372056}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4309010076397054, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4396551724137931\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3869565217391304\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.02944495 0.         0.02944495 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.1 0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.02944494997372056}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.34472080611176437, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43776824034334766\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3869565217391304\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.02944495 0.         0.         0.\n",
      " 0.         0.02944495 0.         0.02944495 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.\n",
      " 0.  0.1 0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.02944494997372056}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4757766448894115, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44017094017094016\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3869565217391304\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.02944495 0.         0.02944495 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.1 0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.02944494997372056}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.38062131591152926, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43829787234042555\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3869565217391304\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38062132 0.         0.         0.         0.         0.\n",
      " 0.38062132 0.         0.         0.         0.         0.38062132\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38062132 0.         0.         0.         0.         0.\n",
      " 0.38062132 0.         0.         0.         0.         0.38062132\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.22355595997897645}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.38062131591152926, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43829787234042555\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38961038961038963\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38062132 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.38062132\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38062132 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.38062132\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3788447679831812}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.38062131591152926, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43829787234042555\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3922413793103448\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.38062132\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.38062132\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.30307581438654496}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.38062131591152926, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43829787234042555\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3905579399141631\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.30307581 0.1        0.30307581 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.30307581 0.1        0.30307581 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.30307581438654496}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5044970527292234, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4406779661016949\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3905579399141631\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.30307581438654496}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.40359764218337874, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4388185654008439\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3905579399141631\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.30307581438654496}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.322878113746703, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4369747899159664\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3905579399141631\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32287811\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32287811\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.24246065150923599}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.322878113746703, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4369747899159664\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3888888888888889\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.24246065150923599}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.2583024909973624, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4351464435146444\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3888888888888889\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.24246065150923599}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20664199279788995, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43333333333333335\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3888888888888889\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.20664199\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.20664199\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3939685212073888}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20664199279788995, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43333333333333335\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39148936170212767\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3939685212073888}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20664199279788995, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43333333333333335\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39148936170212767\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3939685212073888}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.20664199279788995, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43333333333333335\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39148936170212767\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.39396852 0.1        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.39396852 0.1        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3939685212073888}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16531359423831196, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4315352697095436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.39148936170212767\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.16531359\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.31517481696591104}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.16531359423831196, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4315352697095436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3898305084745763\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.31517482 0.1        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.31517482 0.1        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.31517481696591104}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.33225087539064957, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43388429752066116\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3898305084745763\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.         0.         0.31517482 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.         0.         0.31517482 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.31517481696591104}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.4658007003125197, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43621399176954734\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3898305084745763\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31517482 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31517482 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.31517481696591104}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3726405602500158, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4344262295081967\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3898305084745763\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.37264056 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.37264056 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.25213985357272883}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3726405602500158, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4344262295081967\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3881856540084388\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.37264056 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.37264056 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.4017118828581831}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3726405602500158, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4344262295081967\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3907563025210084\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.3213695062865465}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.3726405602500158, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4344262295081967\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3891213389121339\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.1        0.         0.         0.\n",
      " 0.32136951 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.1        0.         0.         0.\n",
      " 0.32136951 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3213695062865465}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.49811244820001266, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43673469387755104\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3891213389121339\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.1        0.         0.         0.\n",
      " 0.         0.         0.32136951 0.32136951 0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.1        0.         0.         0.\n",
      " 0.         0.         0.32136951 0.32136951 0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3213695062865465}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5984899585600101, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43902439024390244\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3891213389121339\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32136951\n",
      " 0.1        0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.1        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32136951\n",
      " 0.1        0.         0.         0.         0.         0.1\n",
      " 0.         0.         0.1        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.3213695062865465}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.47879196684800807, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43724696356275305\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3891213389121339\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32136951\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32136951\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.3213695062865465}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5830335734784065, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43951612903225806\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3891213389121339\n",
      "2 3 0.09090909090909091\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.3213695062865465}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.46642685878272516, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43775100401606426\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3891213389121339\n",
      "2 3 0.09090909090909091\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.2570956050292372}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.46642685878272516, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43775100401606426\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3875\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.20567648402338976}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.46642685878272516, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43775100401606426\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38589211618257263\n",
      "2 3 0.09090909090909091\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.20567648402338976}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.37314148702618016, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38589211618257263\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.37314149\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.37314149\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3645411872187118}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.37314148702618016, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3884297520661157\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37314149 0.37314149 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37314149 0.37314149 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.29163294977496945}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.37314148702618016, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3868312757201646\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37314149 0.37314149 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37314149 0.37314149 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.23330635981997558}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.37314148702618016, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38524590163934425\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37314149 0.37314149 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37314149 0.37314149 0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.3866450878559805}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.37314148702618016, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3877551020408163\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.37314149\n",
      " 0.37314149 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.37314149\n",
      " 0.37314149 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.3093160702847844}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.37314148702618016, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3861788617886179\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.37314149\n",
      " 0.37314149 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.37314149\n",
      " 0.37314149 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.2       ]\n",
      "3 attacking 1\n",
      "1\n",
      "1 3\n",
      "relation {1: {2: 0.5, 3: 0.44745285622782754}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.37314148702618016, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.38866396761133604\n",
      "2 3 0.09090909090909091\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.37314148702618016, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.436\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.35796228 0.\n",
      " 0.         0.         0.35796228 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.35796228 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.35796228 0.\n",
      " 0.         0.         0.35796228 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.35796228 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.49851318962094415, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.43824701195219123\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.35796228 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.35796228 0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 30\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "prob 3 31\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "1 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.1]\n",
      "prob 1 31\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "after [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      "3 attacking 0\n",
      "relation {1: {2: 0.5, 3: 0.35796228498226207}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3870967741935484\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.59881055 0.59881055 0.\n",
      " 0.2        0.2       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.59881055 0.59881055 0.\n",
      " 0.2        0.2       ]\n",
      "prob 3 30\n",
      "relation {1: {2: 0.5, 3: 0.2863698279858097}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.5988105516967553, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.44047619047619047\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3855421686746988\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.28636983 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.28636983 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.2863698279858097}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.6790484413574043, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4426877470355731\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3855421686746988\n",
      "2 3 0.09090909090909091\n",
      "before [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.28636983 0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "after [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.28636983 0.         0.         0.\n",
      " 0.1        0.1       ]\n",
      "1 attacking 3\n",
      "3\n",
      "3 1\n",
      "relation {1: {2: 0.5, 3: 0.2863698279858097}, 2: {1: 0.7440000000000002, 3: 0.09537847296000003}, 3: {1: 0.7432387530859235, 2: 0.16580608000000008}}\n",
      "2 1 1.0\n",
      "3 1 0.4448818897637795\n",
      "1 2 0\n",
      "3 2 0.125\n",
      "1 3 0.3855421686746988\n",
      "2 3 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "ss1.run_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0b30b684-b9c5-487b-b003-125245471b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([0, 1], dtype=int8)),\n",
       " (1, array([1, 0], dtype=int8)),\n",
       " (2, array([1, 2], dtype=int8)),\n",
       " (3, array([1, 8], dtype=int8)),\n",
       " (4, array([2, 1], dtype=int8)),\n",
       " (5, array([2, 5], dtype=int8)),\n",
       " (6, array([2, 3], dtype=int8)),\n",
       " (7, array([3, 2], dtype=int8)),\n",
       " (8, array([4, 5], dtype=int8)),\n",
       " (9, array([5, 6], dtype=int8)),\n",
       " (10, array([5, 2], dtype=int8)),\n",
       " (11, array([5, 4], dtype=int8)),\n",
       " (12, array([6, 7], dtype=int8)),\n",
       " (13, array([6, 5], dtype=int8)),\n",
       " (14, array([7, 8], dtype=int8)),\n",
       " (15, array([7, 6], dtype=int8)),\n",
       " (16, array([8, 9], dtype=int8)),\n",
       " (17, array([8, 1], dtype=int8)),\n",
       " (18, array([8, 7], dtype=int8)),\n",
       " (19, array([9, 8], dtype=int8))]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(env_.board.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "e22eca15-5f6b-4f0a-9f3e-caa15c950365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "bdad0956-fb60-4c9d-99c0-9b8ab15fb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#q_optimizer = optim.Adam(list(qf1.parameters()), lr=args.learning_rate)\n",
    "\n",
    "#actor1_optimizer = optim.Adam(list(actor1.parameters()), lr=args.learning_rate)\n",
    "#actor2_optimizer = optim.Adam(list(actor2.parameters()), lr=args.learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "def agent_action(observation, reward, termination, truncation, info, phase, troops,env,agent,device='cpu'):\n",
    "    \n",
    "    action = env.action_space(agent).sample()                        \n",
    "    #part_0 =np.random.choice(np.where(env.board.calculated_action_mask(agent))[0])\n",
    "    part_0 =np.random.choice(np.where(observation['action_mask'])[0])\n",
    "    action = torch.tensor([\n",
    "                            [\n",
    "                             [part_0],\n",
    "                             [np.around(action[1],2)]\n",
    "                            ]\n",
    "                            ],requires_grad =False).to(device)\n",
    "    \n",
    "    action = action[:,:,0]\n",
    "    action_1 = action[:,0]\n",
    "    action_2 = action[:,1]\n",
    "    act_2_1 = action_1[0]\n",
    "    act_2_2 = action_2[0]\n",
    "\n",
    "    return [act_2_1.clone().detach().cpu().item(), max(act_2_2.clone().detach().cpu().item(),0.001) ]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class sample_and_train(object):\n",
    "    def __init__(self, args,seed=42):\n",
    "        self.args = args\n",
    "        \n",
    "        self.env_config = args['env_config']\n",
    "        self.env = env_risk(**self.env_config)\n",
    "        self.device = args['device']#'cpu'\n",
    "        self.total_agents = len(self.env.possible_agents)\n",
    "        self.total_phases= len(self.env.phases)\n",
    "        self.hero_agents_list_ = [1]\n",
    "        self.the_hero_agent = 1\n",
    "        self.agent_mapper = args['agent_mapper']\n",
    "\n",
    "\n",
    "        self.args['total_agents'] = self.total_agents \n",
    "        self.args['total_phases'] = self.total_phases \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.action_shape = (2,)\n",
    "\n",
    "        self.env.reset(seed=42)\n",
    "        self.total_agents  = len(self.env.possible_agents)\n",
    "        self.total_phases = len(self.env.phases)\n",
    "        self.playe_r = 1\n",
    "\n",
    "\n",
    "\n",
    "        #new_params:\n",
    "        \n",
    "        self.episode_time_lim = args['episode_time_lim']#3000\n",
    "        self.num_iterations = args['num_iterations']#10\n",
    "        self.batch_size = args['model_config']['chunk_size']#100\n",
    "        self.num_episodes = args['num_episodes']#4\n",
    "        self.num_steps = self.num_episodes*self.num_iterations*self.episode_time_lim #120000\n",
    "        \n",
    "        self.run_name = f\"{self.args['env_id']}__{self.args['exp_name']}__{self.args['seed']}__{int(time.time())}\"\n",
    "\n",
    "        TB_log = self.args['TB_log'] \n",
    "        if TB_log:    \n",
    "            self.writer = SummaryWriter(f\"runs/{self.run_name}\")\n",
    "            self.writer.add_text(\n",
    "                \"hyperparameters\",\n",
    "                \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in self.args.items()])),\n",
    "            )\n",
    "        else:\n",
    "            self.writer = None\n",
    "\n",
    "        sample_obs = self.obs_converter(torch.tensor(self.env.last()[0]['observation']\n",
    "                                        ).to(device=self.device),\n",
    "                                        num_classes = self.total_agents+1\n",
    "                                       )\n",
    "        \n",
    "        self.ob_space_shape = sample_obs.shape #env.observation_space(playe_r)['observation'].shape\n",
    "        self.action_mask_shape = self.env.observation_space(self.playe_r)['action_mask'].shape\n",
    "        self.agent_list = list(self.env.possible_agents)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.actor_config_dict =  dict(env=self.env,\n",
    "                        action_space = self.env.observation_space(self.playe_r)['action_mask'].shape[0],\n",
    "                        ob_space=(np.prod(self.ob_space_shape)\n",
    "                         +np.prod(self.action_mask_shape)\n",
    "                         +1*( self.total_agents-1) #the current_agent +1#who actor agent was\n",
    "                         +1*(self.total_phases -1)#the current phase\n",
    "                         +1) # the number of troops\n",
    "                               )\n",
    "        self.init_hero_agent()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def init_hero_agent(self):\n",
    "        self.hero_agents_list = {i:model_mapper(i,self.agent_mapper) for i in \n",
    "                                 self.hero_agents_list_ } # this is a list , need to pass it as an argument\n",
    "\n",
    "        \n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].init_properties(self.total_agents,self.env.phases)\n",
    "            self.hero_agents_list[i].set_device()\n",
    "\n",
    "            #init_model(self,actor_config_dict,device)\n",
    "            \n",
    "            self.hero_agents_list[i].init_model(#model_name='DDPG', \n",
    "                                                #kwarg = dict( \n",
    "                                                actor_config_dict = self.actor_config_dict,\n",
    "                                                args = self.args,\n",
    "                                                device = self.device,\n",
    "                                                writer=self.writer,\n",
    "                                                run_name=self.run_name,\n",
    "                                                agent=i#)\n",
    "                                                )\n",
    "\n",
    "\n",
    "    def init_per_epi_data(self):\n",
    "        selector = self.episode_time_lim#self.num_steps\n",
    "        obs = torch.zeros((selector,) + self.ob_space_shape, requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        actions_1 = torch.zeros((selector,) ).to(self.device,    dtype = torch.float32)\n",
    "        actions_2 = torch.zeros( (selector,)).to(self.device,    dtype = torch.float32)\n",
    "        log_probs_actions_2 = torch.zeros( (selector,)).to(self.device,    dtype = torch.float32)\n",
    "        action_masks = torch.zeros((selector, ) + self.action_mask_shape, requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        current_agent = torch.zeros((selector,1), requires_grad =False).to(self.device,    dtype = torch.float32)*0#-1\n",
    "        current_agent_acting = torch.ones((selector,1), requires_grad =False).to(self.device,    dtype = torch.float32)*0\n",
    "        current_phase = torch.zeros((selector,1), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        current_troops_count = torch.zeros((selector,self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        #logprobs = torch.zeros((self.num_steps, ), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        rewards = torch.zeros((selector, self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        rewards_2 = torch.zeros((selector, self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        returntogo = torch.zeros((selector, self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        dones = torch.zeros((selector, self.total_agents), requires_grad =False).to(self.device)\n",
    "        dones_2 = torch.zeros((selector, self.total_agents), requires_grad =False).to(self.device)\n",
    "        #values = torch.zeros((self.num_steps,  )).to(self.device)\n",
    "        episodes = torch.ones((selector, ), requires_grad =False).to(self.device,    dtype = torch.float32)*-1\n",
    "        t_next = torch.zeros((selector, self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32) \n",
    "        total_rewards = {i:0 for i in self.env.possible_agents} #i can report this\n",
    "        #trace = tensor.zeros((self.context_len,self.qnet_config_dict['ob_space']))\n",
    "        action=1\n",
    "        return (\n",
    "                    obs,actions_1,actions_2,log_probs_actions_2,action_masks,\n",
    "                    current_agent,current_agent_acting,current_phase,current_troops_count,\n",
    "                    rewards,rewards_2,returntogo,dones,dones_2,episodes,t_next,total_rewards,\n",
    "                    action \n",
    "                )\n",
    "\n",
    "    def reset_moves_hero_agents(self):\n",
    "        self.Personality_bot = Personality_bot()\n",
    "        \n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].init_move_count_epi(self.env.phases)\n",
    "\n",
    "\n",
    "    def run_learning_loop(self):\n",
    "\n",
    "        self.env.reset(seed=self.args['seed'])\n",
    "        random.seed(self.args['seed'])\n",
    "        np.random.seed(self.args['seed'])\n",
    "        torch.manual_seed(self.args['seed'])\n",
    "        torch.backends.cudnn.deterministic = self.args['torch_deterministic']\n",
    "\n",
    "        \n",
    "        self.train_loop_init()\n",
    "        curren_epi =0\n",
    "        self.set_memories()\n",
    "        self.training_performance_return = []\n",
    "        self.relation_record_dataset = dict({})\n",
    "        \n",
    "        for iteration in range(1, self.num_iterations+1):\n",
    "            curren_epi,global_break, local_break = self.sample_train(curren_epi,iteration)\n",
    "            if global_break:\n",
    "                print('global_break_3')\n",
    "                break \n",
    "        self.save_relations()\n",
    "\n",
    "    def set_memories(self):\n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].init_buffer(action_space = self.env.action_space(1),\n",
    "                                                 buffer_size=self.args['model_config']['rb_len'])\n",
    "    def sample_train(self,curren_epi,iteration):\n",
    "        step = 0 #steps per iteration\n",
    "        fault_condition = False\n",
    "        clear_output(wait=True)\n",
    "        phase = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        for episode in range(self.num_episodes):\n",
    "            \n",
    "            \n",
    "            step, fault_condition,global_break,local_break = self.sample(iteration,curren_epi,step,fault_condition,clear_output,phase)\n",
    "            self.train(curren_epi,iteration)\n",
    "            curren_epi+=1\n",
    "            \n",
    "            if global_break:\n",
    "                print('global_break_2')\n",
    "                break \n",
    "        \n",
    "        return curren_epi, global_break, local_break\n",
    "        \n",
    "    def train(self,episode_count,iteration):\n",
    "        losses = dict({})\n",
    "        for i in self.hero_agents_list:\n",
    "            if self.hero_agents_list[i].rb.size()>=self.batch_size:\n",
    "                losses[i] = self.hero_agents_list[i].train(episode_count,iteration, batch_size = self.batch_size)\n",
    "\n",
    "        if self.args['TB_log']:\n",
    "            self.write_learning(episode_count,losses)\n",
    "                \n",
    "    \n",
    "    def sample(self,iteration,curren_epi,step,fault_condition,clear_output,phase):\n",
    "\n",
    "        self.hero_agents_list[1].init_optim()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            if fault_condition:\n",
    "                self.env = env_risk(**(self.env_config  #| {\"render_mode\" : None,\"bad_mov_penalization\" : 0.01,\"render_\":False#False\n",
    "                                                        # }\n",
    "                                     ))\n",
    "                self.env.observation_space(1)['observation'].dtype =np.float32\n",
    "\n",
    "\n",
    "            \n",
    "            self.env.reset(seed=self.args['seed'])\n",
    "            \n",
    "            self.reset_moves_hero_agents()\n",
    "            fault_condition = False\n",
    "            step_count = 0\n",
    "            is_draw = 0\n",
    "\n",
    "\n",
    "            (obs,actions_1,actions_2,log_probs_actions_2,action_masks,\n",
    "            current_agent,current_agent_acting,current_phase,current_troops_count,\n",
    "            rewards,rewards_2,returntogo,dones,dones_2,episodes,t_next,total_rewards,\n",
    "            action \n",
    "            ) = self.init_per_epi_data()\n",
    "\n",
    "            for i in self.hero_agents_list:\n",
    "                self.hero_agents_list[i].init_CL_sample_store(self.num_steps\n",
    "                                                             ,self.total_agents,self.total_phases\n",
    "                                                             )\n",
    "            \n",
    "\n",
    "            #observation, reward, termination, truncation, info = env.last()\n",
    "\n",
    "            #iter_ = 0\n",
    "            \n",
    "            for agent in self.env.agent_iter():\n",
    "                e_t = self.env.terminations\n",
    "                if sum(e_t.values()) <(self.env.max_num_agents-1):\n",
    "                    observation, reward, termination, truncation, info = self.env.last()\n",
    "\n",
    "                    observation_ = deepcopy(observation)\n",
    "                    observation_['observation'] = torch.tensor(observation_['observation']).clone().cpu().to(dtype=torch.int32).numpy()\n",
    "                    \n",
    "                    (phase,troops,mask,observation,curr_agent,\n",
    "                     phase_mapping,curr_agent_mapping) =self.process_obs(observation, reward, termination, truncation, info,agent)\n",
    "\n",
    "                    self.hero_agents_list[self.the_hero_agent].current_model_in(observation,\n",
    "                                curr_agent,\n",
    "                                phase_mapping,\n",
    "                                curr_agent_mapping,\n",
    "                                env_board_agents=self.env.board.agents\n",
    "                                      )\n",
    "                    \n",
    "\n",
    "                    #update records\n",
    "                    episodes[step_count] = curren_epi\n",
    "                    obs[step_count] = observation['observation'] #torch.Tensor(observation['observation']).to(self.device) #sould i not add it .... meaning this is the last observation after the player dies\n",
    "                    action_masks[step_count] = torch.Tensor(observation['action_mask']).to(self.device)\n",
    "                    current_agent[step_count] = curr_agent\n",
    "                    current_phase[step_count] = phase = self.env.phase_selection\n",
    "                    current_troops_count[step_count] = torch.tensor([self.env.board.agents[i].bucket \n",
    "                                                                     for i in self.env.possible_agents],requires_grad =False).to(self.device)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                        \n",
    "\n",
    "                    #ACTIONS\n",
    "                    if agent not in self.hero_agents_list:\n",
    "\n",
    "                        #so this is new thing\n",
    "                        action_ = self.Personality_bot.agent_action(observation_, reward, termination, truncation, info, phase, troops,self.env,agent)\n",
    "\n",
    "                        \n",
    "                        #action_ = agent_action(observation, reward, termination, truncation, info, phase, troops,self.env,agent)\n",
    "                    else:\n",
    "                        \n",
    "                        \n",
    "                        a1,a2,v = self.hero_agents_list[self.the_hero_agent].action_predict(self.hero_agents_list[\n",
    "                                                                                                    self.the_hero_agent].model_in,\n",
    "                                                                                                    mask=mask,\n",
    "                                                                                                    use_action_mask=True, #will have to check this later\n",
    "                                                                                                    no_grad = 1)   \n",
    "                                                                                                    \n",
    "                        action_ = [int(a1),float(a2[0,0])]\n",
    "                        \n",
    "                        #print(action_)\n",
    "\n",
    "                        #print(action_[0],action_[1])\n",
    "\n",
    "\n",
    "                    actions_1[step_count] = action_[0]\n",
    "                    actions_2[step_count] = action_[1]\n",
    "                    curr_agent_ = int(curr_agent)\n",
    "\n",
    "                    if not observation['action_mask'][int(action_[0])]: \n",
    "                        fault_condition =True\n",
    "                        if  curr_agent_ in self.hero_agents_list:\n",
    "                            self.hero_agents_list[curr_agent_].bad_move_count+=1\n",
    "                            self.hero_agents_list[curr_agent_].bad_move_phase_count[int(current_phase[step_count][0])]+=1  # when is the where_is_it_performing_bad_really\n",
    "                            #print('here',agent, action, observation['action_mask'])\n",
    "                    if  curr_agent_ in self.hero_agents_list:\n",
    "                        self.hero_agents_list[curr_agent_].move_count[int(current_phase[step_count][0])]+=1  \n",
    "\n",
    "\n",
    "\n",
    "                    curr_reward_list,is_draw = self.handle_episode_rewards(curr_agent,step_count,is_draw)\n",
    "\n",
    "                    rewards_2[step_count] = torch.tensor([curr_reward_list[i] for i in self.env.possible_agents]).to(self.device,dtype=torch.float32)\n",
    "                    if step >1:\n",
    "                        dones_2[step_count] = torch.tensor([ int(self.env.terminations[i]) - dones_2[step_count-1,i-1]  for i in self.env.possible_agents]).to(self.device)\n",
    "                    else:\n",
    "                        dones_2[step_count] = torch.tensor([self.env.terminations[i] for i in self.env.possible_agents]).to(self.device)\n",
    "\n",
    "\n",
    "                    if phase == 1: # now the other agents are social.\n",
    "                        #print(act_2_1,part_0)\n",
    "                        #print(observation_)\n",
    "                        self.Personality_bot.update_history(observation_,self.env,agent,int(action_[0]))\n",
    "                        #self.Personality_bot.print_relation()\n",
    "                    \n",
    "                    \n",
    "                    #env step\n",
    "\n",
    "                    #self.write_relation(step_count)\n",
    "                    self.env.step(action_)\n",
    "\n",
    "                    #increase step\n",
    "                    for age_i in self.env.possible_agents:\n",
    "                        total_rewards[age_i]+=curr_reward_list[age_i] #env.curr_rewards[age_i] if (step_count != episode_time_lim) else -100\n",
    "                                   \n",
    "                    \n",
    "                    step +=1\n",
    "                    self.global_step+=1\n",
    "\n",
    "                else:\n",
    "                    self.training_performance_return.append(total_rewards[1])\n",
    "                    print('done:',self.env.terminations,#env.terminations.values(),\n",
    "                           \",total_reward:\",total_rewards, ',iteration:',iteration,\",episode:\", curren_epi )\n",
    "                    print(self.env.board.territories)\n",
    "                    break\n",
    "                    \n",
    "                step_count+=1\n",
    "\n",
    "                if self.global_step == self.num_steps:\n",
    "                    print('global_break_1')\n",
    "                    print('done:',self.env.terminations,#env.terminations.values(),\n",
    "                           \",total_reward:\",total_rewards, ',iteration:',iteration,\",episode:\", curren_epi )\n",
    "                    print(self.env.board.territories)\n",
    "                    self.training_performance_return.append(total_rewards[1])\n",
    "                    break\n",
    "\n",
    "                if step_count == self.episode_time_lim:\n",
    "                    print('local_break_1')\n",
    "                    print('done:',self.env.terminations,#env.terminations.values(),\n",
    "                           \",total_reward:\",total_rewards, ',iteration:',iteration,\",episode:\", curren_epi )\n",
    "                    print(self.env.board.territories)\n",
    "                    self.training_performance_return.append(total_rewards[1])\n",
    "                    break \n",
    "                \n",
    "\n",
    "                cur_epi_list = (episodes == curren_epi)\n",
    "\n",
    "            #print(obs)\n",
    "            self.find_player_position(curren_epi,total_rewards)\n",
    "            \n",
    "            if self.args['TB_log']:\n",
    "                    self.write_exploring(is_draw,#position,\n",
    "                            curren_epi,step,\n",
    "                            step_count,\n",
    "                            total_rewards,#bad_move_count\n",
    "                            #,bad_move_phase_count,\n",
    "                            #move_count,\n",
    "                            observation,\n",
    "                            self.env,\n",
    "                            cur_epi_list,\n",
    "                            current_agent_acting)\n",
    "\n",
    "            \n",
    "            \n",
    "            print(len(actions_1[:step_count]), len(actions_1[cur_epi_list]))\n",
    "            for i in self.hero_agents_list:\n",
    "                #print(obs)\n",
    "                self.hero_agents_list[i].update_train_data(\n",
    "                         step_count,\n",
    "                         obs,\n",
    "                            self.ob_space_shape,\n",
    "                            rewards_2[:,i-1][:step_count],\n",
    "                            dones_2[:,i-1][:step_count],\n",
    "                            actions_1[:step_count],\n",
    "                            actions_2[:step_count],\n",
    "                            log_probs_actions_2[:step_count],\n",
    "                            action_masks[:step_count],\n",
    "                            current_agent[:step_count],\n",
    "                            current_agent_acting[:step_count],\n",
    "                            current_phase[:step_count],\n",
    "                            current_troops_count[:,i-1][:step_count],\n",
    "                            map_agent_phase_vector = self.map_agent_phase_vector,\n",
    "                            \n",
    "                         )\n",
    "\n",
    "\n",
    "        return step, fault_condition, (self.global_step == self.num_steps),(step_count == self.num_steps)\n",
    "                #print(iter_)\n",
    "                #iter_+=1\n",
    "\n",
    "\n",
    "    def update_relation_record_dataset(self,episode,position):\n",
    "        self.relation_record_dataset[episode] = {'values':self.Personality_bot.relation_tracker,'position':position}\n",
    "\n",
    "    def save_relations(self):\n",
    "        \n",
    "        \n",
    "        # Store data (serialize)\n",
    "        with open(f'relations_data/{self.run_name}.pickle', 'wb') as handle:\n",
    "            pickle.dump(self.relation_record_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "    def write_relation(self,step):\n",
    "        for i in self.Personality_bot.relation:\n",
    "            for j,k in self.Personality_bot.relation[i].items():\n",
    "                \n",
    "                self.writer.add_scalar(f\"relations/{i}_pbt_attack_{j}\",k,(step +1))\n",
    "\n",
    "    def handle_episode_rewards(self,curr_agent,step_count,is_draw):\n",
    "        curr_reward_list =  self.env.curr_rewards\n",
    "                            \n",
    "        if (step_count == (self.episode_time_lim-1))   or (self.global_step == (self.num_steps-1)): # draw reward\n",
    "            is_draw=1\n",
    "            curr_reward_list = {i:-100 for i in self.env.possible_agents }\n",
    "\n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].update_CL_sample_store(curr_agent_=curr_agent,\n",
    "                          inp = {'step':step_count,\n",
    "                                 'act_2_1':None ,\n",
    "                                 'act_2_2':None ,\n",
    "                                 'curr_reward_list':curr_reward_list[i]\n",
    "                          },before_action=4)\n",
    "\n",
    "        return curr_reward_list,is_draw\n",
    "        \n",
    "\n",
    "    def find_player_position(self,curren_epi,total_rewards):\n",
    "        for i in self.hero_agents_list:\n",
    "                    self.hero_agents_list[i].position =self.total_agents\n",
    "                    \n",
    "                    \n",
    "        #[ position = 3 for i in ] \n",
    "        positon_ = {i:self.total_agents for i in self.env.possible_agents}\n",
    "        for k_,(i_,j_) in enumerate(sorted([(b_,a_) for a_,b_ in total_rewards.items()],reverse=True) \n",
    "              ):\n",
    "\n",
    "            positon_[int(j_)] = k_+1\n",
    "            if int(j_) in self.hero_agents_list:\n",
    "                self.hero_agents_list[int(j_)].position = k_+1\n",
    "                print(j_,self.hero_agents_list[int(j_)].position)\n",
    "                #adding this here ... i might have to change it\n",
    "    \n",
    "        self.update_relation_record_dataset(episode=curren_epi,position = positon_)\n",
    "        #update_relation_record_dataset(self,episode,position)\n",
    "    \n",
    "    def process_obs(self,observation, reward, termination, truncation, info,agent):\n",
    "\n",
    "        phase = self.env.phase_selection\n",
    "        troops = self.env.board.agents[agent-1].bucket\n",
    "        \n",
    "        mask = observation[\"action_mask\"]\n",
    "\n",
    "\n",
    "        observation['observation'] =  self.obs_converter(\n",
    "                                            torch.tensor(\n",
    "                                                observation['observation']\n",
    "                                            ).to(self.device,dtype=torch.float32),\n",
    "                                            num_classes = self.total_agents+1)\n",
    "        observation['observation'][:,-1]  =  (observation['observation'][:,-1] - 5.2496)/1.4733\n",
    "        curr_agent = agent\n",
    "        phase_mapping = self.map_agent_phase_hot(phase,num_classes = self.total_phases).float()\n",
    "        curr_agent_mapping = self.map_agent_phase_hot(int(curr_agent)-1,\n",
    "                                                          num_classes = self.total_agents \n",
    "                                                         ).float()\n",
    "\n",
    "        return (phase,troops,mask,observation,curr_agent,\n",
    "                phase_mapping,curr_agent_mapping)\n",
    "\n",
    "        \n",
    "    \n",
    "    def obs_converter(self,  data, num_classes = 4, col =0 ):\n",
    "\n",
    "        if col != None:\n",
    "\n",
    "            #print(data.device)\n",
    "            #print(nn.functional.one_hot(data[:4,col].detach().long(), \n",
    "            #                                            num_classes = num_classes).to(self.device))\n",
    "            return torch.concat((nn.functional.one_hot(data[:,col].detach().long(), \n",
    "                                                        num_classes = num_classes).to(self.device),\n",
    "                                      data[:,~col,None]\n",
    "                                ),axis=1\n",
    "                               )[:,1:].to(self.device)\n",
    "    \n",
    "    def map_agent_phase_hot(self, data,num_classes = 3):\n",
    "        with torch.no_grad():\n",
    "            return nn.functional.one_hot(torch.tensor(data),num_classes = num_classes)[1:].to(self.device)\n",
    "    \n",
    "    def map_agent_phase_vector(self, data,num_classes = 3):\n",
    "        with torch.no_grad():\n",
    "            return nn.functional.one_hot(data[:,0].long(), \n",
    "                                         num_classes = num_classes)[:,1:].to(self.device)\n",
    "\n",
    "\n",
    "    def train_loop_init(self):\n",
    "        self.gamma_t = {i:0 for i in self.env.possible_agents}\n",
    "        \n",
    "        \n",
    "        self.draw_count = 0\n",
    "\n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].init_win_count_iter(self.total_agents )\n",
    "            self.hero_agents_list[i].init_path()\n",
    "        \n",
    "        self.start_time = time.time()\n",
    "        self.global_step = 0\n",
    "        #self.faulting_player = \"\"\n",
    "\n",
    "    def write_learning(self,episode,losses):\n",
    "        \n",
    "        for i in losses:\n",
    "            self.hero_agents_list[i].write_learning(episode,losses[i])\n",
    "        \n",
    "\n",
    "    def write_exploring(self,is_draw,#position,\n",
    "                        curren_epi,step,\n",
    "                        step_count,\n",
    "                        total_rewards,#bad_move_count\n",
    "                        #,bad_move_phase_count,\n",
    "                        #move_count,\n",
    "                        observation,\n",
    "                        env,\n",
    "                        cur_epi_list,\n",
    "                        current_agent_acting):\n",
    "\n",
    "        \n",
    "\n",
    "        if is_draw:\n",
    "            self.draw_count +=1\n",
    "\n",
    "            for i in self.hero_agents_list:\n",
    "\n",
    "                self.writer.add_scalar(f\"draw_charts_agent_{i}/position_draw\",self.hero_agents_list[i].position\n",
    "                                                                                            ,self.draw_count) #draw_count is the number of draw episodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                self.hero_agents_list[i].draw_territory_count = int((self.env.board.territories[:,0] ==i).sum()) #this is the total number of states\n",
    "                \n",
    "                self.hero_agents_list[i].count_draw_dict[\n",
    "                                                        self.hero_agents_list[i].position\n",
    "                                                        ] +=1\n",
    "                self.writer.add_scalar(f\"draw_charts_agent_{i}/draw_territory_count\",\n",
    "                                                                               self.hero_agents_list[i].draw_territory_count,\n",
    "                                                                               self.draw_count)#self.global_step)\n",
    "                \n",
    "                for j in self.hero_agents_list[i].count_draw_dict:\n",
    "                    self.writer.add_scalar(f\"draw_charts_agent_{i}/{j}_position_prop_draw\",int(\n",
    "                                                                                            self.hero_agents_list[i].position==j\n",
    "                                                                                            ),self.draw_count)\n",
    "\n",
    "                    if j not in [1,2]:\n",
    "                        self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_all_prop\",int(\n",
    "                                                                                            self.hero_agents_list[i].position==j\n",
    "                                                                                            ),(curren_epi+1))\n",
    "\n",
    "                        self.writer.add_scalar(f\"draw_charts_agent_{i}/{j}_place_in_draw\",\n",
    "                                                                   self.hero_agents_list[i].count_draw_dict[j],\n",
    "                                                                   self.draw_count)\n",
    "\n",
    "                        self.writer.add_scalar(f\"draw_charts_agent_{i}/{j}_place_in_draw_ratio\",\n",
    "                                                                   self.hero_agents_list[i].count_draw_dict[j]/self.draw_count,\n",
    "                                                                   self.draw_count)\n",
    "                        \n",
    "                    \n",
    "            self.writer.add_scalar(\"draw_charts/draw_count\",self.draw_count,(curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(\"draw_charts/draw\",1,(curren_epi+1))\n",
    "            self.writer.add_scalar(\"draw_charts/draw_to_total_count\",self.draw_count/(curren_epi +1+0.000001),(curren_epi +1))#self.global_step)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            non_draw_count =(curren_epi-self.draw_count+1+0.000001)\n",
    "            for i in self.hero_agents_list:\n",
    "\n",
    "                self.writer.add_scalar(f\"win_charts_agent_{i}/position_win\",self.hero_agents_list[i].position\n",
    "                                                                                            ,(curren_epi+1))\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                self.hero_agents_list[i].count_dict[self.hero_agents_list[i].position\n",
    "                                               ] +=1\n",
    "\n",
    "                \n",
    "                for j in self.hero_agents_list[i].count_dict:\n",
    "                    self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_prop\",int(\n",
    "                                                            self.hero_agents_list[i].position==j\n",
    "                                                            ),(curren_epi+1))\n",
    "\n",
    "                    self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position\",self.hero_agents_list[i].count_dict[j],\n",
    "                                           (curren_epi+1))\n",
    "\n",
    "                    self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_to_total_terminated\",self.hero_agents_list[i].count_dict[j]/non_draw_count,(curren_epi+1))\n",
    "\n",
    "                    if j not in [1,2]:\n",
    "                        self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_all_prop\",int(\n",
    "                                                                                            self.hero_agents_list[i].position==j\n",
    "                                                                                            ),(curren_epi+1))\n",
    "\n",
    "\n",
    "            self.writer.add_scalar(\"draw_charts/draw\",0,(curren_epi+1))\n",
    "            \n",
    "        for i in self.hero_agents_list:\n",
    "\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/model_move_count_per_episode\",   sum(current_agent_acting[:step_count] ==i)  ,  (curren_epi +1))\n",
    "\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/model_2_total_move_count_per_episode\",   sum(current_agent_acting[:step_count] ==i)/sum( self.hero_agents_list[i].move_count.values()),  (curren_epi +1))\n",
    "\n",
    "            self.writer.add_scalar(f\"win_charts_agent_{i}/position_all\",self.hero_agents_list[i].position\n",
    "                                                                                            ,(curren_epi+1))\n",
    "\n",
    "            \n",
    "            for j in self.hero_agents_list[i].count_dict:\n",
    "                self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_to_total\",(\n",
    "                                                            self.hero_agents_list[i].count_dict[j]+\n",
    "                                                            self.hero_agents_list[i].count_draw_dict[j]\n",
    "                                                        \n",
    "                                                            )/(curren_epi +1+0.00001 ),(curren_epi+1))#global_step)\n",
    "\n",
    "            \n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_count_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_count,            (curren_epi +1))#self.global_step)\n",
    "                \n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_count_position_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[0],            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_count_attack_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[1],            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_count_fortify_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[2],            (curren_epi +1))#self.global_step)\n",
    "            \n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/total_moves\",sum(\n",
    "                                                    self.hero_agents_list[i].move_count.values()),            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_to_step_count_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_count/(sum(\n",
    "                                                   self.hero_agents_list[i].move_count.values())+1),            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_to_step_position_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[0]/( \n",
    "                                                   self.hero_agents_list[i].move_count[0]+1),            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_to_step_attack_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[1]/( \n",
    "                                                   self.hero_agents_list[i].move_count[1]+1),            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_to_step_fortify_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[2]/( \n",
    "                                                   self.hero_agents_list[i].move_count[2]+1),            (curren_epi +1))#self.global_step)\n",
    "\n",
    "        \n",
    "        self.writer.add_scalar(\"charts/epsilon\",(curren_epi/((self.num_iterations*self.num_episodes)/10)),(curren_epi +1))#self.global_step)\n",
    "        self.writer.add_scalar(\"charts/avg_per_epi_total_reward\", np.mean(list(total_rewards.values())), (curren_epi +1))#self.global_step)\n",
    "\n",
    "        \n",
    "\n",
    "        #values_total = {i:0 for i in self.env.possible_agents}\n",
    "        \n",
    "\n",
    "        \n",
    "        self.writer.add_scalar(\"charts/episodic_length\", cur_epi_list[:step].sum(), (curren_epi +1))#self.global_step)\n",
    "        \n",
    "        for i in env.possible_agents:\n",
    "            #cur_index = torch.where((current_agent[:,0] == i) &( cur_epi_list ))[0]\n",
    "\n",
    "            #values_total[i] = values[cur_index].mean()\n",
    "            #writer.add_scalar(\"charts/mean_value_per_epi_agent_\"+str(i), values_total[i], global_step)\n",
    "            \n",
    "            self.writer.add_scalar(\"charts/total_reward_per_epi_agent_\"+str(i), total_rewards[i], (curren_epi +1))#self.global_step)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "f356ac27-2501-4b00-8f30-54998c06e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_12 = dict(\n",
    "exp_name = '_exp9_PPO_social_config2_423_entropy_4_agents_1_hero_norm_small',\n",
    "env_id = 'Tiny_risk',\n",
    "learning_rate = 0.0003,#5e-4,#0.003,#0.0003,\n",
    "batch_size = 2,\n",
    "gamma = 0.999,#0.99\n",
    "seed = 423,\n",
    "agent_mapper={1:'A2C',2:'PPO',3:'DDPG'},\n",
    "\n",
    "entropy_coefficient = 0.01,\n",
    "clip_param = 0.1,\n",
    "max_grad_norm = 0.5,\n",
    "\n",
    "    \n",
    "torch_deterministic= True,\n",
    "num_steps=1600000,\n",
    "num_iterations = 500,\n",
    "episode_time_lim = 3000,#10000,\n",
    "hero_agent_maping = [1,0,0],\n",
    "model_name={1:\"ddpg\"}#,2:'transformer_model'}\n",
    ",entropy=True,\n",
    "return_prob=2,\n",
    "actor_wt = 0.5,\n",
    "CE_wt = 0.01,\n",
    "small = True,\n",
    "num_episodes = 10,\n",
    "context_len = 256,\n",
    "rtg_scale=1,\n",
    "shuffle=True,\n",
    "pin_memory=False,#False,\n",
    "drop_last=True,\n",
    "TB_log=True,\n",
    "learning_starts =100,\n",
    "update_epochs = 1,\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\n",
    "pin_memory_device= (\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\n",
    "    \n",
    "env_config = dict(render_mode = None,#'rgb_array', \n",
    "                    default_attack_all  = True,\n",
    "                    agent_count  = 3#4\n",
    "                    ,use_placement_perc=True,\n",
    "                    render_=False,\n",
    "                    bad_mov_penalization = 0.01\n",
    "                 )\n",
    ",model_config = dict(\n",
    "                    n_blocks      =   3,\n",
    "                    embed_dim     =   64,#128 ,\n",
    "                    context_len   =   256,#256  ,\n",
    "                    n_heads       =   1,\n",
    "                    dropout_p     =   0.1,\n",
    "                    wt_decay      =   0.0001,\n",
    "                    warmup_steps  =   100   ,\n",
    "                    tau           =   0.15, #0.95\n",
    "                    chunk_size    =   2000,#64,#8,#32,#64\n",
    "                    chunk_overlap =   1,\n",
    "                    rb_len        =   20*3000, #20\n",
    "\n",
    "\n",
    "                    policy_frequency  =2,\n",
    "                \n",
    "                    warmup_epoch  =   5,  \n",
    "                    total_epoch   =   20,\n",
    "                    initial_lr    =   5e-4,\n",
    "                    final_lr      =   1e-6,\n",
    "\n",
    "                    beta           = 0.5,#args.model_config['beta']         #0.2 #Q_mse\n",
    "                    alpha          = 1,#args.model_config['alpha']          #0.1  #actionloss\n",
    "                    entropy_coeff  = 0.2,#args.model_config['entropy_coeff']         #0.1#0.5   #entropy loss in action\n",
    "                    val_loss_coeff = 0.5#args.model_config['val_loss_coeff']        #0.5      #Q loss\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "                    )\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ad353-f486-40de-82bb-c0a13ba227c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9346805a-1ea2-429c-9a6c-234a60e94d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: {1: True, 2: True, 3: True} ,total_reward: {1: -200.28, 2: -98.16, 3: 107.83} ,iteration: 500 ,episode: 4990\n",
      "[[3 tensor(1.)]\n",
      " [3 tensor(3.)]\n",
      " [3 tensor(2.)]\n",
      " [3 tensor(6.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(1.)]\n",
      " [0 tensor(0.)]\n",
      " [0 tensor(0.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(7.)]]\n",
      "1 3\n",
      "1169 1169\n",
      "epoch 4990 qf1_loss tensor(11.6478, grad_fn=<MseLossBackward0>)\n",
      "actor_loss_1 0.14698147773742676 actor_loss_2 0.1259477734565735\n",
      "done: {1: True, 2: True, 3: True} ,total_reward: {1: -200.26, 2: 108.82000000000001, 3: -98.21} ,iteration: 500 ,episode: 4991\n",
      "[[2 tensor(7.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(4.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(2.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(6.)]]\n",
      "1 3\n",
      "1248 1248\n",
      "epoch 4991 qf1_loss tensor(24.3737, grad_fn=<MseLossBackward0>)\n",
      "local_break_1\n",
      "done: {1: True, 2: False, 3: False} ,total_reward: {1: -200.15, 2: -95.61999999999999, 3: -94.64999999999999} ,iteration: 500 ,episode: 4992\n",
      "[[2 tensor(3.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(2.)]\n",
      " [2 tensor(10.)]\n",
      " [3 tensor(6.)]\n",
      " [3 tensor(2.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(3.)]\n",
      " [3 tensor(3.)]\n",
      " [3 tensor(9.)]]\n",
      "1 3\n",
      "3000 2999\n",
      "epoch 4992 qf1_loss tensor(27.3650, grad_fn=<MseLossBackward0>)\n",
      "actor_loss_1 0.19937777519226074 actor_loss_2 -0.02097056619822979\n",
      "done: {1: True, 2: True, 3: True} ,total_reward: {1: -200.26999999999998, 2: -98.17, 3: 108.41000000000001} ,iteration: 500 ,episode: 4993\n",
      "[[3 tensor(1.)]\n",
      " [3 tensor(6.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(2.)]\n",
      " [3 tensor(12.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(7.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(1.)]]\n",
      "1 3\n",
      "2103 2103\n",
      "epoch 4993 qf1_loss tensor(14.1961, grad_fn=<MseLossBackward0>)\n",
      "done: {1: True, 2: True, 3: True} ,total_reward: {1: -200.19, 2: 108.72, 3: -99.16} ,iteration: 500 ,episode: 4994\n",
      "[[2 tensor(3.)]\n",
      " [2 tensor(2.)]\n",
      " [2 tensor(2.)]\n",
      " [2 tensor(4.)]\n",
      " [2 tensor(2.)]\n",
      " [2 tensor(1.)]\n",
      " [0 tensor(0.)]\n",
      " [0 tensor(0.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(4.)]]\n",
      "1 3\n",
      "1096 1096\n",
      "epoch 4994 qf1_loss tensor(24.1441, grad_fn=<MseLossBackward0>)\n",
      "actor_loss_1 0.0424111932516098 actor_loss_2 0.14215576648712158\n",
      "local_break_1\n",
      "done: {1: True, 2: False, 3: False} ,total_reward: {1: -200.18, 2: -93.76999999999998, 3: -98.25} ,iteration: 500 ,episode: 4995\n",
      "[[2 tensor(5.)]\n",
      " [2 tensor(2.)]\n",
      " [3 tensor(10.)]\n",
      " [2 tensor(2.)]\n",
      " [3 tensor(2.)]\n",
      " [0 tensor(0.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(4.)]\n",
      " [2 tensor(2.)]\n",
      " [2 tensor(3.)]]\n",
      "1 3\n",
      "3000 2999\n",
      "epoch 4995 qf1_loss tensor(27.2523, grad_fn=<MseLossBackward0>)\n",
      "done: {1: True, 2: False, 3: True} ,total_reward: {1: -200.25, 2: 11.850000000000003, 3: -100.09} ,iteration: 500 ,episode: 4996\n",
      "[[2 tensor(7.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(3.)]\n",
      " [2 tensor(6.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(2.)]\n",
      " [2 tensor(3.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]]\n",
      "1 3\n",
      "846 846\n",
      "epoch 4996 qf1_loss tensor(14.4143, grad_fn=<MseLossBackward0>)\n",
      "actor_loss_1 0.5565122961997986 actor_loss_2 0.10209952294826508\n",
      "done: {1: True, 2: True, 3: True} ,total_reward: {1: -200.22, 2: 107.83, 3: -98.17} ,iteration: 500 ,episode: 4997\n",
      "[[2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(13.)]\n",
      " [2 tensor(8.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(1.)]\n",
      " [2 tensor(5.)]]\n",
      "1 3\n",
      "1109 1109\n",
      "epoch 4997 qf1_loss tensor(5.8417, grad_fn=<MseLossBackward0>)\n",
      "done: {1: True, 2: True, 3: False} ,total_reward: {1: -100.22, 2: -200.0, 3: 10.97} ,iteration: 500 ,episode: 4998\n",
      "[[3 5.0]\n",
      " [3 3.0]\n",
      " [3 1.0]\n",
      " [3 3.0]\n",
      " [3 1.0]\n",
      " [3 1.0]\n",
      " [3 5.0]\n",
      " [3 1.0]\n",
      " [3 7.0]\n",
      " [3 5.0]]\n",
      "1 2\n",
      "307 307\n",
      "epoch 4998 qf1_loss tensor(23.0760, grad_fn=<MseLossBackward0>)\n",
      "actor_loss_1 0.0536404587328434 actor_loss_2 -0.08221074193716049\n",
      "done: {1: True, 2: True, 3: True} ,total_reward: {1: -99.74999999999999, 2: -200.01, 3: 109.50000000000001} ,iteration: 500 ,episode: 4999\n",
      "[[3 tensor(1.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(1.)]\n",
      " [3 6.0]\n",
      " [3 4.0]\n",
      " [3 tensor(3.)]\n",
      " [3 tensor(3.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(1.)]\n",
      " [3 tensor(24.)]]\n",
      "1 2\n",
      "1849 1849\n",
      "epoch 4999 qf1_loss tensor(18.3444, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "smp = sample_and_train(args=exp_12)\n",
    "smp.run_learning_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c953d22-69a1-4bb4-83a3-1d36495c8f85",
   "metadata": {},
   "source": [
    "A. DDPG - Robust Starting Combination:\n",
    "\n",
    "Actor Learning Rate (actor_lr): 1e-4 (0.0001) - Conservative, for stability.\n",
    "\n",
    "Critic Learning Rate (critic_lr or q_lr): 1e-3 (0.001) - Slightly higher than actor, often used in DDPG.\n",
    "\n",
    "Actor Network Architecture: 2 hidden layers, 256 units per layer, ReLU activations, tanh output for continuous actions.\n",
    "\n",
    "Critic Network Architecture: 2 hidden layers, 256 units per layer, ReLU activations.\n",
    "\n",
    "Target Network Update Rate (tau or soft_tau): 0.005 - A common value for soft updates, balancing stability and tracking.\n",
    "\n",
    "Replay Buffer Size (buffer_size): 1e6 (1,000,000) - Large buffer for diverse experiences.\n",
    "\n",
    "Batch Size (batch_size): 100 or 128 - Moderate batch size, good balance.\n",
    "\n",
    "Discount Factor (gamma): 0.99 - High for long-term planning in RISK.\n",
    "\n",
    "Policy Update Frequency (policy_frequency): 2 - Update actor every 2 critic updates (more stable).\n",
    "\n",
    "Exploration Noise: Ornstein-Uhlenbeck (OU) Process: theta=0.15, sigma=0.2 - Common OU noise parameters for continuous actions.\n",
    "\n",
    "Gradient Clipping (max_grad_norm): 1.0 (for both actor and critic, clip norm) - Moderate clipping for stability.\n",
    "\n",
    "Optimizer: Adam for both actor and critic optimizers.\n",
    "\n",
    "B. A2C - Robust Starting Combination:\n",
    "\n",
    "Actor Learning Rate (actor_lr): 3e-4 (0.0003) - Slightly higher than DDPG, on-policy learning.\n",
    "\n",
    "Critic Learning Rate (critic_lr): 1e-3 (0.001)\n",
    "\n",
    "Actor Network Architecture: 2 hidden layers, 256 units per layer, ReLU activations, Softmax output for discrete actions (or Gaussian parameters for continuous).\n",
    "\n",
    "Critic Network Architecture: 2 hidden layers, 256 units per layer, ReLU activations.\n",
    "\n",
    "Discount Factor (gamma): 0.99\n",
    "\n",
    "Entropy Coefficient (entropy_coefficient): 0.01 - Moderate entropy bonus for exploration.\n",
    "\n",
    "Value Function Coefficient (vf_coef): 0.5 - Standard balance for value loss.\n",
    "\n",
    "GAE (gae_lambda): 0.95 or 0.97 - Common GAE values for variance reduction.\n",
    "\n",
    "Rollout Length (n_steps or rollout_steps): Experiment with different rollout lengths. Start with something like 128 or 256.\n",
    "\n",
    "Gradient Clipping (max_grad_norm): 1.0 (for both actor and critic, clip norm)\n",
    "\n",
    "Optimizer: Adam for both actor and critic optimizers.\n",
    "\n",
    "C. PPO - Robust Starting Combination:\n",
    "\n",
    "Actor Learning Rate (actor_lr): 3e-4 (0.0003)\n",
    "\n",
    "Critic Learning Rate (critic_lr): 1e-3 (0.001)\n",
    "\n",
    "Actor Network Architecture: 2 hidden layers, 256 units per layer, ReLU activations, Softmax output for discrete actions (or Gaussian parameters for continuous).\n",
    "\n",
    "Critic Network Architecture: 2 hidden layers, 256 units per layer, ReLU activations.\n",
    "\n",
    "Discount Factor (gamma): 0.99\n",
    "\n",
    "Clip Parameter (clip_param or epsilon): 0.2 - Standard PPO clipping value.\n",
    "\n",
    "Entropy Coefficient (entropy_coefficient): 0.01\n",
    "\n",
    "Value Function Coefficient (vf_coef): 0.5\n",
    "\n",
    "Number of PPO Epochs per Update (num_ppo_epochs or update_epochs): 10 epochs - Common PPO epoch count.\n",
    "\n",
    "Mini-Batch Size (mini_batch_size): 64 or 128\n",
    "\n",
    "GAE (gae_lambda): 0.95 or 0.97\n",
    "\n",
    "Rollout Length (n_steps or rollout_steps): Experiment with longer rollouts, e.g., 2048 or 4096 (if computationally feasible).\n",
    "\n",
    "Gradient Clipping (max_grad_norm): 1.0 (for both actor and critic, clip norm)\n",
    "\n",
    "Optimizer: Adam for both actor and critic optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "b52a21f9-cea0-47d8-99e3-a6e4ef509d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_13 = dict(\n",
    "exp_name = '_exp11_ddpg_social_config2_432_entropy_4_agents_1_hero_norm_small',\n",
    "env_id = 'Tiny_risk',\n",
    "learning_rate = 0.001,#5e-4,#0.003,#0.0003,\n",
    "batch_size = 2,\n",
    "gamma = 0.999,#0.99\n",
    "seed = 432,\n",
    "agent_mapper={1:'DDPG',2:'A2C',3:'PPO'},\n",
    "\n",
    "entropy_coefficient = 0.01,\n",
    "clip_param = 0.1,\n",
    "max_grad_norm = 0.5,\n",
    "\n",
    "    \n",
    "torch_deterministic= True,\n",
    "num_steps=1600000,\n",
    "num_iterations = 2,#500,\n",
    "episode_time_lim = 3000,#10000,\n",
    "hero_agent_maping = [1,0,0],\n",
    "model_name={1:\"ddpg\"}#,2:'transformer_model'}\n",
    ",entropy=True,\n",
    "return_prob=2,\n",
    "actor_wt = 0.5,\n",
    "CE_wt = 0.01,\n",
    "small = True,\n",
    "num_episodes = 10,#20,\n",
    "context_len = 256,\n",
    "rtg_scale=1,\n",
    "shuffle=True,\n",
    "pin_memory=False,#False,\n",
    "drop_last=True,\n",
    "TB_log=False,#True,\n",
    "learning_starts =100,\n",
    "update_epochs = 1,\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\n",
    "pin_memory_device= (\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\n",
    "    \n",
    "env_config = dict(render_mode = None,#'rgb_array', \n",
    "                    default_attack_all  = True,\n",
    "                    agent_count  = 3#4\n",
    "                    ,use_placement_perc=True,\n",
    "                    render_=False,\n",
    "                    bad_mov_penalization = 0.01\n",
    "                 )\n",
    ",model_config = dict(\n",
    "                    n_blocks      =   3,\n",
    "                    embed_dim     =   64,#128 ,\n",
    "                    context_len   =   256,#256  ,\n",
    "                    n_heads       =   1,\n",
    "                    dropout_p     =   0.1,\n",
    "                    wt_decay      =   0.0001,\n",
    "                    warmup_steps  =   100   ,\n",
    "                    tau           =   0.15, #0.95\n",
    "                    chunk_size    =   2000,#64,#8,#32,#64\n",
    "                    chunk_overlap =   1,\n",
    "                    rb_len        =   20*3000, #20\n",
    "\n",
    "\n",
    "                    policy_frequency  =2,\n",
    "                \n",
    "                    warmup_epoch  =   5,  \n",
    "                    total_epoch   =   20,\n",
    "                    initial_lr    =   5e-4,\n",
    "                    final_lr      =   1e-6,\n",
    "\n",
    "                    beta           = 0.5,#args.model_config['beta']         #0.2 #Q_mse\n",
    "                    alpha          = 1,#args.model_config['alpha']          #0.1  #actionloss\n",
    "                    entropy_coeff  = 0.2,#args.model_config['entropy_coeff']         #0.1#0.5   #entropy loss in action\n",
    "                    val_loss_coeff = 0.5#args.model_config['val_loss_coeff']        #0.5      #Q loss\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "                    )\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "1792e1b3-ec1c-4d28-a983-cdc9c614725c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {2: {'attacked_me': 0, 'neighbour_cooperate': 0},\n",
       "  3: {'attacked_me': 0, 'neighbour_cooperate': 0}},\n",
       " 2: {1: {'attacked_me': 0, 'neighbour_cooperate': 0},\n",
       "  3: {'attacked_me': 0, 'neighbour_cooperate': 0}},\n",
       " 3: {1: {'attacked_me': 0, 'neighbour_cooperate': 0},\n",
       "  2: {'attacked_me': 0, 'neighbour_cooperate': 0}}}"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smp.Personality_bot.agent_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e5272b-ebcf-47ce-9917-3112bf4ef395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "learning_rate = 0.001,#5e-4,#0.003,#0.0003,\n",
    "batch_size = 2,\n",
    "gamma = 0.999,#0.99\n",
    "seed = 432,\n",
    "entropy_coefficient = 0.01,\n",
    "clip_param = 0.1,\n",
    "max_grad_norm = 0.5,\n",
    "#return_prob=2,\n",
    "actor_wt = 0.5,\n",
    "CE_wt = 0.01,\n",
    "#small = True,\n",
    "#num_episodes = 10,#20,\n",
    "#context_len = 256,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "e2f10d66-da9e-4279-90ec-aafaf56fdb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ashishpanchal/Documents/OMSCS/TIny_risk/Unraveling_Complex_Sequent_Supplementary_Material'"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "b6ee7628-4bc3-4fc3-83d5-6b672107bc15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 1\n",
      "2 attacking 1\n",
      "done: {1: True, 2: False, 3: True} ,total_reward: {1: -100.34, 2: 9.0, 3: -200.0} ,iteration: 2 ,episode: 10\n",
      "[[2 5.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 2.0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [2 6.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [0 0]]\n",
      "1 2\n",
      "249 249\n",
      "epoch 10 qf1_loss tensor(13.7364, grad_fn=<MseLossBackward0>)\n",
      "torch.float32 torch.float32 torch.float32\n",
      "actor_loss tensor(0.0443, grad_fn=<NegBackward0>)\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "done: {1: True, 2: False, 3: True} ,total_reward: {1: -100.78, 2: 10.97, 3: -200.0} ,iteration: 2 ,episode: 11\n",
      "[[2 2.0]\n",
      " [2 4.0]\n",
      " [2 11.0]\n",
      " [2 4.0]\n",
      " [2 2.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 4.0]\n",
      " [2 1.0]\n",
      " [2 1.0]]\n",
      "1 2\n",
      "574 574\n",
      "epoch 11 qf1_loss tensor(36.9400, grad_fn=<MseLossBackward0>)\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "done: {1: True, 2: True, 3: False} ,total_reward: {1: -100.59, 2: -200.0, 3: 10.96} ,iteration: 2 ,episode: 12\n",
      "[[3 5.0]\n",
      " [3 2.0]\n",
      " [3 1.0]\n",
      " [3 1.0]\n",
      " [3 4.0]\n",
      " [3 1.0]\n",
      " [3 3.0]\n",
      " [3 1.0]\n",
      " [3 2.0]\n",
      " [3 6.0]]\n",
      "1 2\n",
      "401 401\n",
      "epoch 12 qf1_loss tensor(13.9820, grad_fn=<MseLossBackward0>)\n",
      "torch.float32 torch.float32 torch.float32\n",
      "actor_loss tensor(0.0321, grad_fn=<NegBackward0>)\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "done: {1: True, 2: True, 3: False} ,total_reward: {1: -101.0, 2: -200.0, 3: 10.900000000000002} ,iteration: 2 ,episode: 13\n",
      "[[3 9.0]\n",
      " [3 1.0]\n",
      " [3 9.0]\n",
      " [3 2.0]\n",
      " [3 7.0]\n",
      " [3 2.0]\n",
      " [3 8.0]\n",
      " [3 4.0]\n",
      " [3 4.0]\n",
      " [3 5.0]]\n",
      "1 2\n",
      "739 739\n",
      "epoch 13 qf1_loss tensor(36.0595, grad_fn=<MseLossBackward0>)\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "done: {1: True, 2: False, 3: True} ,total_reward: {1: -100.62, 2: 10.96, 3: -200.01999999999998} ,iteration: 2 ,episode: 14\n",
      "[[2 1.0]\n",
      " [2 1.0]\n",
      " [2 4.0]\n",
      " [2 5.0]\n",
      " [2 2.0]\n",
      " [2 3.0]\n",
      " [2 3.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 1.0]]\n",
      "1 2\n",
      "479 479\n",
      "epoch 14 qf1_loss tensor(8.9337, grad_fn=<MseLossBackward0>)\n",
      "torch.float32 torch.float32 torch.float32\n",
      "actor_loss tensor(-0.0282, grad_fn=<NegBackward0>)\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "done: {1: True, 2: False, 3: True} ,total_reward: {1: -101.05, 2: 10.900000000000002, 3: -200.04} ,iteration: 2 ,episode: 15\n",
      "[[2 3.0]\n",
      " [2 4.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 2.0]\n",
      " [2 2.0]\n",
      " [2 2.0]\n",
      " [2 3.0]\n",
      " [2 1.0]]\n",
      "1 2\n",
      "895 895\n",
      "epoch 15 qf1_loss tensor(4.6403, grad_fn=<MseLossBackward0>)\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "done: {1: True, 2: False, 3: True} ,total_reward: {1: -200.35, 2: 8.55000000000001, 3: -104.38} ,iteration: 2 ,episode: 16\n",
      "[[2 1.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [0 0.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [0 0.0]]\n",
      "1 3\n",
      "2798 2798\n",
      "epoch 16 qf1_loss tensor(5.0526, grad_fn=<MseLossBackward0>)\n",
      "torch.float32 torch.float32 torch.float32\n",
      "actor_loss tensor(-0.0419, grad_fn=<NegBackward0>)\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "done: {1: True, 2: False, 3: True} ,total_reward: {1: -200.37, 2: 9.770000000000005, 3: -101.09} ,iteration: 2 ,episode: 17\n",
      "[[2 3.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 2.0]\n",
      " [2 1.0]\n",
      " [2 3.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [0 0.0]]\n",
      "1 3\n",
      "1045 1045\n",
      "epoch 17 qf1_loss tensor(13.9658, grad_fn=<MseLossBackward0>)\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "done: {1: True, 2: True, 3: False} ,total_reward: {1: -200.76, 2: -101.14, 3: 8.840000000000003} ,iteration: 2 ,episode: 18\n",
      "[[3 1.0]\n",
      " [3 1.0]\n",
      " [3 2.0]\n",
      " [0 0.0]\n",
      " [3 1.0]\n",
      " [3 1.0]\n",
      " [3 3.0]\n",
      " [0 0.0]\n",
      " [3 1.0]\n",
      " [3 5.0]]\n",
      "1 3\n",
      "1274 1274\n",
      "epoch 18 qf1_loss tensor(5.0633, grad_fn=<MseLossBackward0>)\n",
      "torch.float32 torch.float32 torch.float32\n",
      "actor_loss tensor(-0.0469, grad_fn=<NegBackward0>)\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 0\n",
      "2 attacking 3\n",
      "3 attacking 0\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "2 attacking 0\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "3 attacking 2\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 0\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "2 attacking 3\n",
      "done: {1: True, 2: False, 3: True} ,total_reward: {1: -200.9, 2: 8.680000000000007, 3: -101.35} ,iteration: 2 ,episode: 19\n",
      "[[2 2.0]\n",
      " [2 3.0]\n",
      " [0 0.0]\n",
      " [0 0.0]\n",
      " [2 2.0]\n",
      " [2 1.0]\n",
      " [2 1.0]\n",
      " [2 2.0]\n",
      " [2 1.0]\n",
      " [2 13.0]]\n",
      "1 3\n",
      "2250 2250\n",
      "epoch 19 qf1_loss tensor(17.3097, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "smp = sample_and_train(args=exp_13)\n",
    "smp.run_learning_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "0c803d8b-aa5a-44dc-ac61-e4617d541d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smp.relation_record_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "2703508d-3475-4fb1-8e3f-36f5734d8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "ebe5f3a4-9378-4921-bed5-7ce2d1777a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "relation_list = list(smp.relation_record_dataset[0]['values'].keys())\n",
    "relation_list = dict(enumerate(relation_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "6ad5f6a6-2144-4b0c-86d2-1204302d0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_data = np.zeros((len(smp.relation_record_dataset.keys()),len(relation_list),3000)) \n",
    "\n",
    "relation_data[relation_data == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "05febcd0-8aa5-43f8-9e22-bc387e530a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epi,val_1 in smp.relation_record_dataset.items():\n",
    "    for i,j in relation_list.items():\n",
    "        val_inde = val_1['values'][j]\n",
    "        relation_data[epi][i][:len(val_inde)]=val_inde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "5be88b3b-ebf1-4b80-b834-c78253821375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/9q_38sj961n1slqfmcpfjgnc0000gn/T/ipykernel_36057/3376145678.py:1: RuntimeWarning: Mean of empty slice\n",
      "  plt.plot(np.nanmean(relation_data,axis =0).T,label =list(relation_list.values() ))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x35fdbd2e0>"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.nanmean(relation_data,axis =0).T,label =list(relation_list.values() ))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "2bb33659-8cd6-42c4-a057-6c9bdf8e5366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 2],\n",
       "       [1, 8],\n",
       "       [2, 1],\n",
       "       [2, 5],\n",
       "       [2, 3],\n",
       "       [3, 2],\n",
       "       [4, 5],\n",
       "       [5, 6],\n",
       "       [5, 2],\n",
       "       [5, 4],\n",
       "       [6, 7],\n",
       "       [6, 5],\n",
       "       [7, 8],\n",
       "       [7, 6],\n",
       "       [8, 9],\n",
       "       [8, 1],\n",
       "       [8, 7],\n",
       "       [9, 8]], dtype=int8)"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smp.env.board.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8de85c-d055-430e-8939-8fadef3b11df",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "64059f6c-813f-40ba-80fc-47e93abe9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp.hero_agents_list[1].train(1, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf4122-9b3c-48b7-9252-55859091ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.repeat(repeats=(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a8ae1-090d-42d1-a2bf-fa5d0eb95170",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data= smp.hero_agents_list[smp.the_hero_agent].model_in.repeat(repeats=(2,1))\n",
    "    a1 = smp.hero_agents_list[smp.the_hero_agent].actor1(data)\n",
    "    print(data.shape,a1.shape)\n",
    "    \n",
    "    \n",
    "    a2 = smp.hero_agents_list[smp.the_hero_agent].actor2(data,a1)\n",
    "    print(a1,a2)\n",
    "    v = smp.hero_agents_list[smp.the_hero_agent].qf1(data,a1[:,None],a2)\n",
    "    print(v)\n",
    "    \n",
    "    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be6c01-b9ba-446e-9fc2-c1dde08a7630",
   "metadata": {},
   "source": [
    "# model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78002dd-96de-469c-b5f1-611253cfbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import stable_baselines3 as sb3\n",
    "\n",
    "    if sb3.__version__ < \"2.0\":\n",
    "        raise ValueError(\n",
    "            \"\"\"Ongoing migration: run the following command to install the new dependencies:\n",
    "poetry run pip install \"stable_baselines3==2.0.0a1\"\n",
    "\"\"\"\n",
    "        )\n",
    "    args = tyro.cli(Args)\n",
    "    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
    "    if args.track:\n",
    "        import wandb\n",
    "\n",
    "        wandb.init(\n",
    "            project=args.wandb_project_name,\n",
    "            entity=args.wandb_entity,\n",
    "            sync_tensorboard=True,\n",
    "            config=vars(args),\n",
    "            name=run_name,\n",
    "            monitor_gym=True,\n",
    "            save_code=True,\n",
    "        )\n",
    "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "    writer.add_text(\n",
    "        \"hyperparameters\",\n",
    "        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
    "    )\n",
    "\n",
    "    # TRY NOT TO MODIFY: seeding\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "    # env setup\n",
    "    envs = gym.vector.SyncVectorEnv([make_env(args.env_id, args.seed, 0, args.capture_video, run_name)])\n",
    "    assert isinstance(envs.single_action_space, gym.spaces.Box), \"only continuous action space is supported\"\n",
    "\n",
    "    actor = Actor(envs).to(device)\n",
    "    qf1 = QNetwork(envs).to(device)\n",
    "    qf1_target = QNetwork(envs).to(device)\n",
    "    target_actor = Actor(envs).to(device)\n",
    "    target_actor.load_state_dict(actor.state_dict())\n",
    "    qf1_target.load_state_dict(qf1.state_dict())\n",
    "    q_optimizer = optim.Adam(list(qf1.parameters()), lr=args.learning_rate)\n",
    "    actor_optimizer = optim.Adam(list(actor.parameters()), lr=args.learning_rate)\n",
    "\n",
    "    envs.single_observation_space.dtype = np.float32\n",
    "    rb = ReplayBuffer(\n",
    "        args.buffer_size,\n",
    "        envs.single_observation_space,\n",
    "        envs.single_action_space,\n",
    "        device,\n",
    "        handle_timeout_termination=False,\n",
    "    )\n",
    "    start_time = time.time()\n",
    "\n",
    "    # TRY NOT TO MODIFY: start the game\n",
    "    obs, _ = envs.reset(seed=args.seed)\n",
    "    for global_step in range(args.total_timesteps):\n",
    "        # ALGO LOGIC: put action logic here\n",
    "        if global_step < args.learning_starts:\n",
    "            actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                actions = actor(torch.Tensor(obs).to(device))\n",
    "                actions += torch.normal(0, actor.action_scale * args.exploration_noise)\n",
    "                actions = actions.cpu().numpy().clip(envs.single_action_space.low, envs.single_action_space.high)\n",
    "\n",
    "        # TRY NOT TO MODIFY: execute the game and log data.\n",
    "        next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
    "\n",
    "        # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
    "        if \"final_info\" in infos:\n",
    "            for info in infos[\"final_info\"]:\n",
    "                print(f\"global_step={global_step}, episodic_return={info['episode']['r']}\")\n",
    "                writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
    "                writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
    "                break\n",
    "\n",
    "        # TRY NOT TO MODIFY: save data to reply buffer; handle `final_observation`\n",
    "        real_next_obs = next_obs.copy()\n",
    "        for idx, trunc in enumerate(truncations):\n",
    "            if trunc:\n",
    "                real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
    "        rb.add(obs, real_next_obs, actions, rewards, terminations, infos)\n",
    "\n",
    "        # TRY NOT TO MODIFY: CRUCIAL step easy to overlook\n",
    "        obs = next_obs\n",
    "\n",
    "        # ALGO LOGIC: training.\n",
    "        if global_step > args.learning_starts:\n",
    "            data = rb.sample(args.batch_size)\n",
    "            with torch.no_grad():\n",
    "                next_state_actions = target_actor(data.next_observations)\n",
    "                qf1_next_target = qf1_target(data.next_observations, next_state_actions)\n",
    "                next_q_value = data.rewards.flatten() + (1 - data.dones.flatten()) * args.gamma * (qf1_next_target).view(-1)\n",
    "\n",
    "            qf1_a_values = qf1(data.observations, data.actions).view(-1)\n",
    "            qf1_loss = F.mse_loss(qf1_a_values, next_q_value)\n",
    "\n",
    "            # optimize the model\n",
    "            q_optimizer.zero_grad()\n",
    "            qf1_loss.backward()\n",
    "            q_optimizer.step()\n",
    "\n",
    "            if global_step % args.policy_frequency == 0:\n",
    "                actor_loss = -qf1(data.observations, actor(data.observations)).mean()\n",
    "                actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                actor_optimizer.step()\n",
    "\n",
    "                # update the target network\n",
    "                for param, target_param in zip(actor.parameters(), target_actor.parameters()):\n",
    "                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n",
    "                for param, target_param in zip(qf1.parameters(), qf1_target.parameters()):\n",
    "                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n",
    "\n",
    "            if global_step % 100 == 0:\n",
    "                writer.add_scalar(\"losses/qf1_values\", qf1_a_values.mean().item(), global_step)\n",
    "                writer.add_scalar(\"losses/qf1_loss\", qf1_loss.item(), global_step)\n",
    "                writer.add_scalar(\"losses/actor_loss\", actor_loss.item(), global_step)\n",
    "                print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "                writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
    "\n",
    "    if args.save_model:\n",
    "        model_path = f\"runs/{run_name}/{args.exp_name}.cleanrl_model\"\n",
    "        torch.save((actor.state_dict(), qf1.state_dict()), model_path)\n",
    "        print(f\"model saved to {model_path}\")\n",
    "        from cleanrl_utils.evals.ddpg_eval import evaluate\n",
    "\n",
    "        episodic_returns = evaluate(\n",
    "            model_path,\n",
    "            make_env,\n",
    "            args.env_id,\n",
    "            eval_episodes=10,\n",
    "            run_name=f\"{run_name}-eval\",\n",
    "            Model=(Actor, QNetwork),\n",
    "            device=device,\n",
    "            exploration_noise=args.exploration_noise,\n",
    "        )\n",
    "        for idx, episodic_return in enumerate(episodic_returns):\n",
    "            writer.add_scalar(\"eval/episodic_return\", episodic_return, idx)\n",
    "\n",
    "        if args.upload_model:\n",
    "            from cleanrl_utils.huggingface import push_to_hub\n",
    "\n",
    "            repo_name = f\"{args.env_id}-{args.exp_name}-seed{args.seed}\"\n",
    "            repo_id = f\"{args.hf_entity}/{repo_name}\" if args.hf_entity else repo_name\n",
    "            push_to_hub(args, episodic_returns, repo_id, \"DDPG\", f\"runs/{run_name}\", f\"videos/{run_name}-eval\")\n",
    "\n",
    "    envs.close()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612ea30-c070-46e7-99ae-9ec016b8b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    actor1 = Actor(obs).to(device)\n",
    "    actor2 = ActorDiscrete(obs+1,action).to(device)\n",
    "\n",
    "\n",
    "    target_actor1 = Actor(obs).to(device)\n",
    "    target_actor1.load_state_dict(actor1.state_dict())\n",
    "\n",
    "    target_actor2 = ActorDiscrete(obs+1,action).to(device)\n",
    "    target_actor2.load_state_dict(actor2.state_dict())\n",
    "\n",
    "    qf1 = QNetwork(obs,action+1).to(device)\n",
    "    qf1_target = QNetwork(obs,action+1).to(device)\n",
    "\n",
    "    qf1_target.load_state_dict(qf1.state_dict())\n",
    "    q_optimizer = optim.Adam(list(qf1.parameters()), lr=args.learning_rate)\n",
    "\n",
    "    actor1_optimizer = optim.Adam(list(actor1.parameters()), lr=args.learning_rate)\n",
    "    actor2_optimizer = optim.Adam(list(actor2.parameters()), lr=args.learning_rate)\n",
    "\n",
    "    envs.single_observation_space.dtype = np.float32\n",
    "    #set observation space type\n",
    "    #setup replay buffer\n",
    "\n",
    "    #rb = ReplayBuffer(\n",
    "    #    args.buffer_size,\n",
    "    #    envs.single_observation_space,\n",
    "    #    envs.single_action_space,\n",
    "    #    device,\n",
    "    #    handle_timeout_termination=False,\n",
    "    #)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # TRY NOT TO MODIFY: start the game\n",
    "    #obs, _ = envs.reset(seed=args.seed)\n",
    "\n",
    "    #for global steps \n",
    "\n",
    "\n",
    "        #EXPLORATION and exp collection\n",
    "        #till learning starts random action\n",
    "\n",
    "        #else:\n",
    "        #    with torch.no_grad():\n",
    "        #        actions = actor(torch.Tensor(obs).to(device))\n",
    "        #        actions += torch.normal(0, actor.action_scale * args.exploration_noise)\n",
    "        #        actions = actions.cpu().numpy().clip(envs.single_action_space.low, envs.single_action_space.high) # action cliping\n",
    "        #\n",
    "        ## TRY NOT TO MODIFY: execute the game and log data.\n",
    "        #next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
    "\n",
    "\n",
    "        \n",
    "        # TRY NOT TO MODIFY: save data to reply buffer; handle `final_observation`\n",
    "        #real_next_obs = next_obs.copy()\n",
    "        #for idx, trunc in enumerate(truncations):\n",
    "        #    if trunc:\n",
    "        #        real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
    "        #rb.add(obs, real_next_obs, actions, rewards, terminations, infos)\n",
    "\n",
    "        # TRY NOT TO MODIFY: CRUCIAL step easy to overlook\n",
    "        #obs = next_obs\n",
    "\n",
    "\n",
    "\n",
    "        # ALGO LOGIC: training.\n",
    "        if global_step > args.learning_starts:\n",
    "            # get data batch\n",
    "            #data = rb.sample(args.batch_size)\n",
    "\n",
    "            # get \n",
    "            with torch.no_grad():\n",
    "                next_state_actions1 = target_actor1(data.next_observations)\n",
    "                next_state_actions2 = target_actor2(data.next_observations,next_state_actions1)\n",
    "                qf1_next_target = qf1_target(data.next_observations, next_state_actions1, next_state_actions2)\n",
    "                next_q_value = data.rewards.flatten() + (1 - data.dones.flatten()) * args.gamma * (qf1_next_target).view(-1)\n",
    "\n",
    "            qf1_a_values = qf1(data.observations, data.actions1, data.actions2 ).view(-1)\n",
    "            qf1_loss = F.mse_loss(qf1_a_values, next_q_value)\n",
    "\n",
    "            # optimize the model\n",
    "            q_optimizer.zero_grad()\n",
    "            qf1_loss.backward()\n",
    "            q_optimizer.step()\n",
    "\n",
    "            if global_step % args.policy_frequency == 0:\n",
    "                acts_1 = actor1(data.observations)\n",
    "                acts_2 = actor2(data.observations,acts_1)\n",
    "                actor_loss = -qf1(data.observations, acts_1, acts_2).mean()\n",
    "                actor1_optimizer.zero_grad()\n",
    "                \n",
    "                actor_loss.backward(retain_graph=True)\n",
    "                actor1_optimizer.step()\n",
    "\n",
    "                actor2_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                \n",
    "                actor2_optimizer.step()\n",
    "\n",
    "                \n",
    "                # update the target network\n",
    "                for param, target_param in zip(actor1.parameters(), target_actor1.parameters()):\n",
    "                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n",
    "\n",
    "                for param, target_param in zip(actor2.parameters(), target_actor2.parameters()):\n",
    "                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n",
    "                \n",
    "                for param, target_param in zip(qf1.parameters(), qf1_target.parameters()):\n",
    "                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n",
    "\n",
    "\n",
    "\n",
    "    def train_write(self, iteration, print_=False):\n",
    "\n",
    "        total_loss_list = []\n",
    "        Q_TD_list = []\n",
    "        Q_MSE_list = []\n",
    "        Q_loss_list = []\n",
    "        policy_loss_list = []\n",
    "\n",
    "        if self.args.TB_log:\n",
    "            self.writer.add_scalar(\"charts/learning_rate\", self.optimizer_1.param_groups[0][\"lr\"], iteration)        \n",
    "        \n",
    "        for epoch in range(self.args.update_epochs):\n",
    "            for i,batch in enumerate(self.traj_data_loader):\n",
    "                total_loss = 0\n",
    "                Q_TD = 0\n",
    "                Q_MSE = 0\n",
    "                Q_loss = 0\n",
    "                policy_loss = 0\n",
    "                print(i)\n",
    "\n",
    "\n",
    "                batch_len = batch[0].shape[1]#2840\n",
    "                \n",
    "                if batch_len > self.chunk_size:\n",
    "                    a_ = [(i,i+self.chunk_size) for i in range(0, batch_len     -self.chunk_size,self.chunk_size-self.chunk_overlap)  ]\n",
    "                    a_  =a_+[ (a_[-1][1] -self.chunk_overlap ,batch_len) ]\n",
    "                else:\n",
    "                    a_ = [(0,batch_len)]\n",
    "    \n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                divi = len(a_)\n",
    "\n",
    "                \n",
    "                print('divi',divi,'chunk_size',self.chunk_size,'batch_shape',batch[0].shape)\n",
    "                \n",
    "                for (chunk_id, i) in enumerate(a_):#range(0,batch[0].shape[1] - self.chunk_size + 1,self.chunk_size - self.chunk_overlap)):\n",
    "\n",
    "                    # print(i,(i + self.chunk_size))\n",
    "                    total_loss_chunk, Q_TD_chunk, Q_MSE_chunk, Q_loss_chunk, policy_loss_chunk = self.train_write_smaller_chunk((tens[:, i[0]:i[1]] for tens in batch),\n",
    "                                                                                                                                    iteration, epoch, chunk_id, print_=print_,divi=divi)\n",
    "\n",
    "                    \n",
    "                    total_loss= total_loss + total_loss_chunk\n",
    "                    Q_TD = Q_TD+ Q_TD_chunk\n",
    "                    Q_MSE = Q_MSE+ Q_MSE_chunk\n",
    "                    Q_loss = Q_loss+ Q_loss_chunk\n",
    "                    policy_loss = policy_loss+ policy_loss_chunk\n",
    "\n",
    "                total_loss_list.append(total_loss)\n",
    "                Q_TD_list.append(Q_TD)\n",
    "                Q_MSE_list.append(Q_MSE)\n",
    "                Q_loss_list.append(Q_loss)\n",
    "                policy_loss_list.append(policy_loss)            \n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        \n",
    "        if iteration < self.warmup_epoch:\n",
    "            # Linear warmup: Gradually increase learning rate during warmup\n",
    "            lr = self.initial_lr * iteration / self.warmup_epoch\n",
    "            for param_group in self.optimizer_1.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        else:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        \n",
    "        print(\"total_loss\", np.mean(total_loss_list),\n",
    "              \"Q_TD\", np.mean(Q_TD_list),\n",
    "                \"Q_MSE\", np.mean(Q_MSE_list),\n",
    "                \"Q_loss\", np.mean(Q_loss_list),\n",
    "                \"policy_loss\", np.mean(policy_loss_list))\n",
    "\n",
    "        if self.args.TB_log:\n",
    "        \n",
    "            self.writer.add_scalar(\"total_loss\", np.mean(total_loss_list), iteration)\n",
    "            self.writer.add_scalar(\"Q_TD\", np.mean(Q_TD_list), iteration)\n",
    "            self.writer.add_scalar(\"Q_MSE\", np.mean(Q_MSE_list), iteration)\n",
    "            self.writer.add_scalar(\"Q_loss\", np.mean(Q_loss_list), iteration)\n",
    "            self.writer.add_scalar(\"policy_loss\", np.mean(policy_loss_list), iteration)    \n",
    "                    \n",
    "                \n",
    "                \n",
    "        \n",
    "        self.copy_wt()\n",
    "\n",
    "\n",
    "    def train_write_smaller_chunk(\n",
    "        self,\n",
    "        data,\n",
    "        iteration,\n",
    "        epoch,\n",
    "        chunk_id,\n",
    "        print_=False,divi = 1\n",
    "        ):\n",
    "\n",
    "        (\n",
    "            timesteps,\n",
    "            states,\n",
    "            actions_1,actions_2,log_probs_actions_2,\n",
    "            returntogo,\n",
    "            returns_to_go_cal,\n",
    "            returntogo_pred,\n",
    "            reward,\n",
    "            traj_mask,\n",
    "            action_masks,\n",
    "            current_agent_acting,\n",
    "            current_agent_simple,\n",
    "            current_agent,\n",
    "            current_phase,\n",
    "            current_troops_count,\n",
    "            ) = data\n",
    "\n",
    "\n",
    "        if len(timesteps[0].shape) ==0:\n",
    "            print( timesteps.shape )\n",
    "\n",
    "        \n",
    "        timesteps = timesteps[0].to(self.device)  # B x T\n",
    "        states = states[0].to(self.device)  # B x T x state_dim\n",
    "        actions_1 = actions_1[0].to(self.device)  # B x T x act_dim\n",
    "        actions_2 = actions_2[0].to(self.device)  # B x T x act_dim\n",
    "        log_probs_actions_2 = log_probs_actions_2[0].to(self.device)\n",
    "        reward = reward[0].to(self.device)\n",
    "        returns_to_go_cal =             returns_to_go_cal[0].to(self.device).unsqueeze(dim=-1)  # B x T x 1\n",
    "        returntogo = returntogo[0].to(self.device)\n",
    "        returntogo_pred = returntogo_pred[0].to(self.device)\n",
    "        traj_mask = traj_mask[0].to(self.device)  # B x T\n",
    "        action_masks = action_masks[0].to(self.device)\n",
    "        current_agent_acting = current_agent_acting[0].to(self.device)\n",
    "        current_agent_simple = current_agent_simple[0].to(self.device)\n",
    "        current_agent = current_agent[0].to(self.device)\n",
    "        current_phase = current_phase[0].to(self.device)\n",
    "        current_troops_count = current_troops_count[0].to(self.device)\n",
    "\n",
    "        info = dict({})\n",
    "\n",
    "\n",
    "        \n",
    "        hero_steps = current_agent_simple == self.hero\n",
    "\n",
    "        states = torch.cat((states, action_masks * hero_steps,\n",
    "                              current_phase, current_agent,\n",
    "                              current_troops_count[:, :, None]), axis=2)  # ,torch.ones(len(action_masks))[:,None]*self.hero\n",
    "\n",
    "\n",
    "\n",
    "        #print(actions_1.requires_grad,actions_2.requires_grad)\n",
    "\n",
    "        (action_pred_1,action_pred_2) =  (actions_1* hero_steps[:,0],\n",
    "                                                        actions_2* hero_steps[:,0]\n",
    "                                                         )\n",
    "\n",
    "        # state_preds, action_preds, return_preds = self.model.forward(\n",
    "        #                                                timesteps=timesteps,\n",
    "        #                                                states=states,\n",
    "        #                                                actions=actions,\n",
    "        #                                                returns_to_go=returns_to_go\n",
    "        #                                                #,info = info\n",
    "        #                                            )\n",
    "\n",
    "        #so this return to go is for value loss estimation\n",
    "\n",
    "        _,_, returntogo_pred_v,_ = self.model.forward(\n",
    "                                                        timesteps=timesteps,\n",
    "                                                        states=states,\n",
    "                                                        actions_1=action_pred_1,actions_2=action_pred_2,\n",
    "                                                        returns_to_go=returntogo,\n",
    "                                                            print_=print_\n",
    "                                                        #,info = info\n",
    "                                                    )\n",
    "        \n",
    "        # this is also for value function loss estimation\n",
    "\n",
    "        (#state_preds_target, \n",
    "         _,_,return_preds_target,_) =  self.target_model.forward(timesteps=timesteps,\n",
    "                                                                                states=states, actions_1=action_pred_1,actions_2=action_pred_2,\n",
    "                                                                                returns_to_go=returntogo, print_=print_)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        (#state_preds_target, \n",
    "         return_preds_target) = (return_preds_target.detach())\n",
    "\n",
    "\n",
    "        if  len(reward[:, -1].squeeze().view(-1).shape) == 0:\n",
    "            \n",
    "            print('return_preds_last',return_preds_target.shape)\n",
    "            print('reward_last',reward.shape)\n",
    "            print('returns_to_go_cal_last',returns_to_go_cal.shape)\n",
    "\n",
    "            print('return_preds_last',return_preds_target)\n",
    "            print('reward_last',reward)\n",
    "            print('returns_to_go_cal_last',returns_to_go_cal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        total_loss, (Q_TD, Q_MSE, Q_loss, policy_loss) = self.calculate_loss(\n",
    "                                                                                timesteps,\n",
    "                                                                                return_preds_target,#target model predictions \n",
    "                                                                                returns_to_go_cal, # Q calculated\n",
    "                                                                                hero_steps    ,#current_agent_acting,\n",
    "                                                                                states,\n",
    "                                                                                actions_1,actions_2,log_probs_actions_2,\n",
    "                                                                                returntogo_pred,\n",
    "                                                                                returntogo_pred_v,\n",
    "                                                                                reward,#actual rewards \n",
    "                                                                                returntogo,  #actual R2G given to the model\n",
    "                                                                                action_masks,\n",
    "                                                                                print_,\n",
    "                                                                                chunk_id,divi\n",
    "                                                                                )\n",
    "        #if chunk_id == 0:\n",
    "        #    print (chunk_id, total_loss)\n",
    "\n",
    "        # action_loss = #nn.CrossEntropyLoss().forward(action_preds_2,action_target)#F.mse_loss(action_preds_2, action_target.float(), reduction='mean')\n",
    "\n",
    "        self.optimizer_1.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.25)\n",
    "        self.optimizer_1.step()\n",
    "        #self.scheduler.step()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        # policy_loss.backward(retain_graph=True)\n",
    "\n",
    "        return total_loss.detach().item() ,Q_TD.detach().item(), Q_MSE.detach().item(), Q_loss.detach().item(), policy_loss.detach().item()\n",
    "\n",
    "\n",
    "    def init_path(self):\n",
    "        self.paths = []\n",
    "\n",
    "    def init_CL_sample_store(self):\n",
    "\n",
    "\n",
    "        if self.context_len > 1: # transformer model\n",
    "            self.DT_input = {  # self.actor_config_dict['ob_space']\n",
    "                'timestep': torch.zeros((1,\n",
    "                                        self.context_len),requires_grad =False).to(self.device,\n",
    "                        dtype=torch.int),\n",
    "                'state': torch.zeros((1, self.context_len,\n",
    "                                     self.state_dim),requires_grad =False).to(self.device,dtype=torch.float32),\n",
    "                'action_1': torch.zeros((1, self.context_len\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                'action_2': torch.zeros((1, self.context_len\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                \n",
    "                'return_to_go': torch.ones((1,\n",
    "                        self.context_len),requires_grad =False).to(self.device,dtype=torch.float32) * 110,\n",
    "                }\n",
    "        else: # single traje models\n",
    "            self.DT_input = {  # self.actor_config_dict['ob_space']\n",
    "                'timestep': torch.zeros((1,\n",
    "                                        ),requires_grad =False).to(self.device,\n",
    "                        dtype=torch.int),\n",
    "                'state': torch.zeros((1,\n",
    "                                     self.state_dim),requires_grad =False).to(self.device,dtype=torch.float32),\n",
    "                'action_1': torch.zeros((1,\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                'action_2': torch.zeros((1,\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                \n",
    "                'return_to_go': torch.ones((1,\n",
    "                                    ),requires_grad =False).to(self.device,dtype=torch.float32) * 110,\n",
    "                }            \n",
    "    \n",
    "        self.returntogo = torch.zeros((self.num_steps,\n",
    "                1),requires_grad =False).to(self.device,dtype=torch.float32)  # self.total_agents\n",
    "        self.returntogo_pred = torch.zeros((self.num_steps,\n",
    "                1)).to(self.device,dtype=torch.float32)  # self.total_agents\n",
    "\n",
    "    #here\n",
    "    def current_model_in(\n",
    "        self,\n",
    "        observation,\n",
    "        curr_agent,\n",
    "        phase_mapping,\n",
    "        curr_agent_mapping,\n",
    "        env_board_agents=[],\n",
    "        ):\n",
    "\n",
    "\n",
    "\n",
    "        #single obs\n",
    "        self.model_in =  torch.hstack((observation['observation'\n",
    "                         ].reshape(-1).to(self.device),\n",
    "                         torch.tensor(observation['action_mask'\n",
    "                         ].reshape(-1)).to(self.device) * (curr_agent\n",
    "                         == self.hero), phase_mapping.to(self.device),\n",
    "                         curr_agent_mapping.to(self.device),\n",
    "                         ( (torch.tensor([env_board_agents[self.hero].bucket]).to(self.device) - 5.2496)/1.4733\n",
    "                                      )))[None,\n",
    "                         :].float().requires_grad_(False).to(self.device)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def update_CL_sample_store(\n",
    "        self,\n",
    "        curr_agent_,\n",
    "        inp={'step': None, 'act_2_1': [],'act_2_2': [], 'curr_reward_list': []},\n",
    "        before_action=True,\n",
    "        ):\n",
    "\n",
    "        if self.context_len > 1:\n",
    "            \n",
    "            if before_action == 1 :\n",
    "    \n",
    "                if inp['step'] == 0:\n",
    "    \n",
    "                    # print(self.model_in.shape)\n",
    "                    # print(self.model_in.repeat(self.context_len).shape)\n",
    "    \n",
    "                    self.DT_input['state'] = self.model_in.repeat(self.context_len,\n",
    "                            1).to(self.device)[None, :]\n",
    "                else:\n",
    "    \n",
    "                # if step<self.context_len:\n",
    "    \n",
    "                #    trace[step] = model_in\n",
    "    \n",
    "                    self.DT_input['state'][0, 0:-1] = self.DT_input['state'\n",
    "                            ][0, 1:].clone()\n",
    "                    self.DT_input['state'][0, -1] = self.model_in\n",
    "                    self.DT_input['timestep'][0, 0:-1] = self.DT_input['timestep'][0, 1:].clone()\n",
    "                    self.DT_input['timestep'][0, -1] = inp['step']\n",
    "                    self.DT_input['action_1'][0, 0:-1] = self.DT_input['action_1'][0, 1:].clone()\n",
    "                    self.DT_input['action_2'][0, 0:-1] = self.DT_input['action_2'][0, 1:].clone()\n",
    "                    \n",
    "                    self.DT_input['return_to_go'][0, 0:-1] = self.DT_input['return_to_go'][0, 1:].clone()\n",
    "            elif before_action == 2 :\n",
    "                if self.hero == curr_agent_:\n",
    "                    self.DT_input['action_1'][0, -1] = inp['act_2_1']\n",
    "                else:\n",
    "                    self.DT_input['action_1'][0, -1] = 0\n",
    "    \n",
    "            elif before_action == 3  :\n",
    "                if self.hero == curr_agent_:\n",
    "                    self.DT_input['action_2'][0, -1] = inp['act_2_2']\n",
    "                else:\n",
    "                    self.DT_input['action_2'][0, -1] = 0\n",
    "            else:\n",
    "                    \n",
    "                self.DT_input['return_to_go'][0, -1] = self.DT_input['return_to_go'][0, -1] -    inp['curr_reward_list']  # [self.hero]\n",
    "                self.returntogo[inp['step']] = self.DT_input['return_to_go'\n",
    "                        ][0, -1]\n",
    "\n",
    "        else:\n",
    "            if before_action == 1 :\n",
    "                self.DT_input['state'][0] = self.model_in\n",
    "                self.DT_input['timestep'][0] = inp['step']\n",
    "            elif before_action == 2 :\n",
    "                if self.hero == curr_agent_:\n",
    "                    self.DT_input['action_1'][0] = inp['act_2_1']\n",
    "                else:\n",
    "                    self.DT_input['action_1'][0] = 0                \n",
    "            \n",
    "            elif before_action == 3  :\n",
    "                if self.hero == curr_agent_:\n",
    "                    self.DT_input['action_2'][0] = inp['act_2_2']\n",
    "                else:\n",
    "                    self.DT_input['action_2'][0] = 0\n",
    "            else:\n",
    "                    \n",
    "                self.DT_input['return_to_go'][0] = self.DT_input['return_to_go'][0] -    inp['curr_reward_list']  # [self.hero]\n",
    "                self.returntogo[inp['step']] = self.DT_input['return_to_go'][0]               \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def update_train_data(\n",
    "        self,\n",
    "        step_count,\n",
    "        obs,\n",
    "        ob_space_shape,\n",
    "        rewards_2,\n",
    "        dones_2,\n",
    "        actions_1,\n",
    "        actions_2,\n",
    "        log_probs_actions_2,\n",
    "        action_masks,\n",
    "        current_agent,\n",
    "        current_agent_acting,\n",
    "        current_phase,\n",
    "        current_troops_count,\n",
    "        map_agent_phase_vector,\n",
    "        ):\n",
    "\n",
    "        \n",
    "        \n",
    "        data_ = collections.defaultdict(torch.tensor)\n",
    "        data_['observations'] =             obs[:step_count].reshape(-1,\n",
    "                np.prod(ob_space_shape))\n",
    "\n",
    "                # data_['next_observations'] = obs[1:step_count+1].to(device =self.args.pin_memory_device).reshape(-1,np.prod(T.ob_space_shape)) #torch.tensor([1,2,3,4])\n",
    "                # this return to go is the actual input\n",
    "\n",
    "        data_['returntogo'] =           self.returntogo[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['returntogo_pred'] =      self.returntogo_pred[:step_count]  # torch.tensor([1,2,3,4])\n",
    "\n",
    "        data_['rewards'] =              rewards_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['terminals'] =            dones_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['actions_1'] =            actions_1[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['actions_2'] =            actions_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['log_probs_actions_2'] =  log_probs_actions_2[:step_count]\n",
    "        data_['action_masks'] =         action_masks[:step_count]\n",
    "        data_['current_agent_acting'] = current_agent_acting[:step_count]\n",
    "        data_['current_agent_simple'] = current_agent[:step_count]\n",
    "        data_['current_agent'] =        map_agent_phase_vector(current_agent[:step_count],\n",
    "                                               num_classes=self.total_agents + 1)[:, 1:]\n",
    "        data_['current_phase'] =        map_agent_phase_vector(current_phase[:step_count],\n",
    "                                               num_classes=self.total_phases)\n",
    "        data_['current_troops_count'] = current_troops_count[:step_count]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        self.datase = TrajectoryDataset_per_episode([data_], #len(data[0]['observations'])<self.args.context_len\n",
    "                context_len=self.args.context_len,rtg_scale=self.args.rtg_scale,dev = self.args.pin_memory_device,\n",
    "                 gamma=self.args.gamma)\n",
    "\n",
    "        self.path_que(DataLoader(self.datase, batch_size=len(self.datase)))\n",
    "    def path_que(self, dtl):\n",
    "        \n",
    "        if (len(self.paths)==self.rb_len):\n",
    "            if (self.rb_len >1):\n",
    "                self.paths.pop(random.randrange(len(self.paths)-self.args.num_episodes +1 )) # dont pop the most recent experiences and ensure rb_len > num.episodes\n",
    "            else: \n",
    "                self.paths.pop()\n",
    "        self.paths.append(dtl)\n",
    "        \n",
    "    def create_training_dataset(self):\n",
    "        self.traj_dataset =  TrajectoryDataset_2_through_episodes(self.paths)  # a dataset of dataloaders\n",
    "\n",
    "        self.traj_data_loader = DataLoader(  # only spit 1 episode a time\n",
    "            self.traj_dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=self.args.shuffle,\n",
    "            pin_memory=self.args.pin_memory,\n",
    "            drop_last=self.args.drop_last,\n",
    "            pin_memory_device=self.args.pin_memory_device,\n",
    "            )\n",
    "\n",
    "    \n",
    "    def action_predict(self, save_R=True, return_R=False,shift=1,action_masks = [],return_log_prob_a2 = False): \n",
    "        (#s, \n",
    "         a_1,a_2, R,lp) = self.model(timesteps=self.DT_input['timestep'],\n",
    "                               states=self.DT_input['state'],\n",
    "                               actions_1=self.DT_input['action_1'],\n",
    "                               actions_2=self.DT_input['action_2'],\n",
    "                               returns_to_go=( self.DT_input['return_to_go'][:, :, None] if self.context_len>1 else self.DT_input['return_to_go'][:, None]), \n",
    "                                return_log_prob_a2 = return_log_prob_a2)\n",
    "\n",
    "\n",
    "        took_action = False\n",
    "\n",
    "        \n",
    "\n",
    "        if self.context_len>1: # handling transformer model\n",
    "            # I need to handle for non transformer actions\n",
    "            if len(action_masks) > 0:\n",
    "                #handling when all the probability of masked actions are zero.... #have to force the model to pick 1st valid action.\n",
    "                masked_action = (a_1[0, -1, :]*action_masks)\n",
    "                #valid_ind = torch.nonzero(action_masks).squeeze()\n",
    "                if torch.any(masked_action !=0):\n",
    "                    took_action = True\n",
    "                    \n",
    "                    action_1 = (masked_action).argmax()[None]\n",
    "                else: #im hoping that slowly and steadily the model would learn to predict non zero probabilities for action mask\n",
    "                    \n",
    "                    action_1 = torch.tensor(np.random.choice(torch.where(action_masks)[0]))[None]  #(masked_action + 0.0000001*action_masks).argmax()[None]\n",
    "            else:\n",
    "                action_1 = a_1[0, -1, :].argmax()[None]\n",
    "                \n",
    "            action_2 = a_2[0,-1, 0][None]\n",
    "            if return_log_prob_a2:\n",
    "                log_prob = lp[0,-1, 0][None]\n",
    "            else:\n",
    "                log_prob = None\n",
    "            \n",
    "            if save_R:\n",
    "                self.returntogo_pred[self.DT_input['timestep'][0, -1]] =                 R[0, -1]  # R\n",
    "    \n",
    "            if return_R:\n",
    "                return (action_1, action_2, R[0, -1],took_action,log_prob)\n",
    "            else:\n",
    "                return action_1, action_2,took_action,log_prob\n",
    "\n",
    "\n",
    "        else: # not we are talking about the single obs models\n",
    "\n",
    "            # I need to handle for non transformer actions\n",
    "            if len(action_masks) > 0:\n",
    "                #handling when all the probability of masked actions are zero.... #have to force the model to pick 1st valid action.\n",
    "                masked_action = (a_1[0, :]*action_masks)\n",
    "                #valid_ind = torch.nonzero(action_masks).squeeze()\n",
    "                if torch.any(masked_action !=0):\n",
    "                    took_action = True\n",
    "                    \n",
    "                    action_1 = (masked_action).argmax()[None]\n",
    "                else: #im hoping that slowly and steadily the model would learn to predict non zero probabilities for action mask\n",
    "                    \n",
    "                    action_1 = torch.tensor(np.random.choice(torch.where(action_masks)[0]))[None]  #(masked_action + 0.0000001*action_masks).argmax()[None]\n",
    "            else:\n",
    "                action_1 = a_1[0, :].argmax()[None]\n",
    "                \n",
    "            action_2 = a_2[0, 0][None]\n",
    "            if return_log_prob_a2:\n",
    "                log_prob = lp[0, 0][None]\n",
    "            else:\n",
    "                log_prob = None\n",
    "            \n",
    "            if save_R:\n",
    "                self.returntogo_pred[self.DT_input['timestep'][0]] =                 R[0]  # R\n",
    "    \n",
    "            if return_R:\n",
    "                return (action_1, action_2, R[0],took_action,log_prob)\n",
    "            else:\n",
    "                return action_1, action_2,took_action,log_prob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "    def action_predict_direct(self, data, return_R=False,return_log_prob_a2 = False):\n",
    "        (timesteps, states, actions_1,actions_2, returns_to_go) = data\n",
    "        (#s, \n",
    "         a_1,a_2, R,lp) = self.model(timesteps=timesteps, states=states,\n",
    "                               actions_1=actions_1,actions_2=actions_2,\n",
    "                               returns_to_go=returns_to_go,return_log_prob_a2 = return_log_prob_a2)\n",
    "        if return_R:\n",
    "            return (a_1,a_2, R,lp)\n",
    "        else:\n",
    "            return a_1,a_2,lp\n",
    "\n",
    "    def save_models(self):\n",
    "        newpath = r'./models/' + self.run_name + '/' + str(self.hero)\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "        torch.save(self.model.state_dict(), newpath\n",
    "                   + '/a2c_transformer.pt')\n",
    "\n",
    "    def load_models(self):\n",
    "        newpath = r'./models/' + self.run_name + '/' + str(self.hero)\n",
    "        self.model.load_state_dict(torch.load(newpath\n",
    "                                   + '/a2c_transformer.pt'))\n",
    "        self.target_model.load_state_dict(torch.load(newpath\n",
    "                + '/a2c_transformer.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792b735-4d0a-4d59-94a7-2b596d1fcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((1),requires_grad =False)[0] * 110"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d15b02-1aed-4522-9b7a-7e56e3c64385",
   "metadata": {},
   "source": [
    "## model_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f6a37-4598-42ff-bce2-ee9c441cd9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "#referrence for loss : https://github.com/vy007vikas/PyTorch-ActorCriticRL/blob/master/train.py\n",
    "\n",
    "#reference invalid actions ignore\n",
    "#https://ai.stackexchange.com/questions/2980/how-should-i-handle-invalid-actions-when-using-reinforce\n",
    "#ttps://arxiv.org/abs/2006.14171\n",
    "\n",
    "\n",
    "class main_model:\n",
    "\n",
    "    def __init__(  # ,config,args,hero = 1,\n",
    "        self,\n",
    "        qnet_config_dict,\n",
    "        actor_config_dict,\n",
    "        args,\n",
    "        device,\n",
    "        writer,\n",
    "        run_name,\n",
    "        agent,\n",
    "        ):\n",
    "\n",
    "        self.writer = writer\n",
    "        self.hero = agent\n",
    "        self.args = args\n",
    "        self.run_name = run_name\n",
    "        self.device = device  # config['device']\n",
    "        self.state_dim = actor_config_dict['ob_space']  # config['observation_space']#.shape[0]\n",
    "        self.act_dim = actor_config_dict['action_space']  # config['action_space']#.n #3#1 #env.action_space.shape[0]\n",
    "        self.n_blocks = args.model_config['n_blocks']\n",
    "        self.embed_dim = args.model_config['embed_dim']\n",
    "        self.context_len = args.model_config['context_len']\n",
    "        self.n_heads = args.model_config['n_heads']\n",
    "        self.dropout_p = args.model_config['dropout_p']\n",
    "        self.lr = args.learning_rate\n",
    "        self.wt_decay = args.model_config['wt_decay']\n",
    "        self.rb_len = args.model_config['rb_len']\n",
    "\n",
    "        # self.steps        =            config['steps']\n",
    "\n",
    "        self.warmup_epoch = args.model_config['warmup_epoch']\n",
    "        self.total_epoch = args.model_config['total_epoch']\n",
    "        self.initial_lr =  args.model_config['initial_lr'] #5e-4\n",
    "        self.final_lr =  args.model_config['final_lr'] #1e-6\n",
    "        \n",
    "        self.chunk_size = args.model_config['chunk_size']\n",
    "        self.chunk_overlap = args.model_config['chunk_overlap']\n",
    "        #self.max_d4rl_score = -1000.0\n",
    "        #self.total_updates = 0\n",
    "        self.tau = args.model_config['tau']\n",
    "        self.num_steps = args.num_steps\n",
    "        self.total_agents = args.total_agents\n",
    "        self.total_phases = args.total_phases\n",
    "        self.beta = args.model_config['beta']         #0.2 #Q_mse\n",
    "        self.alpha =args.model_config['alpha']          #0.1  #actionloss\n",
    "        self.entropy_coeff = args.model_config['entropy_coeff']         #0.1#0.5   #entropy loss in action\n",
    "        self.val_loss_coeff = args.model_config['val_loss_coeff']        #0.5      #Q loss\n",
    "        \n",
    "\n",
    "        # context_len_=200\n",
    "\n",
    "        self.model = DecisionTransformer(\n",
    "            state_dim=self.state_dim,\n",
    "            act_dim=self.act_dim,\n",
    "            n_blocks=self.n_blocks,\n",
    "            h_dim=self.embed_dim,\n",
    "            context_len=self.context_len,\n",
    "            n_heads=self.n_heads,\n",
    "            drop_p=self.dropout_p,\n",
    "            max_timestep=self.num_steps,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.target_model = DecisionTransformer(\n",
    "            state_dim=self.state_dim,\n",
    "            act_dim=self.act_dim,\n",
    "            n_blocks=self.n_blocks,\n",
    "            h_dim=self.embed_dim,\n",
    "            context_len=self.context_len,\n",
    "            n_heads=self.n_heads,\n",
    "            drop_p=self.dropout_p,\n",
    "            max_timestep=self.num_steps,\n",
    "            ).to(self.device)\n",
    "\n",
    "        # Set target network parameters to not require gradients\n",
    "        for param in self.target_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.copy_wt()\n",
    "        self.optimizer_2 = torch.optim.AdamW(self.model.parameters(),\n",
    "                lr=0.000005, weight_decay=self.wt_decay)  # lr,\n",
    "\n",
    "        # lr = 0.00001\n",
    "        \n",
    "        self.optimizer_1 = torch.optim.AdamW(self.model.parameters(),\n",
    "                lr=self.lr, weight_decay=self.wt_decay)  # lr,\n",
    "\n",
    "        #self.scheduler =             torch.optim.lr_scheduler.LambdaLR(self.optimizer_1, lambda steps: min((steps + 1) / self.warmup_steps, 1))\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer_1,T_max = self.total_epoch - self.warmup_epoch, eta_min=self.final_lr)\n",
    "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_1, T_0=150, T_mult=2, eta_min=0.01, last_epoch=-1)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def copy_wt(self):\n",
    "\n",
    "        # target_param.load_state_dict(param.state_dict())\n",
    "\n",
    "        for (param, target_param) in zip(self.model.parameters(),\n",
    "                self.target_model.parameters()):\n",
    "            target_param.data.copy_(self.tau * param.data + (1\n",
    "                                    - self.tau) * target_param.data)\n",
    "\n",
    "\n",
    "    def action_loss_fn_3(\n",
    "        self,\n",
    "        timesteps,\n",
    "        states,\n",
    "        actions_1,actions_2,log_probs_actions_2,\n",
    "        returns_to_go,\n",
    "        return_preds_last,\n",
    "        returns_to_go_cal_last,\n",
    "        print_,\n",
    "        action_masks\n",
    "        ):\n",
    "\n",
    "                         # action_preds_2,\n",
    "                         # action_mask,\n",
    "                         # return_preds_2,\n",
    "                         # returns_target,\n",
    "                         # beta = 0.2\n",
    "\n",
    "        # model : calculate the action for the states\n",
    "        # create a new dataset with last action replaced by a_pred_module\n",
    "        # predict value of the action using model critic\n",
    "        # torch sum value....\n",
    "\n",
    "        # pred_a1 = self.actor.forward(s1)\n",
    "        # loss_actor = -1*torch.sum(self.critic.forward(s1, pred_a1))\n",
    "        # self.actor_optimizer.zero_grad()\n",
    "        # loss_actor.backward()\n",
    "        # self.actor_optimizer.step()\n",
    "\n",
    "        # so what should i do ..... hmmm ... yeah i only need time steps where agent is the hero agent...\n",
    "\n",
    "        ################################\n",
    "        #no epoch no re prediction .... \n",
    "        \n",
    "    \n",
    "        if True: # this does not look into old values\n",
    "            ( #_, \n",
    "             action_logit_model_1,#action_model_2_dir\n",
    "                _,_,logp_pi_a_2_dir,dist_entropy_a_1) =   self.model.forward(timesteps=timesteps, states=states,\n",
    "                                   actions_1=actions_1,actions_2=actions_2,\n",
    "                                   returns_to_go=returns_to_go, print_=2,return_logit=True,return_og_log_prob_a2=True)  # print_\n",
    "    \n",
    "                                                            # ,info = info\n",
    "    \n",
    "            actions_1_ = actions_1.clone().detach()#, requires_grad=False)\n",
    "    \n",
    "            # self.actions_ = actions_\n",
    "            # self.action_preds_model_ = action_preds_model\n",
    "            # actions_[:,:,-1] = action_preds_model\n",
    "    \n",
    "\n",
    "            log_probs_1 = -torch.nn.functional.cross_entropy(action_logit_model_1[:, -1, :], \n",
    "                                           actions_1_[:, -1].long(), reduction=\"none\")\n",
    "            \n",
    "            #(a1_[:,-1,:][hero_steps[:,-1,0]]*action_masks[:,-1,:][hero_steps[:,-1,0]])\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            #actions_1_[:, -1] =     ((action_logit_model_1[:, -1, :] + 0.000001*action_masks) *action_masks).argmax(axis=1).clone().detach() #i will fix this later, there is an issue.... when probabilities for all legal actions are 0, the product is same as illigal actions \n",
    "            actions_1_[:, -1] =     (action_logit_model_1[:, -1, :] *action_masks).argmax(axis=1).clone().detach() #i will fix this later, there is an issue.... when probabilities for all legal actions are 0, the product is same as illigal actions \n",
    "\n",
    "            ( #_, \n",
    "             _,#action_logit_model_2\n",
    "                _,_,logp_pi_a_2,_,) =   self.model.forward(timesteps=timesteps, states=states,\n",
    "                                   actions_1=actions_1_,actions_2=actions_2,\n",
    "                                   returns_to_go=returns_to_go, print_=2,return_logit=True,return_og_log_prob_a2=True)\n",
    "            \n",
    "\n",
    "            \n",
    "            #if False:\n",
    "            #with torch.no_grad():\n",
    "            #    ( #_, \n",
    "            #     _,_,values_) =   self.model.forward(timesteps=timesteps, states=states,\n",
    "            #                       actions_1=actions_1_,actions_2=actions_2,\n",
    "            #                       returns_to_go=returns_to_go, print_=2,return_logit=False)\n",
    "\n",
    "            advantages  = returns_to_go_cal_last - return_preds_last.clone().detach()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            #if (not torch.isfinite(action_logit_model_1[:, -1,:]).all()) :\n",
    "            #    print('inf_error', 'action_logit_model_1')\n",
    "            #    print('action_logit_model_1',action_logit_model_1[:, -1,:])\n",
    "            #    print('log_probs_1',log_probs_1)\n",
    "            #    print('actions_1_',actions_1_[:, -1].long())\n",
    "            #    a()\n",
    "            #    \n",
    "            #if (not torch.isfinite(log_probs_1).all()):\n",
    "            #    print('inf_error', 'log_probs_1')\n",
    "            #    print('action_logit_model_1',action_logit_model_1[:, -1,:])\n",
    "            #    print('log_probs_1',log_probs_1)\n",
    "            #    print('actions_1_',actions_1_[:, -1].long())\n",
    "            #    a()\n",
    "            #    \n",
    "            #if (not torch.isfinite(actions_1_[:, -1].long() ).all())  :\n",
    "            #    print('inf_error','actions_1_')\n",
    "            #    print('action_logit_model_1',action_logit_model_1[:, -1,:])\n",
    "            #    print('log_probs_1',log_probs_1)\n",
    "            #    print('actions_1_',actions_1_[:, -1].long())\n",
    "            #    a()\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            try:\n",
    "                #the model is sending everyone .... 1. .... there must be an issue .... lower the weight\n",
    "                log_probs_2_dir = -torch.nn.BCELoss(reduction ='none')(\n",
    "\n",
    "                                               #logp_pi_a_2_dir[:, -1,0],\n",
    "                                               torch.clamp(logp_pi_a_2_dir[:, -1,0], min=0.00001, max=0.9999),\n",
    "                                               #torch.clamp(action_model_2_dir[:, -1,0], min=0.00001, max=0.9999), \n",
    "                                               torch.clamp(log_probs_actions_2[:, -1], min=0.00001, max=0.9999))\n",
    "\n",
    "                #if (not torch.isfinite(action_model_2_dir[:, -1,0]).all()) or (action_model_2_dir[:, -1,0] ==1).any() or (action_model_2_dir[:, -1,0] ==0).any():\n",
    "                #    print('inf_error', 'action_model_2_dir')\n",
    "                #    print('action_model_2_dir',action_model_2_dir[:, -1,0])\n",
    "                #    print('log_probs_2_dir',log_probs_2_dir)\n",
    "                #    print('actions_2',actions_2[:, -1])\n",
    "                #    a()\n",
    "                #    \n",
    "                #if (not torch.isfinite(log_probs_2_dir).all()):\n",
    "                #    print('inf_error', 'log_probs_1')\n",
    "                #    print('action_model_2_dir',action_model_2_dir[:, -1,0])\n",
    "                #    print('log_probs_2_dir',log_probs_2_dir)\n",
    "                #    print('actions_2',actions_2[:, -1])\n",
    "                #    a()\n",
    "                #\n",
    "                #if (not torch.isfinite(actions_2[:, -1]).all()):\n",
    "                #    print('inf_error', 'actions_2')\n",
    "                #    print('action_model_2_dir',action_model_2_dir[:, -1,0])\n",
    "                #    print('log_probs_2_dir',log_probs_2_dir)\n",
    "                #    print('actions_2',actions_2[:, -1])\n",
    "                #    a()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(logp_pi_a_2_dir[:, -1,0])\n",
    "                print(log_probs_actions_2[:, -1])\n",
    "                a()\n",
    "\n",
    "            log_probs_2 = -torch.nn.BCELoss(reduction ='none')(#logp_pi_a_2[:, -1,0],#action_logit_model_2[:, -1,0], \n",
    "                                                               torch.clamp(logp_pi_a_2[:, -1,0], min=0.00001, max=0.9999),\n",
    "                                           torch.clamp(log_probs_actions_2[:, -1], min=0.00001, max=0.9999)\n",
    "                                            )\n",
    "            \n",
    "            #if (not torch.isfinite(log_probs_2).all()):\n",
    "            #    #pass\n",
    "            #    print('inf_error', 'log_probs_2')\n",
    "            #    print('log_probs_2',log_probs_2)\n",
    "            #    a()\n",
    "\n",
    "            #if (not torch.isfinite(action_logit_model_2[:, -1,0]).all()) or (action_logit_model_2[:, -1,0] ==1).any() or (action_logit_model_2[:, -1,0] ==0).any():\n",
    "            #        print('inf_error', 'action_logit_model_2')\n",
    "            #        print('action_logit_model_2',action_logit_model_2[:, -1,0])\n",
    "            #        a()\n",
    "\n",
    "            #print(logp_pi_a_2_dir[:,-1,0],logp_pi_a_2[:,-1,0])\n",
    "\n",
    "            pi_loss = -((log_probs_1 +log_probs_2 + log_probs_2_dir)*(advantages)).mean() - self.entropy_coeff*dist_entropy_a_1.mean()\n",
    "\n",
    "            \n",
    "            \n",
    "            return pi_loss\n",
    "\n",
    "    def value_loss_fn_3(\n",
    "        self,\n",
    "        reward_last,\n",
    "        return_preds_last,\n",
    "        returns_target_last,\n",
    "        returns_to_go_cal_last,\n",
    "        beta=0.2,\n",
    "        alpha=2,\n",
    "        gamma=0.99,\n",
    "        device='cpu',\n",
    "        ):\n",
    "        \n",
    "        RT1 = reward_last[:-1] + gamma * returns_target_last[1:]\n",
    "        try:\n",
    "            Q_TD = torch.nn.functional.smooth_l1_loss(return_preds_last[:-1],RT1) \n",
    "            \n",
    "            Q_TD=Q_TD+torch.nn.functional.smooth_l1_loss(return_preds_last[[-1]], reward_last[[-1]])\n",
    "            \n",
    "            Q_MSE = torch.nn.functional.smooth_l1_loss(return_preds_last, returns_to_go_cal_last)\n",
    "            return (Q_TD ,  Q_MSE)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('in-v-loss')\n",
    "            print( 'return_preds_last' ,return_preds_last)\n",
    "            print('RT1' ,RT1)\n",
    "            print('reward_last' ,reward_last)\n",
    "            print('returns_to_go_cal_last' ,returns_to_go_cal_last)\n",
    "            a()\n",
    "\n",
    "        \n",
    "\n",
    "    def calculate_loss(\n",
    "        self,\n",
    "        timesteps,\n",
    "        returns_target, #target model predictions \n",
    "        returns_to_go_cal,  # Q calculated\n",
    "        hero_steps,#current_agent_acting,\n",
    "        states,\n",
    "        actions_1,actions_2,log_probs_actions_2,\n",
    "        return_preds,\n",
    "        return_preds_v        \n",
    "        ,reward, #actual rewards \n",
    "        returns_to_go,  #actual R2G given to the model\n",
    "        action_masks,\n",
    "        print_,\n",
    "        chunk_id,\n",
    "        divi\n",
    "        ):\n",
    "\n",
    "\n",
    "        \n",
    "        # only consider non padded elements\n",
    "\n",
    "        reward_last = reward[:, -1].squeeze().view(-1).to(self.device,dtype=torch.float32) #require the last reward only\n",
    "        return_preds_last = return_preds[:, -1,-1].squeeze().view(-1).to(self.device,dtype=torch.float32)  # act_dim , this is what out model predicted\n",
    "        return_preds_v_last = return_preds_v[:, -1,-1].squeeze().view(-1).to(self.device,dtype=torch.float32)  # act_dim , this is what out model predicted\n",
    "       \n",
    "        returns_target_last = returns_target[:, -1,-1].squeeze().view(-1).to(self.device,dtype=torch.float32) # target model prediction ... should be the 1st prediction\n",
    "       \n",
    "        returns_to_go_cal_last = returns_to_go_cal[:, -1,-1].squeeze().view(-1).to(self.device,dtype=torch.float32) # we need the Q value of the last action\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        hero_step_filter = hero_steps[:,-1,0] # current_agent_acting[:, -1, 0] == self.hero #last action is out heros\n",
    "\n",
    "        if sum(hero_step_filter) == 0:\n",
    "            policy_loss = torch.tensor(0,device=self.device)\n",
    "        else:\n",
    "            policy_loss = self.action_loss_fn_3(timesteps[hero_step_filter],\n",
    "                                                states[hero_step_filter],\n",
    "                                                actions_1[hero_step_filter],actions_2[hero_step_filter],log_probs_actions_2[hero_step_filter],\n",
    "                                                returns_to_go[hero_step_filter],\n",
    "                                                \n",
    "                                                return_preds_last[hero_step_filter],\n",
    "                                                \n",
    "                                                returns_to_go_cal_last[hero_step_filter], print_,\n",
    "                                               \n",
    "                                                action_masks[:,-1,:][hero_step_filter])\n",
    "\n",
    "        # but we need to figure out a little more\n",
    "\n",
    "\n",
    "\n",
    "        if  len(reward_last) == 0:\n",
    "            print('chunk_id',chunk_id)\n",
    "            print('reward',reward.shape)\n",
    "            print('reward_last',reward)\n",
    "            print('return_preds_last',return_preds_last.shape)\n",
    "\n",
    "\n",
    "            print('return_preds_last',return_preds_last)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if True:  # self.value_cal_loss:\n",
    "            (Q_TD , Q_MSE) = self.value_loss_fn_3(  # value_loss_fn(return_preds_2,return_target,action_mask,beta=1)\n",
    "                                    reward_last,\n",
    "                                    return_preds_v_last,\n",
    "                                    returns_target_last,\n",
    "                                    returns_to_go_cal_last,\n",
    "                                    beta=0.5,\n",
    "                                    alpha=2,\n",
    "                                    gamma=0.99\n",
    "                                )\n",
    "\n",
    "            Q_TD = Q_TD/divi\n",
    "            Q_MSE = Q_MSE/divi\n",
    "            Q_loss = Q_TD + self.beta*Q_MSE\n",
    "            \n",
    "            policy_loss =  policy_loss/divi\n",
    "\n",
    "            \n",
    "            total_loss = self.val_loss_coeff*Q_loss + self.alpha*policy_loss\n",
    "\n",
    "            if (not torch.isfinite(policy_loss)) or (not torch.isfinite(Q_TD)) or (not torch.isfinite(Q_MSE)):\n",
    "                print(divi, 'policy_loss',policy_loss,'Q_TD',Q_TD,'Q_MSE',Q_MSE)\n",
    "                a()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        return total_loss, (Q_TD, Q_MSE, Q_loss, policy_loss)\n",
    "\n",
    "    def train_write(self, iteration, print_=False):\n",
    "\n",
    "        total_loss_list = []\n",
    "        Q_TD_list = []\n",
    "        Q_MSE_list = []\n",
    "        Q_loss_list = []\n",
    "        policy_loss_list = []\n",
    "\n",
    "        if self.args.TB_log:\n",
    "            self.writer.add_scalar(\"charts/learning_rate\", self.optimizer_1.param_groups[0][\"lr\"], iteration)        \n",
    "        \n",
    "        for epoch in range(self.args.update_epochs):\n",
    "            for i,batch in enumerate(self.traj_data_loader):\n",
    "                total_loss = 0\n",
    "                Q_TD = 0\n",
    "                Q_MSE = 0\n",
    "                Q_loss = 0\n",
    "                policy_loss = 0\n",
    "                print(i)\n",
    "\n",
    "\n",
    "                batch_len = batch[0].shape[1]#2840\n",
    "                \n",
    "                if batch_len > self.chunk_size:\n",
    "                    a_ = [(i,i+self.chunk_size) for i in range(0, batch_len     -self.chunk_size,self.chunk_size-self.chunk_overlap)  ]\n",
    "                    a_  =a_+[ (a_[-1][1] -self.chunk_overlap ,batch_len) ]\n",
    "                else:\n",
    "                    a_ = [(0,batch_len)]\n",
    "    \n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                divi = len(a_)\n",
    "\n",
    "                \n",
    "                print('divi',divi,'chunk_size',self.chunk_size,'batch_shape',batch[0].shape)\n",
    "                \n",
    "                for (chunk_id, i) in enumerate(a_):#range(0,batch[0].shape[1] - self.chunk_size + 1,self.chunk_size - self.chunk_overlap)):\n",
    "\n",
    "                    # print(i,(i + self.chunk_size))\n",
    "                    total_loss_chunk, Q_TD_chunk, Q_MSE_chunk, Q_loss_chunk, policy_loss_chunk = self.train_write_smaller_chunk((tens[:, i[0]:i[1]] for tens in batch),\n",
    "                                                                                                                                    iteration, epoch, chunk_id, print_=print_,divi=divi)\n",
    "\n",
    "                    \n",
    "                    total_loss= total_loss + total_loss_chunk\n",
    "                    Q_TD = Q_TD+ Q_TD_chunk\n",
    "                    Q_MSE = Q_MSE+ Q_MSE_chunk\n",
    "                    Q_loss = Q_loss+ Q_loss_chunk\n",
    "                    policy_loss = policy_loss+ policy_loss_chunk\n",
    "\n",
    "                total_loss_list.append(total_loss)\n",
    "                Q_TD_list.append(Q_TD)\n",
    "                Q_MSE_list.append(Q_MSE)\n",
    "                Q_loss_list.append(Q_loss)\n",
    "                policy_loss_list.append(policy_loss)            \n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        \n",
    "        if iteration < self.warmup_epoch:\n",
    "            # Linear warmup: Gradually increase learning rate during warmup\n",
    "            lr = self.initial_lr * iteration / self.warmup_epoch\n",
    "            for param_group in self.optimizer_1.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        else:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        \n",
    "        print(\"total_loss\", np.mean(total_loss_list),\n",
    "              \"Q_TD\", np.mean(Q_TD_list),\n",
    "                \"Q_MSE\", np.mean(Q_MSE_list),\n",
    "                \"Q_loss\", np.mean(Q_loss_list),\n",
    "                \"policy_loss\", np.mean(policy_loss_list))\n",
    "\n",
    "        if self.args.TB_log:\n",
    "        \n",
    "            self.writer.add_scalar(\"total_loss\", np.mean(total_loss_list), iteration)\n",
    "            self.writer.add_scalar(\"Q_TD\", np.mean(Q_TD_list), iteration)\n",
    "            self.writer.add_scalar(\"Q_MSE\", np.mean(Q_MSE_list), iteration)\n",
    "            self.writer.add_scalar(\"Q_loss\", np.mean(Q_loss_list), iteration)\n",
    "            self.writer.add_scalar(\"policy_loss\", np.mean(policy_loss_list), iteration)    \n",
    "                    \n",
    "                \n",
    "                \n",
    "        \n",
    "        self.copy_wt()\n",
    "\n",
    "\n",
    "    def train_write_smaller_chunk(\n",
    "        self,\n",
    "        data,\n",
    "        iteration,\n",
    "        epoch,\n",
    "        chunk_id,\n",
    "        print_=False,divi = 1\n",
    "        ):\n",
    "\n",
    "        (\n",
    "            timesteps,\n",
    "            states,\n",
    "            actions_1,actions_2,log_probs_actions_2,\n",
    "            returntogo,\n",
    "            returns_to_go_cal,\n",
    "            returntogo_pred,\n",
    "            reward,\n",
    "            traj_mask,\n",
    "            action_masks,\n",
    "            current_agent_acting,\n",
    "            current_agent_simple,\n",
    "            current_agent,\n",
    "            current_phase,\n",
    "            current_troops_count,\n",
    "            ) = data\n",
    "\n",
    "\n",
    "        if len(timesteps[0].shape) ==0:\n",
    "            print( timesteps.shape )\n",
    "\n",
    "        \n",
    "        timesteps = timesteps[0].to(self.device)  # B x T\n",
    "        states = states[0].to(self.device)  # B x T x state_dim\n",
    "        actions_1 = actions_1[0].to(self.device)  # B x T x act_dim\n",
    "        actions_2 = actions_2[0].to(self.device)  # B x T x act_dim\n",
    "        log_probs_actions_2 = log_probs_actions_2[0].to(self.device)\n",
    "        reward = reward[0].to(self.device)\n",
    "        returns_to_go_cal =             returns_to_go_cal[0].to(self.device).unsqueeze(dim=-1)  # B x T x 1\n",
    "        returntogo = returntogo[0].to(self.device)\n",
    "        returntogo_pred = returntogo_pred[0].to(self.device)\n",
    "        traj_mask = traj_mask[0].to(self.device)  # B x T\n",
    "        action_masks = action_masks[0].to(self.device)\n",
    "        current_agent_acting = current_agent_acting[0].to(self.device)\n",
    "        current_agent_simple = current_agent_simple[0].to(self.device)\n",
    "        current_agent = current_agent[0].to(self.device)\n",
    "        current_phase = current_phase[0].to(self.device)\n",
    "        current_troops_count = current_troops_count[0].to(self.device)\n",
    "\n",
    "        info = dict({})\n",
    "\n",
    "\n",
    "        \n",
    "        hero_steps = current_agent_simple == self.hero\n",
    "\n",
    "        states = torch.cat((states, action_masks * hero_steps,\n",
    "                              current_phase, current_agent,\n",
    "                              current_troops_count[:, :, None]), axis=2)  # ,torch.ones(len(action_masks))[:,None]*self.hero\n",
    "        (action_pred_1,action_pred_2) =  (actions_1* hero_steps[:,0],\n",
    "                                                        actions_2* hero_steps[:,0]\n",
    "                                                         )\n",
    "\n",
    "\n",
    "    \n",
    "    def train_write_smaller_chunk_(\n",
    "        self,\n",
    "        data,\n",
    "        iteration,\n",
    "        epoch,\n",
    "        chunk_id,\n",
    "        print_=False,divi = 1\n",
    "        ):\n",
    "\n",
    "        (\n",
    "            timesteps,\n",
    "            states,\n",
    "            actions_1,actions_2,log_probs_actions_2,\n",
    "            returntogo,\n",
    "            returns_to_go_cal,\n",
    "            returntogo_pred,\n",
    "            reward,\n",
    "            traj_mask,\n",
    "            action_masks,\n",
    "            current_agent_acting,\n",
    "            current_agent_simple,\n",
    "            current_agent,\n",
    "            current_phase,\n",
    "            current_troops_count,\n",
    "            ) = data\n",
    "\n",
    "\n",
    "        if len(timesteps[0].shape) ==0:\n",
    "            print( timesteps.shape )\n",
    "\n",
    "        \n",
    "        timesteps = timesteps[0].to(self.device)  # B x T\n",
    "        states = states[0].to(self.device)  # B x T x state_dim\n",
    "        actions_1 = actions_1[0].to(self.device)  # B x T x act_dim\n",
    "        actions_2 = actions_2[0].to(self.device)  # B x T x act_dim\n",
    "        log_probs_actions_2 = log_probs_actions_2[0].to(self.device)\n",
    "        reward = reward[0].to(self.device)\n",
    "        returns_to_go_cal =             returns_to_go_cal[0].to(self.device).unsqueeze(dim=-1)  # B x T x 1\n",
    "        returntogo = returntogo[0].to(self.device)\n",
    "        returntogo_pred = returntogo_pred[0].to(self.device)\n",
    "        traj_mask = traj_mask[0].to(self.device)  # B x T\n",
    "        action_masks = action_masks[0].to(self.device)\n",
    "        current_agent_acting = current_agent_acting[0].to(self.device)\n",
    "        current_agent_simple = current_agent_simple[0].to(self.device)\n",
    "        current_agent = current_agent[0].to(self.device)\n",
    "        current_phase = current_phase[0].to(self.device)\n",
    "        current_troops_count = current_troops_count[0].to(self.device)\n",
    "\n",
    "        info = dict({})\n",
    "\n",
    "\n",
    "        \n",
    "        hero_steps = current_agent_simple == self.hero\n",
    "\n",
    "        states = torch.cat((states, action_masks * hero_steps,\n",
    "                              current_phase, current_agent,\n",
    "                              current_troops_count[:, :, None]), axis=2)  # ,torch.ones(len(action_masks))[:,None]*self.hero\n",
    "\n",
    "\n",
    "\n",
    "        #print(actions_1.requires_grad,actions_2.requires_grad)\n",
    "\n",
    "        (action_pred_1,action_pred_2) =  (actions_1* hero_steps[:,0],\n",
    "                                                        actions_2* hero_steps[:,0]\n",
    "                                                         )\n",
    "\n",
    "\n",
    "        #so this return to go is for value loss estimation\n",
    "\n",
    "        _,_, returntogo_pred_v,_ = self.model.forward(\n",
    "                                                        timesteps=timesteps,\n",
    "                                                        states=states,\n",
    "                                                        actions_1=action_pred_1,actions_2=action_pred_2,\n",
    "                                                        returns_to_go=returntogo,\n",
    "                                                            print_=print_\n",
    "                                                        #,info = info\n",
    "                                                    )\n",
    "        \n",
    "        # this is also for value function loss estimation\n",
    "\n",
    "        (#state_preds_target, \n",
    "         _,_,return_preds_target,_) =  self.target_model.forward(timesteps=timesteps,\n",
    "                                                                                states=states, actions_1=action_pred_1,actions_2=action_pred_2,\n",
    "                                                                                returns_to_go=returntogo, print_=print_)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        (#state_preds_target, \n",
    "         return_preds_target) = (return_preds_target.detach())\n",
    "\n",
    "\n",
    "        if  len(reward[:, -1].squeeze().view(-1).shape) == 0:\n",
    "            \n",
    "            print('return_preds_last',return_preds_target.shape)\n",
    "            print('reward_last',reward.shape)\n",
    "            print('returns_to_go_cal_last',returns_to_go_cal.shape)\n",
    "\n",
    "            print('return_preds_last',return_preds_target)\n",
    "            print('reward_last',reward)\n",
    "            print('returns_to_go_cal_last',returns_to_go_cal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        total_loss, (Q_TD, Q_MSE, Q_loss, policy_loss) = self.calculate_loss(\n",
    "                                                                                timesteps,\n",
    "                                                                                return_preds_target,#target model predictions \n",
    "                                                                                returns_to_go_cal, # Q calculated\n",
    "                                                                                hero_steps    ,#current_agent_acting,\n",
    "                                                                                states,\n",
    "                                                                                actions_1,actions_2,log_probs_actions_2,\n",
    "                                                                                returntogo_pred,\n",
    "                                                                                returntogo_pred_v,\n",
    "                                                                                reward,#actual rewards \n",
    "                                                                                returntogo,  #actual R2G given to the model\n",
    "                                                                                action_masks,\n",
    "                                                                                print_,\n",
    "                                                                                chunk_id,divi\n",
    "                                                                                )\n",
    "        #if chunk_id == 0:\n",
    "        #    print (chunk_id, total_loss)\n",
    "\n",
    "        # action_loss = #nn.CrossEntropyLoss().forward(action_preds_2,action_target)#F.mse_loss(action_preds_2, action_target.float(), reduction='mean')\n",
    "\n",
    "        self.optimizer_1.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.25)\n",
    "        self.optimizer_1.step()\n",
    "        #self.scheduler.step()\n",
    "        \n",
    "        # policy_loss.backward(retain_graph=True)\n",
    "\n",
    "        return total_loss.detach().item() ,Q_TD.detach().item(), Q_MSE.detach().item(), Q_loss.detach().item(), policy_loss.detach().item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def init_path(self):\n",
    "        self.paths = []\n",
    "        \n",
    "\n",
    "    def init_CL_sample_store(self):\n",
    "\n",
    "\n",
    "        if self.context_len > 1: # transformer model\n",
    "            self.DT_input = {  # self.actor_config_dict['ob_space']\n",
    "                'timestep': torch.zeros((1,\n",
    "                                        self.context_len),requires_grad =False).to(self.device,\n",
    "                        dtype=torch.int),\n",
    "                'state': torch.zeros((1, self.context_len,\n",
    "                                     self.state_dim),requires_grad =False).to(self.device,dtype=torch.float32),\n",
    "                'action_1': torch.zeros((1, self.context_len\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                'action_2': torch.zeros((1, self.context_len\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                \n",
    "                'return_to_go': torch.ones((1,\n",
    "                        self.context_len),requires_grad =False).to(self.device,dtype=torch.float32) * 110,\n",
    "                }\n",
    "        else: # single traje models\n",
    "            self.DT_input = {  # self.actor_config_dict['ob_space']\n",
    "                'timestep': torch.zeros((1,\n",
    "                                        ),requires_grad =False).to(self.device,\n",
    "                        dtype=torch.int),\n",
    "                'state': torch.zeros((1,\n",
    "                                     self.state_dim),requires_grad =False).to(self.device,dtype=torch.float32),\n",
    "                'action_1': torch.zeros((1,\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                'action_2': torch.zeros((1,\n",
    "                                      )).to(self.device,dtype=torch.float32),\n",
    "                \n",
    "                'return_to_go': torch.ones((1,\n",
    "                                    ),requires_grad =False).to(self.device,dtype=torch.float32) * 110,\n",
    "                }            \n",
    "    \n",
    "        self.returntogo = torch.zeros((self.num_steps,\n",
    "                1),requires_grad =False).to(self.device,dtype=torch.float32)  # self.total_agents\n",
    "        self.returntogo_pred = torch.zeros((self.num_steps,\n",
    "                1)).to(self.device,dtype=torch.float32)  # self.total_agents\n",
    "\n",
    "    #here\n",
    "    def current_model_in(\n",
    "        self,\n",
    "        observation,\n",
    "        curr_agent,\n",
    "        phase_mapping,\n",
    "        curr_agent_mapping,\n",
    "        env_board_agents=[],\n",
    "        ):\n",
    "\n",
    "\n",
    "\n",
    "        #single obs\n",
    "        self.model_in =  torch.hstack((observation['observation'\n",
    "                         ].reshape(-1).to(self.device),\n",
    "                         torch.tensor(observation['action_mask'\n",
    "                         ].reshape(-1)).to(self.device) * (curr_agent\n",
    "                         == self.hero), phase_mapping.to(self.device),\n",
    "                         curr_agent_mapping.to(self.device),\n",
    "                         ( (torch.tensor([env_board_agents[self.hero].bucket]).to(self.device) - 5.2496)/1.4733\n",
    "                                      )))[None,\n",
    "                         :].float().requires_grad_(False).to(self.device)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def update_CL_sample_store(\n",
    "        self,\n",
    "        curr_agent_,\n",
    "        inp={'step': None, 'act_2_1': [],'act_2_2': [], 'curr_reward_list': []},\n",
    "        before_action=True,\n",
    "        ):\n",
    "\n",
    "        if self.context_len > 1:\n",
    "            \n",
    "            if before_action == 1 :\n",
    "    \n",
    "                if inp['step'] == 0:\n",
    "    \n",
    "                    # print(self.model_in.shape)\n",
    "                    # print(self.model_in.repeat(self.context_len).shape)\n",
    "    \n",
    "                    self.DT_input['state'] = self.model_in.repeat(self.context_len,\n",
    "                            1).to(self.device)[None, :]\n",
    "                else:\n",
    "    \n",
    "                # if step<self.context_len:\n",
    "    \n",
    "                #    trace[step] = model_in\n",
    "    \n",
    "                    self.DT_input['state'][0, 0:-1] = self.DT_input['state'\n",
    "                            ][0, 1:].clone()\n",
    "                    self.DT_input['state'][0, -1] = self.model_in\n",
    "                    self.DT_input['timestep'][0, 0:-1] = self.DT_input['timestep'][0, 1:].clone()\n",
    "                    self.DT_input['timestep'][0, -1] = inp['step']\n",
    "                    self.DT_input['action_1'][0, 0:-1] = self.DT_input['action_1'][0, 1:].clone()\n",
    "                    self.DT_input['action_2'][0, 0:-1] = self.DT_input['action_2'][0, 1:].clone()\n",
    "                    \n",
    "                    self.DT_input['return_to_go'][0, 0:-1] = self.DT_input['return_to_go'][0, 1:].clone()\n",
    "            elif before_action == 2 :\n",
    "                if self.hero == curr_agent_:\n",
    "                    self.DT_input['action_1'][0, -1] = inp['act_2_1']\n",
    "                else:\n",
    "                    self.DT_input['action_1'][0, -1] = 0\n",
    "    \n",
    "            elif before_action == 3  :\n",
    "                if self.hero == curr_agent_:\n",
    "                    self.DT_input['action_2'][0, -1] = inp['act_2_2']\n",
    "                else:\n",
    "                    self.DT_input['action_2'][0, -1] = 0\n",
    "            else:\n",
    "                    \n",
    "                self.DT_input['return_to_go'][0, -1] = self.DT_input['return_to_go'][0, -1] -    inp['curr_reward_list']  # [self.hero]\n",
    "                self.returntogo[inp['step']] = self.DT_input['return_to_go'\n",
    "                        ][0, -1]\n",
    "\n",
    "        else:\n",
    "            if before_action == 1 :\n",
    "                self.DT_input['state'][0] = self.model_in\n",
    "                self.DT_input['timestep'][0] = inp['step']\n",
    "            elif before_action == 2 :\n",
    "                if self.hero == curr_agent_:\n",
    "                    self.DT_input['action_1'][0] = inp['act_2_1']\n",
    "                else:\n",
    "                    self.DT_input['action_1'][0] = 0                \n",
    "            \n",
    "            elif before_action == 3  :\n",
    "                if self.hero == curr_agent_:\n",
    "                    self.DT_input['action_2'][0] = inp['act_2_2']\n",
    "                else:\n",
    "                    self.DT_input['action_2'][0] = 0\n",
    "            else:\n",
    "                    \n",
    "                self.DT_input['return_to_go'][0] = self.DT_input['return_to_go'][0] -    inp['curr_reward_list']  # [self.hero]\n",
    "                self.returntogo[inp['step']] = self.DT_input['return_to_go'][0]               \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def update_train_data(\n",
    "        self,\n",
    "        step_count,\n",
    "        obs,\n",
    "        ob_space_shape,\n",
    "        rewards_2,\n",
    "        dones_2,\n",
    "        actions_1,\n",
    "        actions_2,\n",
    "        log_probs_actions_2,\n",
    "        action_masks,\n",
    "        current_agent,\n",
    "        current_agent_acting,\n",
    "        current_phase,\n",
    "        current_troops_count,\n",
    "        map_agent_phase_vector,\n",
    "        ):\n",
    "\n",
    "        \n",
    "        \n",
    "        data_ = collections.defaultdict(torch.tensor)\n",
    "        data_['observations'] =             obs[:step_count].reshape(-1,\n",
    "                np.prod(ob_space_shape))\n",
    "\n",
    "                # data_['next_observations'] = obs[1:step_count+1].to(device =self.args.pin_memory_device).reshape(-1,np.prod(T.ob_space_shape)) #torch.tensor([1,2,3,4])\n",
    "                # this return to go is the actual input\n",
    "\n",
    "        data_['returntogo'] =           self.returntogo[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['returntogo_pred'] =      self.returntogo_pred[:step_count]  # torch.tensor([1,2,3,4])\n",
    "\n",
    "        data_['rewards'] =              rewards_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['terminals'] =            dones_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['actions_1'] =            actions_1[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['actions_2'] =            actions_2[:step_count]  # torch.tensor([1,2,3,4])\n",
    "        data_['log_probs_actions_2'] =  log_probs_actions_2[:step_count]\n",
    "        data_['action_masks'] =         action_masks[:step_count]\n",
    "        data_['current_agent_acting'] = current_agent_acting[:step_count]\n",
    "        data_['current_agent_simple'] = current_agent[:step_count]\n",
    "        data_['current_agent'] =        map_agent_phase_vector(current_agent[:step_count],\n",
    "                                               num_classes=self.total_agents + 1)[:, 1:]\n",
    "        data_['current_phase'] =        map_agent_phase_vector(current_phase[:step_count],\n",
    "                                               num_classes=self.total_phases)\n",
    "        data_['current_troops_count'] = current_troops_count[:step_count]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        self.datase = TrajectoryDataset_per_episode([data_], #len(data[0]['observations'])<self.args.context_len\n",
    "                context_len=1,#self.args.context_len,\n",
    "                rtg_scale=1,#self.args.rtg_scale,\n",
    "                dev = self.device,#self.args.pin_memory_device,\n",
    "                 gamma=0.99#self.args.gamma\n",
    "                        )\n",
    "\n",
    "        self.path_que(DataLoader(self.datase, batch_size=len(self.datase)))\n",
    "    def path_que(self, dtl):\n",
    "        \n",
    "        if (len(self.paths)==self.rb_len):\n",
    "            if (self.rb_len >1):\n",
    "                self.paths.pop(random.randrange(len(self.paths)-self.args.num_episodes +1 )) # dont pop the most recent experiences and ensure rb_len > num.episodes\n",
    "            else: \n",
    "                self.paths.pop()\n",
    "        self.paths.append(dtl)\n",
    "        \n",
    "    def create_training_dataset(self):\n",
    "        self.traj_dataset =  TrajectoryDataset_2_through_episodes(self.paths)  # a dataset of dataloaders\n",
    "\n",
    "        self.traj_data_loader = DataLoader(  # only spit 1 episode a time\n",
    "            self.traj_dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=self.args.shuffle,\n",
    "            pin_memory=self.args.pin_memory,\n",
    "            drop_last=self.args.drop_last,\n",
    "            pin_memory_device=self.args.pin_memory_device,\n",
    "            )\n",
    "\n",
    "    \n",
    "    def action_predict(self, save_R=True, return_R=False,shift=1,action_masks = [],return_log_prob_a2 = False): \n",
    "        (#s, \n",
    "         a_1,a_2, R,lp) = self.model(timesteps=self.DT_input['timestep'],\n",
    "                               states=self.DT_input['state'],\n",
    "                               actions_1=self.DT_input['action_1'],\n",
    "                               actions_2=self.DT_input['action_2'],\n",
    "                               returns_to_go=( self.DT_input['return_to_go'][:, :, None] if self.context_len>1 else self.DT_input['return_to_go'][:, None]), \n",
    "                                return_log_prob_a2 = return_log_prob_a2)\n",
    "\n",
    "\n",
    "        took_action = False\n",
    "\n",
    "        \n",
    "\n",
    "        if self.context_len>1: # handling transformer model\n",
    "            # I need to handle for non transformer actions\n",
    "            if len(action_masks) > 0:\n",
    "                #handling when all the probability of masked actions are zero.... #have to force the model to pick 1st valid action.\n",
    "                masked_action = (a_1[0, -1, :]*action_masks)\n",
    "                #valid_ind = torch.nonzero(action_masks).squeeze()\n",
    "                if torch.any(masked_action !=0):\n",
    "                    took_action = True\n",
    "                    \n",
    "                    action_1 = (masked_action).argmax()[None]\n",
    "                else: #im hoping that slowly and steadily the model would learn to predict non zero probabilities for action mask\n",
    "                    \n",
    "                    action_1 = torch.tensor(np.random.choice(torch.where(action_masks)[0]))[None]  #(masked_action + 0.0000001*action_masks).argmax()[None]\n",
    "            else:\n",
    "                action_1 = a_1[0, -1, :].argmax()[None]\n",
    "                \n",
    "            action_2 = a_2[0,-1, 0][None]\n",
    "            if return_log_prob_a2:\n",
    "                log_prob = lp[0,-1, 0][None]\n",
    "            else:\n",
    "                log_prob = None\n",
    "            \n",
    "            if save_R:\n",
    "                self.returntogo_pred[self.DT_input['timestep'][0, -1]] =                 R[0, -1]  # R\n",
    "    \n",
    "            if return_R:\n",
    "                return (action_1, action_2, R[0, -1],took_action,log_prob)\n",
    "            else:\n",
    "                return action_1, action_2,took_action,log_prob\n",
    "\n",
    "\n",
    "        else: # not we are talking about the single obs models\n",
    "\n",
    "            # I need to handle for non transformer actions\n",
    "            if len(action_masks) > 0:\n",
    "                #handling when all the probability of masked actions are zero.... #have to force the model to pick 1st valid action.\n",
    "                masked_action = (a_1[0, :]*action_masks)\n",
    "                #valid_ind = torch.nonzero(action_masks).squeeze()\n",
    "                if torch.any(masked_action !=0):\n",
    "                    took_action = True\n",
    "                    \n",
    "                    action_1 = (masked_action).argmax()[None]\n",
    "                else: #im hoping that slowly and steadily the model would learn to predict non zero probabilities for action mask\n",
    "                    \n",
    "                    action_1 = torch.tensor(np.random.choice(torch.where(action_masks)[0]))[None]  #(masked_action + 0.0000001*action_masks).argmax()[None]\n",
    "            else:\n",
    "                action_1 = a_1[0, :].argmax()[None]\n",
    "                \n",
    "            action_2 = a_2[0, 0][None]\n",
    "            if return_log_prob_a2:\n",
    "                log_prob = lp[0, 0][None]\n",
    "            else:\n",
    "                log_prob = None\n",
    "            \n",
    "            if save_R:\n",
    "                self.returntogo_pred[self.DT_input['timestep'][0]] =                 R[0]  # R\n",
    "    \n",
    "            if return_R:\n",
    "                return (action_1, action_2, R[0],took_action,log_prob)\n",
    "            else:\n",
    "                return action_1, action_2,took_action,log_prob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "    def action_predict_direct(self, data, return_R=False,return_log_prob_a2 = False):\n",
    "        (timesteps, states, actions_1,actions_2, returns_to_go) = data\n",
    "        (#s, \n",
    "         a_1,a_2, R,lp) = self.model(timesteps=timesteps, states=states,\n",
    "                               actions_1=actions_1,actions_2=actions_2,\n",
    "                               returns_to_go=returns_to_go,return_log_prob_a2 = return_log_prob_a2)\n",
    "        if return_R:\n",
    "            return (a_1,a_2, R,lp)\n",
    "        else:\n",
    "            return a_1,a_2,lp\n",
    "\n",
    "    def save_models(self):\n",
    "        newpath = r'./models/' + self.run_name + '/' + str(self.hero)\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "        torch.save(self.model.state_dict(), newpath\n",
    "                   + '/a2c_transformer.pt')\n",
    "\n",
    "    def load_models(self):\n",
    "        newpath = r'./models/' + self.run_name + '/' + str(self.hero)\n",
    "        self.model.load_state_dict(torch.load(newpath\n",
    "                                   + '/a2c_transformer.pt'))\n",
    "        self.target_model.load_state_dict(torch.load(newpath\n",
    "                + '/a2c_transformer.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056dfe34-b872-459a-a0ab-2fed6ee1b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(1)[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc6e4d-f4d1-4016-9b83-3e73a2dd03ce",
   "metadata": {},
   "source": [
    "# hero agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb54a04-3ca6-4b9c-a5dd-976f958bb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Hero_agent(int):\n",
    "    def init_properties(self,agent_count,phases,cp=[],df=[],direct_action=True):\n",
    "        #self.draw_count = 0\n",
    "        self.init_win_count_iter(agent_count)\n",
    "        self.init_move_count_epi(phases)\n",
    "        self.cp = cp\n",
    "        self.df = df\n",
    "        self.direct_action = direct_action\n",
    "        self.init_reward_concern(agent_count,cp=cp,df=df)\n",
    "        \n",
    "    def init_reward_concern(self,agent_count,cp=[],df=[]):\n",
    "        if len(cp)==0:\n",
    "            cp = [int(self)]\n",
    "        self.concern=torch.tensor([(1 if i in cp \n",
    "                             else \n",
    "                             (-1 if i in df \n",
    "                                  else 0)) for i in range(1,agent_count+1) ])\n",
    "        #self.concern_2 = self.concern\n",
    "        #self.concern_2[self-1] =0\n",
    "        \n",
    "        self.multi_dependency = (sum(self.concern !=0)>1)\n",
    "        \n",
    "        \n",
    "    def init_model(self,model_name=\"DDQN_module\",\n",
    "                   kwarg = dict({})):\n",
    "        self.model = model_selector(model_name=model_name, \n",
    "                                    kwarg = kwarg)\n",
    "\n",
    "        \n",
    "    def init_win_count_iter(self,agent_count):\n",
    "        self.count_dict = {i:0 for i in range(1,agent_count+1)}\n",
    "        self.count_draw_dict = {i:0 for i in range(1,agent_count+1)}\n",
    "        self.draw_territory_count = 0\n",
    "    def init_move_count_epi(self,phases):\n",
    "        self.bad_move_count = 0\n",
    "        self.bad_move_phase_count = {i:0 for i in phases}\n",
    "        self.move_count =  {i:0 for i in phases}        \n",
    "    \n",
    "    def model_def(self, model):\n",
    "        self.model =model\n",
    "\n",
    "    def action_predict(self,save_R=True,return_R = False,action_masks = [],return_log_prob_a2 = False):\n",
    "        return self.model.action_predict(save_R=save_R,return_R = return_R, action_masks = action_masks,return_log_prob_a2 = return_log_prob_a2)\n",
    "\n",
    "    def action_predict_direct(self,data,return_R = False,return_log_prob_a2 = False):\n",
    "        return self.model.action_predict_direct(data,return_R = return_R,return_log_prob_a2 = return_log_prob_a2)\n",
    "    def save_models(self):\n",
    "        self.model.save_models()\n",
    "\n",
    "    def process_reward(self,rewards,step,hero_steps):\n",
    "        if self.multi_dependency and self.direct_action:\n",
    "            return (rewards*self.concern.to(rewards.device)).sum(-1)[:step][hero_steps][:,None]\n",
    "        elif self.multi_dependency and not self.direct_action:\n",
    "            base_rew = torch.zeros( rewards[:step,self-1][hero_steps].shape,require_grad=False)\n",
    "            #print(base_rew)\n",
    "\n",
    "            \n",
    "            hero_step_list  = np.arange(0,step)[hero_steps]\n",
    "            for i,j in zip(hero_step_list[:-1],hero_step_list[1:]):\n",
    "                if j-i>1:\n",
    "                    #print(j,i,rewards[i:j],(rewards[i:j]*self.concern),(rewards[i:j]*self.concern).sum())\n",
    "                    base_rew[i]+= (rewards[i:j]*self.concern).sum()\n",
    "            #print(base_rew,rewards[hero_step_list[-1]:],(rewards[hero_step_list[-1]:]*self.concern))\n",
    "            base_rew[-1]+= (rewards[hero_step_list[-1]:]*self.concern).sum()\n",
    "            \n",
    "            return base_rew[:,None]\n",
    "            \n",
    "        else:\n",
    "            return rewards[:step][hero_steps][:,None]\n",
    "    \n",
    "    #def model_forward_call(self,name,kwarg):\n",
    "    #    return self.model_dict[name](**kwarg)\n",
    "        \n",
    "\n",
    "a = Hero_agent(1)\n",
    "a.init_properties(3,[1,2,3],cp=[1],df=[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93987dc-f231-4bb2-b391-daacb339f6e9",
   "metadata": {},
   "source": [
    "# replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb52f02c-108a-429c-84c8-616be46650ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "class TrajectoryDataset_per_episode(Dataset): #this should have only 1 trajectory no matter what\n",
    "    def __init__(self, trajectories, context_len, rtg_scale,dev,gamma=0.99,min_len = 10**6):\n",
    "        self.trajectories = trajectories\n",
    "        self.context_len = context_len\n",
    "        self.dev = dev\n",
    "        min_len = min(min_len, len(self.trajectories[0]['observations'])) ##len(data[0]['observations'])<self.args.context_len\n",
    "\n",
    "\n",
    "        \n",
    "        #states = []\n",
    "        #for traj in self.trajectories:\n",
    "        #    traj_len = traj['observations'].shape[0]\n",
    "        #    min_len = min(min_len, traj_len)\n",
    "        #    states.append(traj['observations'])\n",
    "        #    # calculate returns to go and rescale them \n",
    "\n",
    "        self.pad_init()\n",
    "        \n",
    "        self.trajectories[0]['returns_to_go_cal'] = discount_cumsum(self.trajectories[0]['rewards'], gamma) / rtg_scale\n",
    "\n",
    "        self.trajectories[0]['current_troops_count'] = (self.trajectories[0]['current_troops_count'] - 5.2496)/1.4733\n",
    "        \n",
    "        #print(min_len)\n",
    "        \n",
    "        # used for input normalization\n",
    "        \n",
    "        #states = torch.concatenate(states, axis=0).to(dtype = torch.float32)\n",
    "        #self.state_mean, self.state_std = torch.mean(self.trajectories[0]['observations'], axis=0\n",
    "        #                                            ), torch.std(self.trajectories[0]['observations'], axis=0) + 1e-6\n",
    "\n",
    "        # normalize states\n",
    "        #for traj in self.trajectories:\n",
    "\n",
    "            #self.trajectories[0]['current_troops_count']\n",
    "            #traj['observations'] = (traj['observations'].to(dtype=torch.float32) - self.state_mean) / self.state_std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def pad_init(self):\n",
    "\n",
    "\n",
    "\n",
    "        #observations : torch.Size([255, 40]) torch.Size([2442, 40]) \n",
    "        # returntogo : torch.Size([255, 1]) torch.Size([2442, 1]) \n",
    "        # returntogo_pred : torch.Size([255, 1]) torch.Size([2442, 1]) \n",
    "        # rewards : torch.Size([255]) torch.Size([2442]) \n",
    "        # terminals : torch.Size([255]) torch.Size([2442]) \n",
    "        # actions :\n",
    "        #torch.Size([255, 2]) torch.Size([2442, 2]) \n",
    "        # action_masks : torch.Size([255, 32]) torch.Size([2442, 32]) \n",
    "        # current_agent_simple : torch.Size([255, 1]) torch.Size([2442, 1]) \n",
    "        # current_agent : torch.Size([255, 2]) torch.Size([2442, 2]) \n",
    "        # current_phase : torch.Size([255, 2]) torch.Size([2442, 2]) \n",
    "        # current_troops_count : torch.Size([255]) torch.Size([2442])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        self.trajectories[0]['observations'] =  torch.cat( (\n",
    "                                              self.trajectories[0]['observations'][0].repeat([self.context_len -1]+[1 for i in range(len(self.trajectories[0]['observations'].shape)-1) ]),\n",
    "                                              self.trajectories[0]['observations']\n",
    "                                              \n",
    "                                            ),dim=0)          \n",
    "        \n",
    "\n",
    "        self.trajectories[0]['returntogo'] =      torch.cat( (\n",
    "                                              self.trajectories[0]['returntogo'][[0]].repeat([self.context_len -1]+[1 for i in range(len(self.trajectories[0]['returntogo'].shape)-1) ]),\n",
    "                                              self.trajectories[0]['returntogo']\n",
    "                                              \n",
    "                                            ),dim=0)         # torch.tensor([1,2,3,4])\n",
    "        self.trajectories[0]['returntogo_pred'] =             torch.cat( (\n",
    "                                              self.trajectories[0]['returntogo_pred'][[0]].repeat([self.context_len -1]+[1 for i in range(len(self.trajectories[0]['returntogo_pred'].shape)-1) ]),\n",
    "                                              self.trajectories[0]['returntogo_pred']\n",
    "                                              \n",
    "                                            ),dim=0)   # torch.tensor([1,2,3,4])\n",
    "\n",
    "        self.trajectories[0]['rewards'] =    torch.cat( (\n",
    "                                              torch.zeros([self.context_len -1]).to(device=self.dev),\n",
    "                                              self.trajectories[0]['rewards']\n",
    "                                              \n",
    "                                            ),dim=0)  # torch.tensor([1,2,3,4])\n",
    "        self.trajectories[0]['terminals'] =    torch.cat( (\n",
    "                                              self.trajectories[0]['terminals'][[0]].repeat([self.context_len -1]+[1 for i in range(len(self.trajectories[0]['terminals'].shape)-1) ]),\n",
    "                                              self.trajectories[0]['terminals']\n",
    "                                              \n",
    "                                            ),dim=0)  # torch.tensor([1,2,3,4])\n",
    "\n",
    "        \n",
    "        self.trajectories[0]['actions_1'] =      torch.cat( (\n",
    "                                              torch.zeros([self.context_len -1]+list(self.trajectories[0]['actions_1'].shape[1:])).to(device=self.dev),\n",
    "                                              self.trajectories[0]['actions_1']\n",
    "                                              \n",
    "                                            ),dim=0)\n",
    "        \n",
    "        self.trajectories[0]['actions_2'] =      torch.cat( (\n",
    "                                              torch.zeros([self.context_len -1]+list(self.trajectories[0]['actions_2'].shape[1:])).to(device=self.dev),\n",
    "                                              self.trajectories[0]['actions_2']\n",
    "                                              \n",
    "                                            ),dim=0)\n",
    "\n",
    "        self.trajectories[0]['log_probs_actions_2'] = torch.cat( (\n",
    "                                              torch.zeros([self.context_len -1]+list(self.trajectories[0]['log_probs_actions_2'].shape[1:])).to(device=self.dev),\n",
    "                                              self.trajectories[0]['log_probs_actions_2']\n",
    "                                              \n",
    "                                            ),dim=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # torch.tensor([1,2,3,4])\n",
    "        self.trajectories[0]['action_masks'] =    torch.cat( (\n",
    "                                              torch.zeros([self.context_len -1]+list(self.trajectories[0]['action_masks'].shape[1:])).to(device=self.dev,dtype=torch.float32),\n",
    "                                              self.trajectories[0]['action_masks']\n",
    "                                              \n",
    "                                            ),dim=0)\n",
    "\n",
    "\n",
    "\n",
    "        self.trajectories[0]['current_agent_acting'] =     torch.cat( (\n",
    "                                                              torch.zeros([self.context_len -1]+list(self.trajectories[0]['current_agent_acting'].shape[1:])).to(device=self.dev,dtype=torch.float32),\n",
    "                                                              self.trajectories[0]['current_agent_acting']\n",
    "                                                              \n",
    "                                                            ),dim=0)\n",
    "        \n",
    "        self.trajectories[0]['current_agent_simple'] =     torch.cat( (\n",
    "                                                              torch.zeros([self.context_len -1]+list(self.trajectories[0]['current_agent_simple'].shape[1:])).to(device=self.dev,dtype=torch.float32),\n",
    "                                                              self.trajectories[0]['current_agent_simple']\n",
    "                                                              \n",
    "                                                            ),dim=0)\n",
    "\n",
    "        \n",
    "        self.trajectories[0]['current_agent'] =             torch.cat( (\n",
    "                                                              torch.zeros([self.context_len -1]+list(self.trajectories[0]['current_agent'].shape[1:])).to(device=self.dev,dtype=torch.float32),\n",
    "                                                              self.trajectories[0]['current_agent']\n",
    "                                                              \n",
    "                                                            ),dim=0)\n",
    "\n",
    "        \n",
    "        self.trajectories[0]['current_phase'] =             torch.cat( (\n",
    "                                                          self.trajectories[0]['current_phase'][0].repeat([self.context_len -1]+[1 for i in range(len(self.trajectories[0]['current_phase'].shape)-1) ]),\n",
    "                                                          self.trajectories[0]['current_phase']\n",
    "                                                          \n",
    "                                                        ),dim=0) \n",
    "        self.trajectories[0]['current_troops_count'] =      torch.cat( (\n",
    "                                              self.trajectories[0]['current_troops_count'][0].repeat([self.context_len -1]),\n",
    "                                              self.trajectories[0]['current_troops_count']\n",
    "                                              \n",
    "                                            ),dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        #print(len(self.trajectories),(self.trajectories[0].shape),len(self.trajectories[0])- self.context_len + 1 )\n",
    "        return sum(max(0, len(traj['observations'])- self.context_len + 1\n",
    "                      ) for traj in self.trajectories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        total_len = 0\n",
    "        for traj in self.trajectories:\n",
    "            \n",
    "            #print(total_len, idx - total_len, total_len + len(traj), - self.context_len + 1)\n",
    "            \n",
    "            if total_len  <= idx < total_len + len(traj['observations']) - self.context_len + 1    :\n",
    "                si = idx - total_len\n",
    "                \n",
    "                #context = traj[si:si + self.context_length]\n",
    "                states = (traj['observations'][si : si + self.context_len])\n",
    "                \n",
    "                actions_1 = traj['actions_1'][si : si + self.context_len]#torch.cat((traj['actions_1'][si : si + self.context_len-1].clone().detach(),   traj['actions_1'][[si + self.context_len-1]]      ),dim =0)\n",
    "                actions_2 = traj['actions_2'][si : si + self.context_len]#torch.cat((traj['actions_2'][si : si + self.context_len-1].clone().detach(),   traj['actions_2'][[si + self.context_len-1]]      ),dim =0)\n",
    "\n",
    "                log_probs_actions_2 = traj['log_probs_actions_2'][si : si + self.context_len]\n",
    "                \n",
    "                reward =  (traj['rewards'][si : si + self.context_len])\n",
    "                returntogo = (traj['returntogo'][si : si + self.context_len])\n",
    "                returns_to_go_cal = (traj['returns_to_go_cal'][si : si + self.context_len])\n",
    "                returntogo_pred = torch.cat((traj['returntogo_pred'][si : si + self.context_len-1].clone().detach(),  traj['returntogo_pred'][[ si + self.context_len-1]]       ),dim =0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                action_masks = (traj['action_masks'][si : si + self.context_len])\n",
    "\n",
    "                current_agent_acting = (traj['current_agent_acting'][si : si + self.context_len])\n",
    "                current_agent = (traj['current_agent'][si : si + self.context_len])\n",
    "                current_agent_simple = (traj['current_agent_simple'][si : si + self.context_len])\n",
    "                current_phase = (traj['current_phase'][si : si + self.context_len])\n",
    "                current_troops_count = (traj['current_troops_count'][si : si + self.context_len])\n",
    "    \n",
    "                \n",
    "                timesteps = torch.arange(start=si, end=si+self.context_len, step=1)\n",
    "    \n",
    "                # all ones since no padding\n",
    "                traj_mask = torch.ones(self.context_len, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "                if self.context_len> len(states):\n",
    "                    padding_len = self.context_len - len(states)\n",
    "    \n",
    "                    states                = torch.cat([states,\n",
    "                                    torch.zeros(([padding_len] + list(states.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)  \n",
    "                    actions_1               = torch.cat([actions_1,\n",
    "                                    torch.zeros(([padding_len] + list(actions_1.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)\n",
    "                    \n",
    "                    actions_2               = torch.cat([actions_2,\n",
    "                                    torch.zeros(([padding_len] + list(actions_2.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)\n",
    "\n",
    "                    log_probs_actions_2 =  torch.cat([log_probs_actions_2,\n",
    "                                    torch.zeros(([padding_len] + list(log_probs_actions_2.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)\n",
    "                    \n",
    "                    reward                = torch.cat([reward,\n",
    "                                    torch.zeros(([padding_len] + list(reward.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)  \n",
    "\n",
    "\n",
    "                    returntogo            = torch.cat([returntogo,\n",
    "                                    torch.zeros(([padding_len] + list(returntogo.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)\n",
    "                    returns_to_go_cal     = torch.cat([returns_to_go_cal,\n",
    "                                    torch.zeros(([padding_len] + list(returns_to_go_cal.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)\n",
    "                    returntogo_pred       = torch.cat([returntogo_pred,\n",
    "                                    torch.zeros(([padding_len] + list(returntogo_pred.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "                    action_masks          = torch.cat([action_masks,\n",
    "                                    torch.zeros(([padding_len] + list(action_masks.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)        \n",
    "\n",
    "                    current_agent_acting = torch.cat([current_agent_acting,\n",
    "                                    torch.zeros(([padding_len] + list(current_agent_acting.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)\n",
    "                    \n",
    "                    current_agent         = torch.cat([current_agent,\n",
    "                                    torch.zeros(([padding_len] + list(current_agent.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)\n",
    "                    \n",
    "                    current_troops_count = torch.cat([current_troops_count,\n",
    "                                        torch.zeros(([padding_len] + list(current_troops_count.shape[1:])),\n",
    "                                        dtype=current_troops_count.dtype\n",
    "                                                   )], \n",
    "                                       dim=0)\n",
    "                    current_phase         = torch.cat([current_phase,\n",
    "                                    torch.zeros(([padding_len] + list(current_phase.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)         \n",
    "                    current_troops_count  = torch.cat([current_troops_count,\n",
    "                                    torch.zeros(([padding_len] + list(current_troops_count.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)                \n",
    "                    traj_mask             = torch.cat([traj_mask,\n",
    "                                    torch.zeros(([padding_len] + list(traj_mask.shape[1:])),\n",
    "                                    dtype=reward.dtype\n",
    "                                               )], \n",
    "                                   dim=0)     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                return  timesteps, states, actions_1,actions_2,log_probs_actions_2, returntogo, returns_to_go_cal, returntogo_pred,reward, traj_mask ,action_masks,current_agent_acting,current_agent_simple,current_agent,current_phase,current_troops_count\n",
    "                \n",
    "                #return pad(torch.tensor(context), (0,(self.context_length - len(context))),mode=\"constant\"), [1]\n",
    "\n",
    "            total_len += len(traj) - self.context_len + 1\n",
    "\n",
    "        raise IndexError(\"Index out of range 1\")\n",
    "\n",
    "\n",
    "class TrajectoryDataset_2_through_episodes(Dataset):\n",
    "    def __init__(self, trajectories):\n",
    "        self.trajectories = trajectories\n",
    "\n",
    "        #all_obs = torch.concat([ traj.dataset.trajectories[0]['observations'] for traj in self.trajectories],axis=0)\n",
    "        #self.state_mean = torch.mean(all_obs,axis =0)\n",
    "        #self.state_std = torch.std(all_obs,axis =0) + 1e-6\n",
    "        \n",
    "        #for traj in self.trajectories:\n",
    "        #    traj.dataset.trajectories[0]['observations'] = (traj.dataset.trajectories[0]['observations'].to(dtype=torch.float32) - self.state_mean) / self.state_std\n",
    "\n",
    "\n",
    "        #print(self.state_mean,self.state_std)\n",
    "        \n",
    "    #def get_state_stats(self):\n",
    "        #return self.state_mean, self.state_std        \n",
    "\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        total_len = 0\n",
    "        if total_len  <= idx < total_len + len(self.trajectories)  :\n",
    "            return [batch for batch in self.trajectories[idx] ][0]\n",
    "\n",
    "\n",
    "        raise IndexError(\"Index out of range 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff383a25-6ff6-4efd-805e-68181b016dd8",
   "metadata": {},
   "source": [
    "# trainer module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "442272e1-3d31-49aa-9a78-7758b6dd1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    ## Trainer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Args,param_dict =dict({})\n",
    "                 ):\n",
    "        # #### Configurations\n",
    "\n",
    "        self.args = Args()#tyro.cli(Args)\n",
    "        self.param_dict = param_dict\n",
    "        self.update_arg(param_dict=param_dict)\n",
    "        self.device = self.args.device#torch.device(\"cuda\" if torch.cuda.is_available() and self.args.cuda else \"cpu\")\n",
    "        \n",
    "        \n",
    "        #self.args.batch_size = int(self.args.num_envs * self.args.num_steps)\n",
    "        self.args.minibatch_size = int(self.args.batch_size // self.args.num_minibatches)\n",
    "        #self.args.num_iterations = self.args.total_timesteps // self.args.batch_size\n",
    "        self.gam = self.args.gamma\n",
    "        #self.args.minibatch_size = 256#128 \n",
    "        self.num_steps = self.args.num_steps#120000#1000000\n",
    "        self.num_iterations = self.args.num_iterations\n",
    "        self.episode_time_lim = self.args.episode_time_lim\n",
    "        self.hero_agent_count = self.args.hero_agent_count\n",
    "        self.env_config = self.args.env_config\n",
    "        self.num_episodes = self.args.num_episodes\n",
    "        self.context_len=self.args.model_config['context_len'] #200\n",
    "\n",
    "        self.training_performance_return = []\n",
    "        \n",
    "        #self.env_config = dict(render_mode = 'rgb_array', default_attack_all  = True,\n",
    "        #                    agent_count  = 4\n",
    "        #                       ,use_placement_perc=True,render_=False)        \n",
    "        \n",
    "        self.run_name = f\"{self.args.env_id}__{self.args.exp_name}__{self.args.seed}__{int(time.time())}\"\n",
    "\n",
    "        \n",
    "\n",
    "        TB_log = self.args.TB_log \n",
    "        if TB_log:    \n",
    "            self.writer = SummaryWriter(f\"runs/{self.run_name}\")\n",
    "            self.writer.add_text(\n",
    "                \"hyperparameters\",\n",
    "                \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(self.args).items()])),\n",
    "            )\n",
    "        else:\n",
    "            self.writer = None\n",
    "        \n",
    "        # TRY NOT TO MODIFY: seeding\n",
    "        random.seed(self.args.seed)\n",
    "        np.random.seed(self.args.seed)\n",
    "        #torch.manual_seed(self.args.seed)\n",
    "        \n",
    "        torch.backends.cudnn.deterministic = self.args.torch_deterministic\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.playe_r = 1#\"agent_1\" #\n",
    "        \n",
    "\n",
    "        \n",
    "        self.action_shape = (2,)\n",
    "\n",
    "\n",
    "\n",
    "        self.env = env_risk(**self.env_config)\n",
    "        \n",
    "        self.env.reset(seed=42)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        self.args.total_agents = self.total_agents  = len(self.env.possible_agents)\n",
    "        self.args.total_phases = self.total_phases = len(self.env.phases)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        print(torch.tensor(self.env.last()[0]['observation']\n",
    "                          ))\n",
    "\n",
    "        print(torch.tensor(self.env.last()[0]['observation']\n",
    "                          ).to(device=self.device))\n",
    "        sample_obs = self.obs_converter(torch.tensor(self.env.last()[0]['observation']\n",
    "                                                    ).to(device=self.device),\n",
    "                                        num_classes = self.total_agents+1\n",
    "                                       )\n",
    "        \n",
    "        self.ob_space_shape = sample_obs.shape #env.observation_space(playe_r)['observation'].shape\n",
    "        self.action_mask_shape = self.env.observation_space(self.playe_r)['action_mask'].shape\n",
    "        \n",
    "        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "        \n",
    "        \n",
    "        self.agent_list = list(self.env.possible_agents)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        self.the_hero_agent = 1\n",
    "\n",
    "        \n",
    "        self.qnet_config_dict = dict(action_space = self.env.action_space(self.playe_r\n",
    "                                                                         ).shape[0],\n",
    "                                    ob_space=(np.prod(self.ob_space_shape\n",
    "                                                    )+np.prod(self.action_mask_shape)\n",
    "                                         +1*( self.total_agents -1) #the current_agent +1#who actor agent was\n",
    "                                         +1*(self.total_phases -1)#the current phase\n",
    "                                         +1 )# the number of troops\n",
    "                               )\n",
    "        self.actor_config_dict =  dict(env=self.env,\n",
    "                        action_space = self.env.observation_space(self.playe_r)['action_mask'].shape[0],\n",
    "                        ob_space=(np.prod(self.ob_space_shape)\n",
    "                                         +np.prod(self.action_mask_shape)\n",
    "                                         +1*( self.total_agents-1) #the current_agent +1#who actor agent was\n",
    "                                         +1*(self.total_phases -1)#the current phase\n",
    "                                         +1) # the number of troops\n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        #torch.Tensor(torch.hstack((observation['observation'].reshape(-1),\n",
    "        #                            torch.tensor(observation['action_mask'].reshape(-1)).to(self.device),\n",
    "        #                                   phase_mapping,\n",
    "        #                                    curr_agent_mapping,\n",
    "        #                                   torch.tensor([env.board.agents[curr_agent].bucket ]).to(self.device)))[None,:]#.repeat(3,axis = 0)\n",
    "        #                                        ).float()\n",
    "                        \n",
    "        \n",
    "        self.hero_agents_list = {i:Hero_agent(i) for i in range(1,self.hero_agent_count+1) } # this is a list , need to pass it as an argument\n",
    "        \n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].init_properties(self.total_agents,self.env.phases)        \n",
    "\n",
    "\n",
    "            print(len(self.args.model_name[i]))\n",
    "            \n",
    "            self.hero_agents_list[i].init_model(model_name=self.args.model_name[i], kwarg = dict(\n",
    "\n",
    "                                                qnet_config_dict = self.qnet_config_dict, \n",
    "                                                actor_config_dict = self.actor_config_dict,\n",
    "                                                args = self.args,\n",
    "                                                device = self.device,\n",
    "                                                writer=self.writer,\n",
    "                                                run_name=self.run_name,\n",
    "                                                agent=i)\n",
    "                                                )\n",
    "            \n",
    "\n",
    "            #self.target_actor.load_state_dict(self.actor.state_dict())\n",
    "            #self.qf1_target.load_state_dict(self.qf1.state_dict())\n",
    "            #self.q_optimizer = optim.Adam(list(self.qf1.parameters()), lr=self.args.learning_rate)\n",
    "            #self.actor_optimizer = optim.Adam(list(self.actor.parameters()), lr=self.args.learning_rate)\n",
    "\n",
    "    def update_arg(self,param_dict=dict({})):\n",
    "       for i,j in param_dict.items():\n",
    "           setattr(self.args,i,j)\n",
    "\n",
    "        \n",
    "\n",
    "    def obs_converter(self,  data, num_classes = 4, col =0 ):\n",
    "\n",
    "        if col != None:\n",
    "\n",
    "            #print(data.device)\n",
    "            #print(nn.functional.one_hot(data[:4,col].detach().long(), \n",
    "            #                                            num_classes = num_classes).to(self.device))\n",
    "            return torch.concat((nn.functional.one_hot(data[:,col].detach().long(), \n",
    "                                                        num_classes = num_classes).to(self.device),\n",
    "                                      data[:,~col,None]\n",
    "                                ),axis=1\n",
    "                               )[:,1:].to(self.device)\n",
    "    \n",
    "    def map_agent_phase_hot(self, data,num_classes = 3):\n",
    "        with torch.no_grad():\n",
    "            return nn.functional.one_hot(torch.tensor(data),num_classes = num_classes)[1:].to(self.device)\n",
    "    \n",
    "    def map_agent_phase_vector(self, data,num_classes = 3):\n",
    "        with torch.no_grad():\n",
    "            return nn.functional.one_hot(data[:,0].long(), \n",
    "                                                            num_classes = num_classes)[:,1:].to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def train_loop_init(self):\n",
    "        self.gamma_t = {i:0 for i in self.env.possible_agents}\n",
    "        \n",
    "        \n",
    "        self.draw_count = 0\n",
    "\n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].init_win_count_iter(self.total_agents )\n",
    "            self.hero_agents_list[i].model.init_path()\n",
    "        \n",
    "         \n",
    "        #self.first_count = 0\n",
    "        #self.second_count = 0\n",
    "        #self.third_count = 0\n",
    "        #self.third_count_draw = 0\n",
    "        \n",
    "        self.start_time = time.time()\n",
    "        self.global_step = 0\n",
    "        #self.faulting_player = \"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    def run_training_loop(self):\n",
    "        \"\"\"\n",
    "        ### Run training loop\n",
    "        \"\"\"\n",
    "\n",
    "        # last 100 episode information\n",
    "        #tracker.set_queue('reward', 100, True)\n",
    "        #tracker.set_queue('length', 100, True)\n",
    "\n",
    "\n",
    "        for i in self.hero_agents_list: # each agent has his own buffer, this is kinda pain because now this information is stored and not discarded\n",
    "    \n",
    "            self.hero_agents_list[i].rb = ReplayBuffer(\n",
    "                    self.args.buffer_size,\n",
    "                    Box(low =0, high=2000, shape =(self.qnet_config_dict['ob_space']+1,), dtype=np.float32),\n",
    "                    Box(low =0, high=2000, shape =(2,), dtype=np.float32),\n",
    "                    self.device,\n",
    "                    handle_timeout_termination=False,\n",
    "                )\n",
    "\n",
    "        env = env_risk(**(self.env_config #| {\"render_mode\" : None, \"bad_mov_penalization\" : 0.01,\"render_\":False}\n",
    "                         ))\n",
    "        env.reset(42)\n",
    "        \n",
    "        self.train_loop_init()\n",
    "        #self.paths=[]\n",
    "        \n",
    "        self.training_performance_return = []\n",
    "        \n",
    "        for iteration in range(1, self.num_iterations+1):\n",
    "\n",
    "\n",
    "            #1st you sample data\n",
    "            self.sample(\n",
    "                                env,iteration,\n",
    "                                \n",
    "                                \n",
    "                 \n",
    "                            )\n",
    "\n",
    "            \n",
    "            #2nd you create a new dataset\n",
    "            for i in self.hero_agents_list:\n",
    "                    self.hero_agents_list[i].model.create_training_dataset()\n",
    "\n",
    "            \n",
    "            #3rd you train the model\n",
    "            self.train(iteration)\n",
    "            #break\n",
    "\n",
    "            \n",
    "            \n",
    "            #if self.global_step%100 ==0:\n",
    "            #    SPS = int(self.global_step / (time.time() - self.start_time))\n",
    "            #    print(\"SPS:\", SPS)       \n",
    "            #    self.writer.add_scalar(\"charts/SPS\", SPS, self.global_step)\n",
    "        \n",
    "            \n",
    "            self.save_models()\n",
    "\n",
    "    def train(self,iteration):\n",
    "\n",
    "        if True:#self.global_step > self.args.learning_starts:\n",
    "\n",
    "            for i in self.hero_agents_list:\n",
    "                self.hero_agents_list[i].model.train_write(\n",
    "                        iteration,print_=True)\n",
    "                \n",
    "                        \n",
    "                    \n",
    "    \n",
    "    def train_(self,iteration):\n",
    "        \n",
    "        for epoch in range(self.args.update_epochs):\n",
    "            \n",
    "            if self.global_step > self.args.learning_starts:\n",
    "\n",
    "                for i in self.hero_agents_list:\n",
    "                    self.hero_agents_list[i].model.train_write(self.hero_agents_list[i].rb.sample(self.args.batch_size)\n",
    "                                                         ,iteration,epoch)\n",
    "                    \n",
    "    def save_models(self):\n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].save_models()  \n",
    "\n",
    "    def reset_moves_hero_agents(self):\n",
    "        for i in self.hero_agents_list:\n",
    "            self.hero_agents_list[i].init_move_count_epi(self.env.phases)\n",
    "\n",
    "\n",
    "    def set_episode_recorders(self):\n",
    "        obs = torch.zeros((self.num_steps,) + self.ob_space_shape, requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        \n",
    "        actions_1 = torch.zeros((self.num_steps,) ).to(self.device,    dtype = torch.float32)\n",
    "        \n",
    "        actions_2 = torch.zeros( (self.num_steps,)).to(self.device,    dtype = torch.float32)\n",
    "        log_probs_actions_2 = torch.zeros( (self.num_steps,)).to(self.device,    dtype = torch.float32)\n",
    "        \n",
    "        action_masks = torch.zeros((self.num_steps, ) + self.action_mask_shape, requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        current_agent = torch.zeros((self.num_steps,1), requires_grad =False).to(self.device,    dtype = torch.float32)*0#-1\n",
    "        current_agent_acting = torch.ones((self.num_steps,1), requires_grad =False).to(self.device,    dtype = torch.float32)*0\n",
    "        current_phase = torch.zeros((self.num_steps,1), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        current_troops_count = torch.zeros((self.num_steps,self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        #logprobs = torch.zeros((self.num_steps, ), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        rewards = torch.zeros((self.num_steps, self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        rewards_2 = torch.zeros((self.num_steps, self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        \n",
    "        returntogo = torch.zeros((self.num_steps, self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "        dones = torch.zeros((self.num_steps, self.total_agents), requires_grad =False).to(self.device)\n",
    "        dones_2 = torch.zeros((self.num_steps, self.total_agents), requires_grad =False).to(self.device)\n",
    "        #values = torch.zeros((self.num_steps,  )).to(self.device)\n",
    "        episodes = torch.ones((self.num_steps, ), requires_grad =False).to(self.device,    dtype = torch.float32)*-1\n",
    "        t_next = torch.zeros((self.num_steps, self.total_agents), requires_grad =False).to(self.device,    dtype = torch.float32)\n",
    "            \n",
    "        total_rewards = {i:0 for i in env.possible_agents} #i can report this\n",
    "\n",
    "        return (\n",
    "                obs\n",
    "                ,actions_1\n",
    "                ,actions_2\n",
    "                ,log_probs_actions_2\n",
    "                ,action_masks\n",
    "                ,current_agent\n",
    "                ,current_agent_acting\n",
    "                ,current_phase\n",
    "                ,current_troops_count\n",
    "                ,rewards\n",
    "                ,rewards_2\n",
    "                ,returntogo\n",
    "                ,dones\n",
    "                ,dones_2\n",
    "                ,episodes\n",
    "                ,t_next\n",
    "                ,total_rewards\n",
    "                )\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    def sample(self,env,iteration\n",
    "                                ):\n",
    "        \n",
    "\n",
    "        #for i in self.hero_agents_list:\n",
    "        #    self.hero_agents_list[i].model.init_path()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        #if True:\n",
    "            # sample `worker_steps` from each worker\n",
    "            #there are no worker steps... rather there are full episodes\n",
    "\n",
    "            step = 0\n",
    "            fault_condition = False\n",
    "            clear_output(wait=True)\n",
    "            phase = 0\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            for episode in range(self.num_episodes):#num_episodes):\n",
    "                #num_steps is the maximum number of steps before the game is stopped\n",
    "\n",
    "\n",
    "                (\n",
    "                obs\n",
    "                ,actions_1\n",
    "                ,actions_2\n",
    "                ,log_probs_actions_2\n",
    "                ,action_masks\n",
    "                ,current_agent\n",
    "                ,current_agent_acting\n",
    "                ,current_phase\n",
    "                ,current_troops_count\n",
    "                ,rewards\n",
    "                ,rewards_2\n",
    "                ,returntogo\n",
    "                ,dones\n",
    "                ,dones_2\n",
    "                ,episodes\n",
    "                ,t_next\n",
    "                ,total_rewards\n",
    "                ) = self.set_episode_recorders()\n",
    "                \n",
    "                #trace = tensor.zeros((self.context_len,self.qnet_config_dict['ob_space']))\n",
    "                action=1\n",
    "                #return2g = 110\n",
    "                \n",
    "                \n",
    "                #init model sample store : but do i need it now?\n",
    "                for i in self.hero_agents_list:\n",
    "                    self.hero_agents_list[i].model.init_CL_sample_store()\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                if fault_condition:\n",
    "                    env = env_risk(**(self.env_config  #| {\"render_mode\" : None,\"bad_mov_penalization\" : 0.01,\"render_\":False#False\n",
    "                                                        # }\n",
    "                                     )\n",
    "                                      )#game.env(render_mode=None)\n",
    "\n",
    "                curren_epi = episode + (iteration-1)*self.num_episodes\n",
    "                env.reset(curren_epi) #for riplication\n",
    "                fault_condition = False\n",
    "                step_count = 0\n",
    "                \n",
    "                self.reset_moves_hero_agents()\n",
    "                is_draw = 0\n",
    "                \n",
    "                #draw_territory_count = 0\n",
    "                #is_third = 0\n",
    "\n",
    "                for agent in env.agent_iter(): # episode loop\n",
    "                    e_t = env.terminations\n",
    "                    if sum(e_t.values()) <(self.total_agents-1):\n",
    "                        observation, reward, termination, truncation, info = env.last()\n",
    "        \n",
    "                        observation['observation'] =  self.obs_converter(\n",
    "                                                        torch.tensor(\n",
    "                                                            observation['observation']\n",
    "                                                        ).to(self.device,dtype=torch.float32),\n",
    "                                                        num_classes = self.total_agents+1)\n",
    "                        \n",
    "                        observation['observation'][:,-1]  =  (observation['observation'][:,-1] - 5.2496)/1.4733\n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        episodes[step_count] = curren_epi\n",
    "                        obs[step_count] = observation['observation'] #torch.Tensor(observation['observation']).to(self.device) #sould i not add it .... meaning this is the last observation after the player dies\n",
    "                        action_masks[step_count] = torch.Tensor(observation['action_mask']).to(self.device)\n",
    "                        \n",
    "                        #curr_agent = agent#int(agent[-1])\n",
    "                        current_agent[step_count] = curr_agent = agent\n",
    "                        current_phase[step_count] = phase = env.phase_selection\n",
    "                        phase_mapping = self.map_agent_phase_hot(phase,num_classes = self.total_phases).float()\n",
    "                        \n",
    "                        curr_agent_mapping = self.map_agent_phase_hot(int(curr_agent)-1,\n",
    "                                                                      num_classes = self.total_agents \n",
    "                                                                     ).float()\n",
    "                        \n",
    "                        current_troops_count[step_count] = torch.tensor([env.board.agents[i].bucket for i in env.possible_agents],requires_grad =False).to(self.device)\n",
    "                    \n",
    "\n",
    "                        \n",
    "\n",
    "                        for i in self.hero_agents_list:\n",
    "                            self.hero_agents_list[i].model.current_model_in(observation,curr_agent,\n",
    "                                                                            phase_mapping,curr_agent_mapping,\n",
    "                                                                            env_board_agents=env.board.agents)\n",
    "                            self.hero_agents_list[i].model.update_CL_sample_store(curr_agent_=i,\n",
    "                                                                                  inp = {'step':step_count,\n",
    "                                                                                         'act_2_1':[] ,\n",
    "                                                                                         'act_2_2':[] ,\n",
    "                                                                                         'curr_reward_list':[]\n",
    "                                          },before_action=1)\n",
    "                            \n",
    "                        \n",
    "                        action_taken = False\n",
    "                        log_prob_a2 = None  \n",
    "                        if True:\n",
    "                            \n",
    "                            mask = observation[\"action_mask\"]\n",
    "                            if (self.global_step < self.args.learning_starts) or (\n",
    "                                np.random.rand() > min(\n",
    "                                                ((curren_epi)/((self.num_iterations*self.num_episodes)/10))\n",
    "                                                , 0.95)\n",
    "                                                #) or (agent != self.the_hero_agent) \n",
    "                                                ) or ( agent not in self.hero_agents_list):\n",
    "        \n",
    "                                \n",
    "                                action = env.action_space(agent).sample()\n",
    "                                \n",
    "                                #part_0 =np.random.choice(np.where(env.board.calculated_action_mask(agent))[0])\n",
    "                                part_0 =np.random.choice(np.where(observation['action_mask'])[0])\n",
    "                                action = torch.tensor([\n",
    "                                                        [\n",
    "                                                         [part_0],\n",
    "                                                         [np.around(action[1],2)]\n",
    "                                                        ]\n",
    "                                                        ],requires_grad =False).to(self.device)\n",
    "                                \n",
    "                                action = action[:,:,0]\n",
    "                                action_1 = action[:,0]\n",
    "                                action_2 = action[:,1]\n",
    "                                log_prob_a2 = torch.tensor([  1/(sum(mask)+0.0001) ],requires_grad =False).to(self.device)\n",
    "                                for i in self.hero_agents_list:\n",
    "                                    \n",
    "                                    self.hero_agents_list[i].model.update_CL_sample_store(curr_agent_=curr_agent,\n",
    "                                                                                          inp = {'step':step_count,\n",
    "                                                                                                 'act_2_1':action_1 ,\n",
    "                                                                                                 'act_2_2':[] ,\n",
    "                                                                                                 'curr_reward_list':[]\n",
    "                                                  },before_action=2)\n",
    "                                    \n",
    "                                    self.hero_agents_list[i].model.update_CL_sample_store(curr_agent_=curr_agent,\n",
    "                                                                                          inp = {'step':step_count,\n",
    "                                                                                                 'act_2_1':[] ,\n",
    "                                                                                                 'act_2_2':action_2 ,\n",
    "                                                                                                 'curr_reward_list':[]\n",
    "                                                  },before_action=3)\n",
    "\n",
    "                                \n",
    "\n",
    "\n",
    "                            \n",
    "\n",
    "                                                              \n",
    "                            else:\n",
    "                                action_taken = True\n",
    "                                #action_masks[step]\n",
    "\n",
    "                                #need to update this\n",
    "                                action_1,_,action_taken,_ = self.hero_agents_list[curr_agent].action_predict(save_R=False,action_masks=action_masks[step_count])\n",
    "                                #action_1 = action_1[None,:]\n",
    "                                #so the action_1 should be updated here... and prediction of action_2 would be re-done\n",
    "\n",
    "\n",
    "                                \n",
    "                                \n",
    "                                if action_taken:\n",
    "                                    current_agent_acting[step_count] = curr_agent\n",
    "\n",
    "                                for i in self.hero_agents_list:\n",
    "                                    \n",
    "                                    self.hero_agents_list[i].model.update_CL_sample_store(curr_agent_=curr_agent,\n",
    "                                                                                          inp = {'step':step_count,\n",
    "                                                                                                 'act_2_1':action_1 ,\n",
    "                                                                                                 #'act_2_1':action_1[0] ,\n",
    "                                                                                                 'act_2_2':[] ,\n",
    "                                                                                                 'curr_reward_list':[]\n",
    "                                                  },before_action=2)\n",
    "\n",
    "                                _,action_2,_,log_prob_a2 = self.hero_agents_list[curr_agent].action_predict(save_R=False,action_masks=action_masks[step_count],return_log_prob_a2 = True)\n",
    "                               # action_2 = action_2[None,:]\n",
    "\n",
    "\n",
    "                                for i in self.hero_agents_list:\n",
    "                                    \n",
    "                                    self.hero_agents_list[i].model.update_CL_sample_store(curr_agent_=curr_agent,\n",
    "                                                                                          inp = {'step':step_count,\n",
    "                                                                                                 'act_2_1':[] ,\n",
    "                                                                                                 #'act_2_2':action_2[0] ,\n",
    "                                                                                                 'act_2_2':action_2 ,\n",
    "                                                                                                 'curr_reward_list':[]\n",
    "                                                  },before_action=3)\n",
    "                                    \n",
    "\n",
    "\n",
    "\n",
    "                            \n",
    "                                #print(action,action.requires_grad)\n",
    "                                #if len(action.shape)<2:\n",
    "                                    #print(episode,\"---2--\",action, action.shape)\n",
    "                                    #a()\n",
    "                                    #break\n",
    "                                \n",
    "                            \n",
    "                                #action = self.actor(torch.Tensor(model_in).to(self.device))\n",
    "\n",
    "                            #this is only to predict and save the return to go for all the transformer agents, will optimize later\n",
    "                            _ =  [ self.hero_agents_list[i].action_predict(save_R=True, action_masks=action_masks[step_count] # it only matters for the correct agent ... we are only saving the Q\n",
    "\n",
    "                                                                           \n",
    "                                                                          \n",
    "                                                                          ) for i in self.hero_agents_list]\n",
    "\n",
    "                            \n",
    "                            actions_1[step_count] = action_1\n",
    "                            actions_2[step_count] = action_2\n",
    "                            if log_prob_a2 != None:\n",
    "                                log_probs_actions_2[step_count] = log_prob_a2\n",
    "                            curr_agent_ = int(curr_agent)\n",
    "                            \n",
    "                            \n",
    "        \n",
    "                            if not observation['action_mask'][action_1.long()]: \n",
    "                                fault_condition =True\n",
    "                                \n",
    "                                #self.faulting_player = agent\n",
    "\n",
    "                                \n",
    "\n",
    "\n",
    "                                if  curr_agent_ in self.hero_agents_list:\n",
    "                                    self.hero_agents_list[curr_agent_].bad_move_count+=1\n",
    "                                    self.hero_agents_list[curr_agent_].bad_move_phase_count[int(current_phase[step_count][0])]+=1  # when is the where_is_it_performing_bad_really\n",
    "                                    #print('here',agent, action, observation['action_mask'])\n",
    "                            \n",
    "        \n",
    "                            if  curr_agent_ in self.hero_agents_list:\n",
    "                                self.hero_agents_list[curr_agent_].move_count[int(current_phase[step_count][0])]+=1  \n",
    "                            #if self.the_hero_agent == curr_agent:\n",
    "                                #move_count[int(current_phase[step][0])]+=1        \n",
    "        \n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            \n",
    "                        #print('here',agent, action)\n",
    "                        if action_1 != None :\n",
    "                            act_2_1 = action_1[0]\n",
    "                            act_2_2 = action_2[0]\n",
    "                            \n",
    "                            #act_2 = action.detach().cpu().numpy()[0]#list([action.detach().cpu().numpy()[0][0], max(action.detach().cpu().numpy()[0][1],0.1) ])\n",
    "                            #act_2 = torch.tensor([act_2[0], max(act_2[1],0.001) ]).to(device = self.device)\n",
    "                            #print(max(act_2_2.clone().detach().cpu().item(),0.001))\n",
    "                            env.step([act_2_1.clone().detach().cpu().item(), max(act_2_2.clone().detach().cpu().item(),0.001) ])  \n",
    "                            try:\n",
    "                                _ =1\n",
    "                                #env.step([act_2_1.clone().detach().cpu().item(), max(act_2_2.clone().detach().cpu().item(),0.001) ])    \n",
    "                            except Exception as e:\n",
    "                                print(\"action_taken\",action_taken)\n",
    "                                print(e)\n",
    "                                \n",
    "                                print([act_2_1.clone().detach().cpu(), max(act_2_2.clone().detach().cpu(),0.001) ])\n",
    "                                \n",
    "                            \n",
    "                        #env.step(act_2 if action != None else None)        \n",
    "        \n",
    "        \n",
    "                        if True:\n",
    "        \n",
    "                            \n",
    "                            curr_reward_list =  env.curr_rewards\n",
    "                            \n",
    "                            if (step_count == (self.episode_time_lim-1))   or (self.global_step == (self.num_steps-1)): # draw reward\n",
    "                                is_draw=1\n",
    "                                curr_reward_list = {i:-100 for i in env.possible_agents }\n",
    "\n",
    "                            \n",
    "\n",
    "                            #if self.hero == curr_agent_:\n",
    "                            #    DT_input['action'][-1]  =act_2\n",
    "                            #DT_input['return_to_go'][-1] -=  curr_reward_list[self.hero]\n",
    "                            #returntogo[step] = DT_input['return_to_go'][-1]\n",
    "\n",
    "                            for i in self.hero_agents_list:\n",
    "                                self.hero_agents_list[i].model.update_CL_sample_store(curr_agent_=curr_agent,\n",
    "                                              inp = {'step':step_count,\n",
    "                                                     'act_2_1':None ,\n",
    "                                                     'act_2_2':None ,\n",
    "                                                     'curr_reward_list':curr_reward_list[i]\n",
    "                                              },before_action=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            \n",
    "                            rewards_2[step_count] = torch.tensor([curr_reward_list[i] for i in env.possible_agents]).to(self.device,dtype=torch.float32)\n",
    "                            if step >1:\n",
    "                                dones_2[step_count] = torch.tensor([ int(env.terminations[i]) - dones_2[step_count-1,i-1]  for i in env.possible_agents]).to(self.device)\n",
    "                            else:\n",
    "                                dones_2[step_count] = torch.tensor([env.terminations[i] for i in env.possible_agents]).to(self.device)\n",
    "\n",
    "\n",
    "                        #list_curr_reward_list = np.array(list(curr_reward_list.values()))\n",
    "                        \n",
    "                        #if sum(curr_reward_list.values()) == -300:\n",
    "                            #print('here')\n",
    "                            #is_draw=1\n",
    "        \n",
    "                        \n",
    "                        for age_i in env.possible_agents:\n",
    "                            \n",
    "                            total_rewards[age_i]+=curr_reward_list[age_i] #env.curr_rewards[age_i] if (step_count != episode_time_lim) else -100\n",
    "                                    \n",
    "                        \n",
    "                        step +=1\n",
    "                        self.global_step+=1\n",
    "        \n",
    "                    else:\n",
    "                        self.training_performance_return.append(total_rewards[1])\n",
    "                        print('done:',env.terminations,#env.terminations.values(),\n",
    "                              \",total_reward:\",total_rewards, ',iteration:',iteration,\",episode:\", episode )\n",
    "                        print(env.board.territories)\n",
    "                        break    \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "                    step_count+=1\n",
    "                    \n",
    "                    if (self.global_step == self.num_steps) :# or (fault_condition and (fa ulting_player != agent) and (len(env.agents)==0)):\n",
    "                        \n",
    "                        print('global_break_1')\n",
    "                        self.training_performance_return.append(total_rewards[1])\n",
    "                        print('done:',env.terminations,#env.terminations.values(),\n",
    "                              \",total_reward:\",total_rewards, ',iteration:',iteration,\",episode:\", episode )\n",
    "                        print(env.board.territories)\n",
    "\n",
    "                        #have to get out of the outer loop\n",
    "                        break\n",
    "                    elif (step_count == self.episode_time_lim):\n",
    "                        print('episode_break_1')\n",
    "                        self.training_performance_return.append(total_rewards[1])\n",
    "                        print('done:',env.terminations,#env.terminations.values(),\n",
    "                              \",total_reward:\",total_rewards, ',iteration:',iteration,\",episode:\", episode )\n",
    "                        print(env.board.territories)\n",
    "                        break\n",
    "\n",
    "                #self.obs=obs\n",
    "                \n",
    "                #print_here\n",
    "                print(episode,step_count,iteration)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                #print(rewards[step-2])\n",
    "                if self.global_step == self.num_steps:\n",
    "                    print('global_break_2')\n",
    "                    break \n",
    "\n",
    "                for i in self.hero_agents_list:\n",
    "                    self.hero_agents_list[i].position =self.total_agents\n",
    "                    \n",
    "                    \n",
    "                #[ position = 3 for i in ] \n",
    "                for k_,(i_,j_) in enumerate(sorted([(j_,i_) for i_,j_ in total_rewards.items()],reverse=True) \n",
    "                      ):\n",
    "                    if int(j_) in self.hero_agents_list:\n",
    "                        self.hero_agents_list[int(j_)].position = k_+1\n",
    "                        print(j_,self.hero_agents_list[int(j_)].position)\n",
    "                        \n",
    "                        \n",
    "                    #if j_==self.the_hero_agent:\n",
    "                    #    position = k_+1\n",
    "\n",
    "                cur_epi_list = (episodes == curren_epi)\n",
    "                        \n",
    "                if self.args.TB_log:\n",
    "                    self.write_exploring(is_draw,#position,\n",
    "                            curren_epi,step,\n",
    "                            step_count,\n",
    "                            total_rewards,#bad_move_count\n",
    "                            #,bad_move_phase_count,\n",
    "                            #move_count,\n",
    "                            observation,\n",
    "                            env,\n",
    "                            cur_epi_list,\n",
    "                            current_agent_acting)\n",
    "\n",
    "                #paths = []\n",
    "\n",
    "                for i in self.hero_agents_list:\n",
    "                    self.hero_agents_list[i].model.update_train_data(\n",
    "                         step_count,\n",
    "                         obs,\n",
    "                            self.ob_space_shape,\n",
    "                            rewards_2[:,i-1],\n",
    "                            dones_2[:,i-1],\n",
    "                            actions_1[cur_epi_list],actions_2,log_probs_actions_2,\n",
    "                            action_masks,\n",
    "                            current_agent,\n",
    "                            current_agent_acting,\n",
    "                            current_phase,\n",
    "                            current_troops_count[:,i-1],\n",
    "                            map_agent_phase_vector = self.map_agent_phase_vector,\n",
    "                            \n",
    "                         )\n",
    "\n",
    "\n",
    "\n",
    "        #this  ---------------\n",
    "        #avg_episode_length = torch.mean(torch.tensor(\n",
    "        #                    [(episodes[:step] == i_epi).sum() for i_epi in episodes[:step].unique()]).float())#np.mean([(episodes[:step] == i_epi).sum() for i_epi in episodes[:step].unique()])\n",
    "        #if self.args.TB_log:\n",
    "        #    self.writer.add_scalar(\"charts/avg_episodic_length\", avg_episode_length, self.global_step)\n",
    "\n",
    "\n",
    "\n",
    "        #return paths\n",
    "        #return rb    \n",
    "        \n",
    "\n",
    "    def write_exploring(self,is_draw,#position,\n",
    "                        curren_epi,step,\n",
    "                        step_count,\n",
    "                        total_rewards,#bad_move_count\n",
    "                        #,bad_move_phase_count,\n",
    "                        #move_count,\n",
    "                        observation,\n",
    "                        env,\n",
    "                        cur_epi_list,\n",
    "                        current_agent_acting):\n",
    "\n",
    "        if is_draw:\n",
    "            self.draw_count +=1\n",
    "\n",
    "            for i in self.hero_agents_list:\n",
    "\n",
    "                self.writer.add_scalar(f\"draw_charts_agent_{i}/position_draw\",self.hero_agents_list[i].position\n",
    "                                                                                            ,self.draw_count) #draw_count is the number of draw episodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                self.hero_agents_list[i].draw_territory_count = int(observation['observation'][:,i].sum()) #this is the total number of states\n",
    "                \n",
    "                self.hero_agents_list[i].count_draw_dict[\n",
    "                                                        self.hero_agents_list[i].position\n",
    "                                                        ] +=1\n",
    "                self.writer.add_scalar(f\"draw_charts_agent_{i}/draw_territory_count\",\n",
    "                                                                               self.hero_agents_list[i].draw_territory_count,\n",
    "                                                                               self.draw_count)#self.global_step)\n",
    "                \n",
    "                for j in self.hero_agents_list[i].count_draw_dict:\n",
    "                    self.writer.add_scalar(f\"draw_charts_agent_{i}/{j}_position_prop_draw\",int(\n",
    "                                                                                            self.hero_agents_list[i].position==j\n",
    "                                                                                            ),self.draw_count)\n",
    "\n",
    "                    if j not in [1,2]:\n",
    "                        self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_all_prop\",int(\n",
    "                                                                                            self.hero_agents_list[i].position==j\n",
    "                                                                                            ),(curren_epi+1))\n",
    "\n",
    "                        self.writer.add_scalar(f\"draw_charts_agent_{i}/{j}_place_in_draw\",\n",
    "                                                                   self.hero_agents_list[i].count_draw_dict[j],\n",
    "                                                                   self.draw_count)\n",
    "\n",
    "                        self.writer.add_scalar(f\"draw_charts_agent_{i}/{j}_place_in_draw_ratio\",\n",
    "                                                                   self.hero_agents_list[i].count_draw_dict[j]/self.draw_count,\n",
    "                                                                   self.draw_count)\n",
    "                        \n",
    "                    \n",
    "            self.writer.add_scalar(\"draw_charts/draw_count\",self.draw_count,(curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(\"draw_charts/draw\",1,(curren_epi+1))\n",
    "            self.writer.add_scalar(\"draw_charts/draw_to_total_count\",self.draw_count/(curren_epi +1+0.000001),(curren_epi +1))#self.global_step)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            non_draw_count =(curren_epi-self.draw_count+1+0.000001)\n",
    "            for i in self.hero_agents_list:\n",
    "\n",
    "                self.writer.add_scalar(f\"win_charts_agent_{i}/position_win\",self.hero_agents_list[i].position\n",
    "                                                                                            ,(curren_epi+1))\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                self.hero_agents_list[i].count_dict[self.hero_agents_list[i].position\n",
    "                                               ] +=1\n",
    "\n",
    "                \n",
    "                for j in self.hero_agents_list[i].count_dict:\n",
    "                    self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_prop\",int(\n",
    "                                                            self.hero_agents_list[i].position==j\n",
    "                                                            ),(curren_epi+1))\n",
    "\n",
    "                    self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position\",self.hero_agents_list[i].count_dict[j],\n",
    "                                           (curren_epi+1))\n",
    "\n",
    "                    self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_to_total_terminated\",self.hero_agents_list[i].count_dict[j]/non_draw_count,(curren_epi+1))\n",
    "\n",
    "                    if j not in [1,2]:\n",
    "                        self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_all_prop\",int(\n",
    "                                                                                            self.hero_agents_list[i].position==j\n",
    "                                                                                            ),(curren_epi+1))\n",
    "\n",
    "\n",
    "            self.writer.add_scalar(\"draw_charts/draw\",0,(curren_epi+1))\n",
    "            \n",
    "        for i in self.hero_agents_list:\n",
    "\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/model_move_count_per_episode\",   sum(current_agent_acting[:step_count] ==i)  ,  (curren_epi +1))\n",
    "\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/model_2_total_move_count_per_episode\",   sum(current_agent_acting[:step_count] ==i)/sum( self.hero_agents_list[i].move_count.values()),  (curren_epi +1))\n",
    "\n",
    "            self.writer.add_scalar(f\"win_charts_agent_{i}/position_all\",self.hero_agents_list[i].position\n",
    "                                                                                            ,(curren_epi+1))\n",
    "\n",
    "            \n",
    "            for j in self.hero_agents_list[i].count_dict:\n",
    "                self.writer.add_scalar(f\"win_charts_agent_{i}/{j}_position_to_total\",(\n",
    "                                                            self.hero_agents_list[i].count_dict[j]+\n",
    "                                                            self.hero_agents_list[i].count_draw_dict[j]\n",
    "                                                        \n",
    "                                                            )/(curren_epi +1+0.00001 ),(curren_epi+1))#global_step)\n",
    "\n",
    "            \n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_count_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_count,            (curren_epi +1))#self.global_step)\n",
    "                \n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_count_position_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[0],            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_count_attack_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[1],            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_count_fortify_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[2],            (curren_epi +1))#self.global_step)\n",
    "            \n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/total_moves\",sum(\n",
    "                                                    self.hero_agents_list[i].move_count.values()),            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_to_step_count_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_count/(sum(\n",
    "                                                   self.hero_agents_list[i].move_count.values())+1),            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_to_step_position_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[0]/( \n",
    "                                                   self.hero_agents_list[i].move_count[0]+1),            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_to_step_attack_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[1]/( \n",
    "                                                   self.hero_agents_list[i].move_count[1]+1),            (curren_epi +1))#self.global_step)\n",
    "            self.writer.add_scalar(f\"moves/agent_{i}/bad_move_to_step_fortify_per_episode\",\n",
    "                                               self.hero_agents_list[i].bad_move_phase_count[2]/( \n",
    "                                                   self.hero_agents_list[i].move_count[2]+1),            (curren_epi +1))#self.global_step)\n",
    "\n",
    "        \n",
    "        self.writer.add_scalar(\"charts/epsilon\",(curren_epi/((self.num_iterations*self.num_episodes)/10)),(curren_epi +1))#self.global_step)\n",
    "        self.writer.add_scalar(\"charts/avg_per_epi_total_reward\", np.mean(list(total_rewards.values())), (curren_epi +1))#self.global_step)\n",
    "\n",
    "        \n",
    "\n",
    "        #values_total = {i:0 for i in self.env.possible_agents}\n",
    "        \n",
    "\n",
    "        \n",
    "        self.writer.add_scalar(\"charts/episodic_length\", cur_epi_list[:step].sum(), (curren_epi +1))#self.global_step)\n",
    "        \n",
    "        for i in env.possible_agents:\n",
    "            #cur_index = torch.where((current_agent[:,0] == i) &( cur_epi_list ))[0]\n",
    "\n",
    "            #values_total[i] = values[cur_index].mean()\n",
    "            #writer.add_scalar(\"charts/mean_value_per_epi_agent_\"+str(i), values_total[i], global_step)\n",
    "            \n",
    "            self.writer.add_scalar(\"charts/total_reward_per_epi_agent_\"+str(i), total_rewards[i], (curren_epi +1))#self.global_step)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5ef2c-809a-471a-a3ab-ac044049a212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80d7f2-d7f7-428d-9b5f-f70642dcc8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8815f-f99c-4b15-82e7-90cc48c66fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a5ba-0d1a-404d-bf4d-36db6450b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cfc23-dba9-4a51-97e7-f901760c21ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b611c-fc8a-4ef2-ba05-c754bb9da346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad476a7-6507-41a1-8427-506ba727cad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec6ad37-742d-4510-893e-27cfec644bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c365e-30f1-48e5-8d25-c6f04be1b6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fdf692-0c3e-48c4-a7d9-7902ae187a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27560f9-f1fb-4a5c-9374-652525467ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e4626-d33f-4660-9ee4-c98f94b67f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc5abf-53b6-4d9a-85b5-6b5429bd27fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e32426-5897-4d30-8b73-d71b64227320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ca33b-dca6-43d6-af8a-5898e6e05435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import stable_baselines3 as sb3\n",
    "\n",
    "    if sb3.__version__ < \"2.0\":\n",
    "        raise ValueError(\n",
    "            \"\"\"Ongoing migration: run the following command to install the new dependencies:\n",
    "poetry run pip install \"stable_baselines3==2.0.0a1\"\n",
    "\"\"\"\n",
    "        )\n",
    "    args = Args()#tyro.cli(Args)\n",
    "    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
    "    #if args.track:\n",
    "    #    import wandb\n",
    "\n",
    "        #wandb.init(\n",
    "        #    project=args.wandb_project_name,\n",
    "        #    entity=args.wandb_entity,\n",
    "        #    sync_tensorboard=True,\n",
    "        #    config=vars(args),\n",
    "        #    name=run_name,\n",
    "        #    monitor_gym=True,\n",
    "        #    save_code=True,\n",
    "        #)\n",
    "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "    writer.add_text(\n",
    "        \"hyperparameters\",\n",
    "        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
    "    )\n",
    "\n",
    "    # TRY NOT TO MODIFY: seeding\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "    # env setup\n",
    "    envs = gym.vector.SyncVectorEnv([make_env(args.env_id, args.seed, 0, args.capture_video, run_name)])\n",
    "    assert isinstance(envs.single_action_space, gym.spaces.Box), \"only continuous action space is supported\"\n",
    "\n",
    "    actor = Actor(envs).to(device)\n",
    "    qf1 = QNetwork(envs).to(device)\n",
    "    qf1_target = QNetwork(envs).to(device)\n",
    "    target_actor = Actor(envs).to(device)\n",
    "    target_actor.load_state_dict(actor.state_dict())\n",
    "    qf1_target.load_state_dict(qf1.state_dict())\n",
    "    q_optimizer = optim.Adam(list(qf1.parameters()), lr=args.learning_rate)\n",
    "    actor_optimizer = optim.Adam(list(actor.parameters()), lr=args.learning_rate)\n",
    "\n",
    "    envs.single_observation_space.dtype = np.float32\n",
    "    rb = ReplayBuffer(\n",
    "        args.buffer_size,\n",
    "        envs.single_observation_space,\n",
    "        envs.single_action_space,\n",
    "        device,\n",
    "        handle_timeout_termination=False,\n",
    "    )\n",
    "    start_time = time.time()\n",
    "\n",
    "    # TRY NOT TO MODIFY: start the game\n",
    "    obs, _ = envs.reset(seed=args.seed)\n",
    "    for global_step in range(args.total_timesteps):\n",
    "        # ALGO LOGIC: put action logic here\n",
    "        if global_step < args.learning_starts:\n",
    "            actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                actions = actor(torch.Tensor(obs).to(device))\n",
    "                actions += torch.normal(0, actor.action_scale * args.exploration_noise)\n",
    "                actions = actions.cpu().numpy().clip(envs.single_action_space.low, envs.single_action_space.high)\n",
    "\n",
    "        # TRY NOT TO MODIFY: execute the game and log data.\n",
    "        next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
    "\n",
    "        # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
    "        if \"final_info\" in infos:\n",
    "            for info in infos[\"final_info\"]:\n",
    "                print(f\"global_step={global_step}, episodic_return={info['episode']['r']}\")\n",
    "                writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
    "                writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
    "                break\n",
    "\n",
    "        # TRY NOT TO MODIFY: save data to reply buffer; handle `final_observation`\n",
    "        real_next_obs = next_obs.copy()\n",
    "        for idx, trunc in enumerate(truncations):\n",
    "            if trunc:\n",
    "                real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
    "        rb.add(obs, real_next_obs, actions, rewards, terminations, infos)\n",
    "\n",
    "        # TRY NOT TO MODIFY: CRUCIAL step easy to overlook\n",
    "        obs = next_obs\n",
    "\n",
    "        # ALGO LOGIC: training.\n",
    "        if global_step > args.learning_starts:\n",
    "            data = rb.sample(args.batch_size)\n",
    "            with torch.no_grad():\n",
    "                next_state_actions = target_actor(data.next_observations)\n",
    "                qf1_next_target = qf1_target(data.next_observations, next_state_actions)\n",
    "                next_q_value = data.rewards.flatten() + (1 - data.dones.flatten()) * args.gamma * (qf1_next_target).view(-1)\n",
    "\n",
    "            qf1_a_values = qf1(data.observations, data.actions).view(-1)\n",
    "            qf1_loss = F.mse_loss(qf1_a_values, next_q_value)\n",
    "\n",
    "            # optimize the model\n",
    "            q_optimizer.zero_grad()\n",
    "            qf1_loss.backward()\n",
    "            q_optimizer.step()\n",
    "\n",
    "            if global_step % args.policy_frequency == 0:\n",
    "                actor_loss = -qf1(data.observations, actor(data.observations)).mean()\n",
    "                actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                actor_optimizer.step()\n",
    "\n",
    "                # update the target network\n",
    "                for param, target_param in zip(actor.parameters(), target_actor.parameters()):\n",
    "                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n",
    "                for param, target_param in zip(qf1.parameters(), qf1_target.parameters()):\n",
    "                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n",
    "\n",
    "            if global_step % 100 == 0:\n",
    "                writer.add_scalar(\"losses/qf1_values\", qf1_a_values.mean().item(), global_step)\n",
    "                writer.add_scalar(\"losses/qf1_loss\", qf1_loss.item(), global_step)\n",
    "                writer.add_scalar(\"losses/actor_loss\", actor_loss.item(), global_step)\n",
    "                print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "                writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
    "\n",
    "    if args.save_model:\n",
    "        model_path = f\"runs/{run_name}/{args.exp_name}.cleanrl_model\"\n",
    "        torch.save((actor.state_dict(), qf1.state_dict()), model_path)\n",
    "        print(f\"model saved to {model_path}\")\n",
    "        from cleanrl_utils.evals.ddpg_eval import evaluate\n",
    "\n",
    "        episodic_returns = evaluate(\n",
    "            model_path,\n",
    "            make_env,\n",
    "            args.env_id,\n",
    "            eval_episodes=10,\n",
    "            run_name=f\"{run_name}-eval\",\n",
    "            Model=(Actor, QNetwork),\n",
    "            device=device,\n",
    "            exploration_noise=args.exploration_noise,\n",
    "        )\n",
    "        for idx, episodic_return in enumerate(episodic_returns):\n",
    "            writer.add_scalar(\"eval/episodic_return\", episodic_return, idx)\n",
    "\n",
    "        if args.upload_model:\n",
    "            from cleanrl_utils.huggingface import push_to_hub\n",
    "\n",
    "            repo_name = f\"{args.env_id}-{args.exp_name}-seed{args.seed}\"\n",
    "            repo_id = f\"{args.hf_entity}/{repo_name}\" if args.hf_entity else repo_name\n",
    "            push_to_hub(args, episodic_returns, repo_id, \"DDPG\", f\"runs/{run_name}\", f\"videos/{run_name}-eval\")\n",
    "\n",
    "    envs.close()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b463dca-79aa-4afa-add7-6b3e2f0c8529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107e755-84b7-4197-99c4-78a7a88d29d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaebee5-3968-4cef-b1e5-fbfb575ab99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4ef06-ea3f-4c7c-8314-ff9fc26307e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL_project)",
   "language": "python",
   "name": "dl_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
